galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:15,347 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ss9xb with k8s id: gxy-ss9xb succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:48:15,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 161: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:16,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rlzbp with k8s id: gxy-rlzbp succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:16,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7rg2f with k8s id: gxy-7rg2f succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:16,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-khx2v with k8s id: gxy-khx2v succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:16,574 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qz7h9 with k8s id: gxy-qz7h9 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:48:16,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 162: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:16,738 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 163: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:16,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 164: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-03 06:48:17,400 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 173
tpv.core.entities DEBUG 2024-11-03 06:48:17,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:48:17,492 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:48:17,497 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:48:17,509 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:48:17,524 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Working directory for job is: /galaxy/server/database/jobs_directory/000/173
galaxy.jobs.runners DEBUG 2024-11-03 06:48:17,532 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [173] queued (34.888 ms)
galaxy.jobs.handler INFO 2024-11-03 06:48:17,594 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:17,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jsdhn with k8s id: gxy-jsdhn succeeded
galaxy.jobs.handler DEBUG 2024-11-03 06:48:18,597 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 174
tpv.core.entities DEBUG 2024-11-03 06:48:18,702 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:48:18,702 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:48:18,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:48:18,796 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:48:18,813 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Working directory for job is: /galaxy/server/database/jobs_directory/000/174
galaxy.jobs.runners DEBUG 2024-11-03 06:48:18,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [174] queued (112.780 ms)
galaxy.jobs.handler INFO 2024-11-03 06:48:18,894 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:22,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gwhn5 with k8s id: gxy-gwhn5 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:22,295 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9b9nm with k8s id: gxy-9b9nm succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:23,336 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tghgc with k8s id: gxy-tghgc succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:23,396 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qr7rp with k8s id: gxy-qr7rp succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:23,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2prpz with k8s id: gxy-2prpz succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:23,415 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-859kd with k8s id: gxy-859kd succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:48:30,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 161 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:30,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 225
galaxy.jobs INFO 2024-11-03 06:48:30,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 161 in /galaxy/server/database/jobs_directory/000/161
galaxy.jobs DEBUG 2024-11-03 06:48:30,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 161 executed (179.347 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:30,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 161 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:48:31,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 166: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:32,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 163 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:32,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 227
galaxy.jobs INFO 2024-11-03 06:48:32,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 163 in /galaxy/server/database/jobs_directory/000/163
galaxy.jobs.runners DEBUG 2024-11-03 06:48:32,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 162 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:32,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 226
galaxy.jobs DEBUG 2024-11-03 06:48:32,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 163 executed (218.542 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 163 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-03 06:48:32,607 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 162 in /galaxy/server/database/jobs_directory/000/162
galaxy.jobs.runners DEBUG 2024-11-03 06:48:32,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 164 finished
galaxy.jobs DEBUG 2024-11-03 06:48:32,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 162 executed (172.831 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,698 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 173
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,729 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 162 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 06:48:32,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 228
galaxy.jobs INFO 2024-11-03 06:48:32,795 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 164 in /galaxy/server/database/jobs_directory/000/164
galaxy.jobs DEBUG 2024-11-03 06:48:32,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [173] prepared (102.211 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:48:32,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/173/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/173/registry.xml' '/galaxy/server/database/jobs_directory/000/173/upload_params.json' '237:/galaxy/server/database/objects/1/8/e/dataset_18e75fd7-4805-4435-989c-3c11256f0831_files:/galaxy/server/database/objects/1/8/e/dataset_18e75fd7-4805-4435-989c-3c11256f0831.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:48:32,840 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (173) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/173/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/173/galaxy_173.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:48:32,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 164 executed (164.355 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 164 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:32,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 174
galaxy.jobs.runners DEBUG 2024-11-03 06:48:32,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 165: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-03 06:48:33,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [174] prepared (98.076 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:48:33,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/174/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/174/registry.xml' '/galaxy/server/database/jobs_directory/000/174/upload_params.json' '238:/galaxy/server/database/objects/2/a/d/dataset_2ad11034-abfe-4891-bea8-cbbe6a50f4ee_files:/galaxy/server/database/objects/2/a/d/dataset_2ad11034-abfe-4891-bea8-cbbe6a50f4ee.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:48:33,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (174) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/174/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/174/galaxy_174.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:33,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:33,096 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:48:33,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 168: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:33,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 169: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:33,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:33,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:42,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pqsmt with k8s id: gxy-pqsmt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:42,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-twl2s with k8s id: gxy-twl2s succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:48:45,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 166 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:45,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 230
galaxy.jobs INFO 2024-11-03 06:48:45,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 166 in /galaxy/server/database/jobs_directory/000/166
galaxy.jobs DEBUG 2024-11-03 06:48:45,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 166 executed (192.668 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:45,837 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 166 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:48:46,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 167: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:47,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 165 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:47,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 229
galaxy.jobs INFO 2024-11-03 06:48:47,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 165 in /galaxy/server/database/jobs_directory/000/165
galaxy.jobs DEBUG 2024-11-03 06:48:48,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 165 executed (142.882 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:48,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 165 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:48:48,230 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 169 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:48,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 233
galaxy.jobs INFO 2024-11-03 06:48:48,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 169 in /galaxy/server/database/jobs_directory/000/169
galaxy.jobs.runners DEBUG 2024-11-03 06:48:48,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 171: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:48,433 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 168 finished
galaxy.model.metadata DEBUG 2024-11-03 06:48:48,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 232
galaxy.jobs DEBUG 2024-11-03 06:48:48,607 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 169 executed (358.798 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:48,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 169 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-03 06:48:48,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 168 in /galaxy/server/database/jobs_directory/000/168
galaxy.jobs DEBUG 2024-11-03 06:48:48,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 168 executed (294.621 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:48:48,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 168 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:48:49,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 170: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:48:49,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 172: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:49:00,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 167 finished
galaxy.model.metadata DEBUG 2024-11-03 06:49:00,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 231
galaxy.jobs INFO 2024-11-03 06:49:01,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 167 in /galaxy/server/database/jobs_directory/000/167
galaxy.jobs DEBUG 2024-11-03 06:49:01,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 167 executed (203.005 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:01,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 167 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:01,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 173: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:49:03,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 171 finished
galaxy.model.metadata DEBUG 2024-11-03 06:49:03,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 235
galaxy.jobs INFO 2024-11-03 06:49:03,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 171 in /galaxy/server/database/jobs_directory/000/171
galaxy.jobs DEBUG 2024-11-03 06:49:03,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 171 executed (185.608 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:03,440 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 171 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:03,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 170 finished
galaxy.model.metadata DEBUG 2024-11-03 06:49:03,643 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 234
galaxy.jobs INFO 2024-11-03 06:49:03,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 170 in /galaxy/server/database/jobs_directory/000/170
galaxy.jobs.runners DEBUG 2024-11-03 06:49:03,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 174: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:49:03,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 172 finished
galaxy.jobs DEBUG 2024-11-03 06:49:03,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 170 executed (176.255 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:03,817 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 170 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 06:49:03,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 236
galaxy.jobs INFO 2024-11-03 06:49:03,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 172 in /galaxy/server/database/jobs_directory/000/172
galaxy.jobs DEBUG 2024-11-03 06:49:03,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 172 executed (138.354 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:03,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 172 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:10,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 173 finished
galaxy.model.metadata DEBUG 2024-11-03 06:49:10,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 237
galaxy.jobs INFO 2024-11-03 06:49:10,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 173 in /galaxy/server/database/jobs_directory/000/173
galaxy.jobs DEBUG 2024-11-03 06:49:10,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 173 executed (97.679 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:10,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:11,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 174 finished
galaxy.model.metadata DEBUG 2024-11-03 06:49:11,447 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 238
galaxy.jobs INFO 2024-11-03 06:49:11,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 174 in /galaxy/server/database/jobs_directory/000/174
galaxy.jobs DEBUG 2024-11-03 06:49:11,524 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 174 executed (96.380 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:11,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:12,235 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 175
tpv.core.entities DEBUG 2024-11-03 06:49:12,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:12,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:12,281 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:12,290 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:12,304 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Working directory for job is: /galaxy/server/database/jobs_directory/000/175
galaxy.jobs.runners DEBUG 2024-11-03 06:49:12,316 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [175] queued (35.666 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:12,320 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:12,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 175
galaxy.jobs DEBUG 2024-11-03 06:49:12,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [175] prepared (138.909 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:49:12,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:49:12,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:49:12,489 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:49:12,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/175/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/175/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/bismark_0 &&    mkdir 'multiqc_WDir/bismark_0/align_0' &&     ln -s '/galaxy/server/database/objects/b/d/d/dataset_bdd99a94-a9c0-48ba-adf6-074f97592f43.dat' 'multiqc_WDir/bismark_0/align_0/bismark_txt_SE_report.txt' && mkdir multiqc_WDir/bowtie2_1 &&         grep -q '% overall alignment rate' /galaxy/server/database/objects/f/6/d/dataset_f6dee863-a6a1-4cc0-8848-2ea081cdb009.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_1_txt'" && ln -s '/galaxy/server/database/objects/f/6/d/dataset_f6dee863-a6a1-4cc0-8848-2ea081cdb009.dat' 'multiqc_WDir/bowtie2_1/bowtie2_1_txt'  &&       grep -q '% overall alignment rate' /galaxy/server/database/objects/9/3/2/dataset_93273c47-11ad-443c-8e38-a25163b39a53.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_2_txt'" && ln -s '/galaxy/server/database/objects/9/3/2/dataset_93273c47-11ad-443c-8e38-a25163b39a53.dat' 'multiqc_WDir/bowtie2_1/bowtie2_2_txt'  &&   mkdir multiqc_WDir/hisat2_2 &&         grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/d/c/1/dataset_dc1cc0d1-a002-488e-8a43-eb285e36f01e.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_1_txt'" && ln -s '/galaxy/server/database/objects/d/c/1/dataset_dc1cc0d1-a002-488e-8a43-eb285e36f01e.dat' 'multiqc_WDir/hisat2_2/hisat2_1_txt'  &&       grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/b/7/8/dataset_b78e396d-f92c-44bd-a348-a2804fdb260d.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_2_txt'" && ln -s '/galaxy/server/database/objects/b/7/8/dataset_b78e396d-f92c-44bd-a348-a2804fdb260d.dat' 'multiqc_WDir/hisat2_2/hisat2_2_txt'  &&   mkdir multiqc_WDir/hicexplorer_3 &&         grep -q 'Min rest. site distance' /galaxy/server/database/objects/1/6/5/dataset_165d8746-7c8c-4e7c-b9dd-44dbc2c4a0b1.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/1/6/5/dataset_165d8746-7c8c-4e7c-b9dd-44dbc2c4a0b1.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/1/6/5/dataset_165d8746-7c8c-4e7c-b9dd-44dbc2c4a0b1.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/1/6/5/dataset_165d8746-7c8c-4e7c-b9dd-44dbc2c4a0b1.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log_1'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/a/4/a/dataset_a4ad9252-f1ee-44e8-8228-757290092793.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer2_log'" && ln -s '/galaxy/server/database/objects/a/4/a/dataset_a4ad9252-f1ee-44e8-8228-757290092793.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer2_log'  &&   mkdir multiqc_WDir/kallisto_4 &&         grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/e/0/e/dataset_e0ecea45-6dc6-4b0f-b7ae-1e2584f8aab9.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_1_txt'" && ln -s '/galaxy/server/database/objects/e/0/e/dataset_e0ecea45-6dc6-4b0f-b7ae-1e2584f8aab9.dat' 'multiqc_WDir/kallisto_4/kallisto_1_txt'  &&       grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/5/1/3/dataset_5133d486-1613-4f87-93c8-f27944253115.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_2_txt'" && ln -s '/galaxy/server/database/objects/5/1/3/dataset_5133d486-1613-4f87-93c8-f27944253115.dat' 'multiqc_WDir/kallisto_4/kallisto_2_txt'  &&   mkdir multiqc_WDir/macs2_5 &&     grep -q "# This file is generated by MACS" /galaxy/server/database/objects/9/b/4/dataset_9b4c270a-5713-42d9-bb93-9b783b490d7e.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/9/b/4/dataset_9b4c270a-5713-42d9-bb93-9b783b490d7e.dat' 'multiqc_WDir/macs2_5/macs_1_txt_peaks.xls' &&    grep -q "# This file is generated by MACS" /galaxy/server/database/objects/6/4/7/dataset_647cfae5-a471-4ab4-8a70-103bd12dbe92.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/6/4/7/dataset_647cfae5-a471-4ab4-8a70-103bd12dbe92.dat' 'multiqc_WDir/macs2_5/macs_2_txt_peaks.xls' && mkdir multiqc_WDir/star_6 &&    mkdir 'multiqc_WDir/star_6/log_0' &&     ln -s '/galaxy/server/database/objects/6/f/1/dataset_6f1fa0d9-7bb1-47c1-b4ae-17a4f1368b9f.dat' 'multiqc_WDir/star_6/log_0/star_log_txt_Log.final.out' &&   mkdir 'multiqc_WDir/star_6/genecounts_1' &&     ln -s '/galaxy/server/database/objects/1/8/e/dataset_18e75fd7-4805-4435-989c-3c11256f0831.dat' 'multiqc_WDir/star_6/genecounts_1/star_counts_txt_ReadsPerGene.out.tab' && mkdir multiqc_WDir/tophat_7 &&     ln -s '/galaxy/server/database/objects/2/a/d/dataset_2ad11034-abfe-4891-bea8-cbbe6a50f4ee.dat' 'multiqc_WDir/tophat_7/tophat_txtalign_summary.txt' &&  multiqc multiqc_WDir --filename "report"]
galaxy.jobs.runners DEBUG 2024-11-03 06:49:12,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (175) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/175/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/175/galaxy_175.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/175/working/report.html" -a -f "/galaxy/server/database/objects/0/e/a/dataset_0ea4cdb2-db39-43c1-a26c-4a46b3b6965a.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/175/working/report.html" "/galaxy/server/database/objects/0/e/a/dataset_0ea4cdb2-db39-43c1-a26c-4a46b3b6965a.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:12,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:49:12,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:49:12,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:49:12,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:12,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:13,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:21,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9jgdk with k8s id: gxy-9jgdk succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:49:21,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 175: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:49:29,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 175 finished
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_bismark_alignment.txt] with element identifier [bismark_alignment] for output [stats] (14.486 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_bowtie2.txt] with element identifier [bowtie2] for output [stats] (0.552 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_cutadapt.txt] with element identifier [cutadapt] for output [stats] (0.449 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (0.406 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_hicexplorer.txt] with element identifier [hicexplorer] for output [stats] (0.429 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_hisat2.txt] with element identifier [hisat2] for output [stats] (0.399 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_kallisto.txt] with element identifier [kallisto] for output [stats] (0.429 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_macs.txt] with element identifier [macs] for output [stats] (0.383 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.403 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_star.txt] with element identifier [star] for output [stats] (0.369 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/175/working/report_data/multiqc_tophat.txt.txt] with element identifier [tophat.txt] for output [stats] (0.339 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:49:29,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) Add dynamic collection datasets to history for output [stats] (104.029 ms)
galaxy.model.metadata DEBUG 2024-11-03 06:49:29,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 239
galaxy.jobs INFO 2024-11-03 06:49:29,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 175 in /galaxy/server/database/jobs_directory/000/175
galaxy.jobs DEBUG 2024-11-03 06:49:29,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 175 executed (323.493 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:29,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:31,641 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 178, 177, 176
tpv.core.entities DEBUG 2024-11-03 06:49:31,662 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:31,663 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:31,666 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:31,675 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:31,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Working directory for job is: /galaxy/server/database/jobs_directory/000/176
galaxy.jobs.runners DEBUG 2024-11-03 06:49:31,694 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [176] queued (28.631 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:31,697 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,700 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 176
tpv.core.entities DEBUG 2024-11-03 06:49:31,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:31,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:31,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:31,725 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:31,755 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Working directory for job is: /galaxy/server/database/jobs_directory/000/177
galaxy.jobs.runners DEBUG 2024-11-03 06:49:31,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [177] queued (50.275 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:31,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 177
tpv.core.entities DEBUG 2024-11-03 06:49:31,785 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:31,785 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:31,790 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:31,804 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:31,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [176] prepared (115.583 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:31,845 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Working directory for job is: /galaxy/server/database/jobs_directory/000/178
galaxy.jobs.runners DEBUG 2024-11-03 06:49:31,854 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [178] queued (64.171 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:31,858 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 178
galaxy.jobs.command_factory INFO 2024-11-03 06:49:31,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/176/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/176/registry.xml' '/galaxy/server/database/jobs_directory/000/176/upload_params.json' '251:/galaxy/server/database/objects/4/8/a/dataset_48a19530-811c-4123-9d00-0d144b136aff_files:/galaxy/server/database/objects/4/8/a/dataset_48a19530-811c-4123-9d00-0d144b136aff.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:31,887 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (176) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/176/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/176/galaxy_176.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:49:31,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [177] prepared (112.336 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:31,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/177/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/177/registry.xml' '/galaxy/server/database/jobs_directory/000/177/upload_params.json' '252:/galaxy/server/database/objects/2/9/4/dataset_294e3250-c3dd-4763-b4f4-da21b1737c1f_files:/galaxy/server/database/objects/2/9/4/dataset_294e3250-c3dd-4763-b4f4-da21b1737c1f.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:31,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (177) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/177/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/177/galaxy_177.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:31,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:31,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [178] prepared (111.718 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:32,008 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/178/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/178/registry.xml' '/galaxy/server/database/jobs_directory/000/178/upload_params.json' '253:/galaxy/server/database/objects/4/0/3/dataset_4035b2d7-9c9d-4f75-aa49-658dd3e09631_files:/galaxy/server/database/objects/4/0/3/dataset_4035b2d7-9c9d-4f75-aa49-658dd3e09631.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:32,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (178) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/178/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/178/galaxy_178.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,676 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-03 06:49:32,862 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 181, 180, 179, 183, 182
tpv.core.entities DEBUG 2024-11-03 06:49:32,883 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:32,883 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:32,886 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:32,895 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:32,907 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Working directory for job is: /galaxy/server/database/jobs_directory/000/179
galaxy.jobs.runners DEBUG 2024-11-03 06:49:32,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [179] queued (26.896 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:32,916 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 179
tpv.core.entities DEBUG 2024-11-03 06:49:32,926 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:32,926 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:32,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:32,943 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:32,972 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Working directory for job is: /galaxy/server/database/jobs_directory/000/180
galaxy.jobs.runners DEBUG 2024-11-03 06:49:32,978 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [180] queued (47.448 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:32,981 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:32,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 180
tpv.core.entities DEBUG 2024-11-03 06:49:33,001 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:33,001 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:33,006 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:33,017 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:33,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [179] prepared (111.542 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:33,054 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Working directory for job is: /galaxy/server/database/jobs_directory/000/181
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,061 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [181] queued (55.201 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:33,064 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,071 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 181
galaxy.jobs.command_factory INFO 2024-11-03 06:49:33,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/179/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/179/registry.xml' '/galaxy/server/database/jobs_directory/000/179/upload_params.json' '254:/galaxy/server/database/objects/7/6/f/dataset_76fbef73-5612-44c1-a1aa-4cf6f41fa0b1_files:/galaxy/server/database/objects/7/6/f/dataset_76fbef73-5612-44c1-a1aa-4cf6f41fa0b1.dat']
tpv.core.entities DEBUG 2024-11-03 06:49:33,079 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:33,082 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:33,087 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,095 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (179) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/179/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/179/galaxy_179.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:49:33,103 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:33,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [180] prepared (111.625 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:33,146 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Working directory for job is: /galaxy/server/database/jobs_directory/000/182
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,152 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,156 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [182] queued (69.067 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:33,158 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-03 06:49:33,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/180/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/180/registry.xml' '/galaxy/server/database/jobs_directory/000/180/upload_params.json' '255:/galaxy/server/database/objects/7/2/c/dataset_72cfa101-1bdf-4877-95d0-f7d139635162_files:/galaxy/server/database/objects/7/2/c/dataset_72cfa101-1bdf-4877-95d0-f7d139635162.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 182
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (180) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/180/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/180/galaxy_180.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-03 06:49:33,187 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:33,188 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:33,194 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:33,212 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:33,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [181] prepared (153.691 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:33,260 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Working directory for job is: /galaxy/server/database/jobs_directory/000/183
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,268 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [183] queued (74.099 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:33,271 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-03 06:49:33,272 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/181/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/181/registry.xml' '/galaxy/server/database/jobs_directory/000/181/upload_params.json' '256:/galaxy/server/database/objects/f/9/2/dataset_f92904de-89d3-4c68-b8c2-7a2ada2489e5_files:/galaxy/server/database/objects/f/9/2/dataset_f92904de-89d3-4c68-b8c2-7a2ada2489e5.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,274 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 183
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,282 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (181) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/181/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/181/galaxy_181.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:33,313 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [182] prepared (131.724 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:33,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/182/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/182/registry.xml' '/galaxy/server/database/jobs_directory/000/182/upload_params.json' '257:/galaxy/server/database/objects/7/5/c/dataset_75c0e1ed-64f4-4609-9cd1-8f6f7bde8781_files:/galaxy/server/database/objects/7/5/c/dataset_75c0e1ed-64f4-4609-9cd1-8f6f7bde8781.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (182) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/182/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/182/galaxy_182.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:49:33,379 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [183] prepared (93.737 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:33,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/183/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/183/registry.xml' '/galaxy/server/database/jobs_directory/000/183/upload_params.json' '258:/galaxy/server/database/objects/c/0/7/dataset_c073076f-b021-41f6-8e28-e93a763070c6_files:/galaxy/server/database/objects/c/0/7/dataset_c073076f-b021-41f6-8e28-e93a763070c6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:33,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (183) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/183/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/183/galaxy_183.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,859 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:33,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:34,087 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:34,177 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-03 06:49:38,355 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 184
tpv.core.entities DEBUG 2024-11-03 06:49:38,383 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:38,383 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:38,388 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:38,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:38,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Working directory for job is: /galaxy/server/database/jobs_directory/000/184
galaxy.jobs.runners DEBUG 2024-11-03 06:49:38,422 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [184] queued (33.049 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:38,425 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:38,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 184
galaxy.jobs DEBUG 2024-11-03 06:49:38,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [184] prepared (114.431 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:38,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/184/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/184/registry.xml' '/galaxy/server/database/jobs_directory/000/184/upload_params.json' '259:/galaxy/server/database/objects/1/c/1/dataset_1c109fa8-a832-4dfc-961c-77878033d1e8_files:/galaxy/server/database/objects/1/c/1/dataset_1c109fa8-a832-4dfc-961c-77878033d1e8.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:38,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (184) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/184/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/184/galaxy_184.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:38,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:38,654 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:39,429 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 186, 185, 187
tpv.core.entities DEBUG 2024-11-03 06:49:39,456 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:39,456 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:39,460 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:39,470 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:39,485 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Working directory for job is: /galaxy/server/database/jobs_directory/000/185
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,492 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [185] queued (32.252 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:39,495 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 185
tpv.core.entities DEBUG 2024-11-03 06:49:39,510 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:39,510 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:39,515 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:39,526 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:39,549 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Working directory for job is: /galaxy/server/database/jobs_directory/000/186
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,557 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [186] queued (41.467 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:39,559 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 186
tpv.core.entities DEBUG 2024-11-03 06:49:39,579 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:39,579 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:39,585 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:39,604 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:39,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [185] prepared (117.229 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:39,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Working directory for job is: /galaxy/server/database/jobs_directory/000/187
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,665 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [187] queued (80.279 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:39,672 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 187
galaxy.jobs.command_factory INFO 2024-11-03 06:49:39,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/185/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/185/registry.xml' '/galaxy/server/database/jobs_directory/000/185/upload_params.json' '260:/galaxy/server/database/objects/4/b/1/dataset_4b196f0c-f719-48b6-a1d5-0f72113719d8_files:/galaxy/server/database/objects/4/b/1/dataset_4b196f0c-f719-48b6-a1d5-0f72113719d8.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,699 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (185) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/185/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/185/galaxy_185.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:39,750 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [186] prepared (168.740 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:39,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/186/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/186/registry.xml' '/galaxy/server/database/jobs_directory/000/186/upload_params.json' '261:/galaxy/server/database/objects/d/2/1/dataset_d219d148-6a70-4fad-b03b-1d8bff1c6d17_files:/galaxy/server/database/objects/d/2/1/dataset_d219d148-6a70-4fad-b03b-1d8bff1c6d17.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (186) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/186/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/186/galaxy_186.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-03 06:49:39,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [187] prepared (139.008 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:39,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/187/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/187/registry.xml' '/galaxy/server/database/jobs_directory/000/187/upload_params.json' '262:/galaxy/server/database/objects/7/d/f/dataset_7dfecab8-f882-4f25-99eb-6e0d260b2b74_files:/galaxy/server/database/objects/7/d/f/dataset_7dfecab8-f882-4f25-99eb-6e0d260b2b74.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:39,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (187) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/187/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/187/galaxy_187.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:39,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:40,677 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 190, 192, 191, 188, 193, 189
tpv.core.entities DEBUG 2024-11-03 06:49:40,706 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:40,706 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:40,711 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:40,723 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:40,739 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Working directory for job is: /galaxy/server/database/jobs_directory/000/188
galaxy.jobs.runners DEBUG 2024-11-03 06:49:40,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [188] queued (34.684 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:40,748 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:40,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 188
tpv.core.entities DEBUG 2024-11-03 06:49:40,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:40,764 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:40,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:40,784 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:40,808 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Working directory for job is: /galaxy/server/database/jobs_directory/000/189
galaxy.jobs.runners DEBUG 2024-11-03 06:49:40,816 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [189] queued (47.402 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:40,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:40,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 189
tpv.core.entities DEBUG 2024-11-03 06:49:40,828 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:40,829 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:40,833 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:40,848 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:40,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [188] prepared (99.449 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:40,900 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Working directory for job is: /galaxy/server/database/jobs_directory/000/190
galaxy.jobs.runners DEBUG 2024-11-03 06:49:40,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [190] queued (79.963 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:40,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/188/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/188/registry.xml' '/galaxy/server/database/jobs_directory/000/188/upload_params.json' '263:/galaxy/server/database/objects/b/7/2/dataset_b72a8b96-772c-47a7-ac7b-7727cd0ff5a9_files:/galaxy/server/database/objects/b/7/2/dataset_b72a8b96-772c-47a7-ac7b-7727cd0ff5a9.dat']
galaxy.jobs.handler INFO 2024-11-03 06:49:40,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:40,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 190
galaxy.jobs.runners DEBUG 2024-11-03 06:49:40,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (188) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/188/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/188/galaxy_188.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-03 06:49:40,965 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:40,966 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:40,971 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:40,998 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,007 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:41,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [189] prepared (182.590 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:41,078 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Working directory for job is: /galaxy/server/database/jobs_directory/000/191
galaxy.jobs.command_factory INFO 2024-11-03 06:49:41,082 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/189/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/189/registry.xml' '/galaxy/server/database/jobs_directory/000/189/upload_params.json' '264:/galaxy/server/database/objects/0/c/b/dataset_0cb96097-7c7a-454a-940a-2528ad927160_files:/galaxy/server/database/objects/0/c/b/dataset_0cb96097-7c7a-454a-940a-2528ad927160.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,090 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [191] queued (118.866 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:41,098 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/189/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/189/galaxy_189.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,112 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 191
tpv.core.entities DEBUG 2024-11-03 06:49:41,121 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:41,122 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:41,126 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,146 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-03 06:49:41,159 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:41,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [190] prepared (216.551 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:41,208 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Working directory for job is: /galaxy/server/database/jobs_directory/000/192
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,215 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [192] queued (88.833 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:41,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/190/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/190/registry.xml' '/galaxy/server/database/jobs_directory/000/190/upload_params.json' '265:/galaxy/server/database/objects/a/9/f/dataset_a9f970f2-90e4-4998-b6a0-db6191bf4732_files:/galaxy/server/database/objects/a/9/f/dataset_a9f970f2-90e4-4998-b6a0-db6191bf4732.dat']
galaxy.jobs.handler INFO 2024-11-03 06:49:41,223 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 192
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,237 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (190) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/190/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/190/galaxy_190.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-03 06:49:41,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:41,260 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:41,266 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:41,286 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:41,333 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [191] prepared (200.646 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:41,353 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Working directory for job is: /galaxy/server/database/jobs_directory/000/193
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,361 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [193] queued (94.969 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:41,365 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 193
galaxy.jobs.command_factory INFO 2024-11-03 06:49:41,376 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/191/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/191/registry.xml' '/galaxy/server/database/jobs_directory/000/191/upload_params.json' '266:/galaxy/server/database/objects/c/2/8/dataset_c28412a1-10c5-42a7-983e-77abc7dbdab9_files:/galaxy/server/database/objects/c/2/8/dataset_c28412a1-10c5-42a7-983e-77abc7dbdab9.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (191) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/191/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/191/galaxy_191.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:49:41,407 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [192] prepared (145.740 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-03 06:49:41,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/192/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/192/registry.xml' '/galaxy/server/database/jobs_directory/000/192/upload_params.json' '267:/galaxy/server/database/objects/e/a/0/dataset_ea03441d-1017-4c97-bf7e-2152b4044e50_files:/galaxy/server/database/objects/e/a/0/dataset_ea03441d-1017-4c97-bf7e-2152b4044e50.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,460 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,483 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (192) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/192/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/192/galaxy_192.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:41,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [193] prepared (126.145 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:41,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/193/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/193/registry.xml' '/galaxy/server/database/jobs_directory/000/193/upload_params.json' '268:/galaxy/server/database/objects/7/5/2/dataset_7524222a-28d0-4f60-9eb5-6a9262d09258_files:/galaxy/server/database/objects/7/5/2/dataset_7524222a-28d0-4f60-9eb5-6a9262d09258.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:49:41,543 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (193) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/193/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/193/galaxy_193.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:41,568 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,371 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 197, 199, 198, 196, 195, 194, 200
tpv.core.entities DEBUG 2024-11-03 06:49:42,399 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:42,399 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,403 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:42,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:42,424 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Working directory for job is: /galaxy/server/database/jobs_directory/000/194
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [194] queued (27.904 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:42,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,437 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 194
tpv.core.entities DEBUG 2024-11-03 06:49:42,445 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:42,445 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,450 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:42,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:42,493 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Working directory for job is: /galaxy/server/database/jobs_directory/000/195
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,505 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [195] queued (54.683 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hc87f with k8s id: gxy-hc87f succeeded
galaxy.jobs.handler INFO 2024-11-03 06:49:42,509 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 195
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-s8shk with k8s id: gxy-s8shk succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cmfdh with k8s id: gxy-cmfdh succeeded
tpv.core.entities DEBUG 2024-11-03 06:49:42,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:42,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,569 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:42,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:42,645 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [194] prepared (196.788 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:42,681 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Working directory for job is: /galaxy/server/database/jobs_directory/000/196
galaxy.jobs.command_factory INFO 2024-11-03 06:49:42,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/194/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/194/registry.xml' '/galaxy/server/database/jobs_directory/000/194/upload_params.json' '269:/galaxy/server/database/objects/6/c/9/dataset_6c946566-b7d8-42f7-8d5c-385afeb2feaf_files:/galaxy/server/database/objects/6/c/9/dataset_6c946566-b7d8-42f7-8d5c-385afeb2feaf.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,699 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [196] queued (129.963 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:42,703 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (194) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/194/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/194/galaxy_194.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-03 06:49:42,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:42,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:42,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [195] prepared (218.294 ms)
galaxy.jobs DEBUG 2024-11-03 06:49:42,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,805 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:49:42,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/195/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/195/registry.xml' '/galaxy/server/database/jobs_directory/000/195/upload_params.json' '270:/galaxy/server/database/objects/0/e/2/dataset_0e2e1250-3e81-4ca1-98c7-b6f74aef0731_files:/galaxy/server/database/objects/0/e/2/dataset_0e2e1250-3e81-4ca1-98c7-b6f74aef0731.dat']
galaxy.jobs DEBUG 2024-11-03 06:49:42,829 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Working directory for job is: /galaxy/server/database/jobs_directory/000/197
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,840 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [197] queued (93.489 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:42,843 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,888 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (195) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/195/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/195/galaxy_195.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-03 06:49:42,891 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:42,895 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:42,905 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-03 06:49:42,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 176: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 195 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:42,969 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:42,980 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 195 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:43,004 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Working directory for job is: /galaxy/server/database/jobs_directory/000/198
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 177: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,038 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [198] queued (132.308 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:43,042 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Job dispatched
tpv.core.entities DEBUG 2024-11-03 06:49:43,065 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:43,066 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:43,096 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-03 06:49:43,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:43,138 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Working directory for job is: /galaxy/server/database/jobs_directory/000/199
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,144 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [199] queued (48.370 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:43,150 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 196
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 178: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,223 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
tpv.core.entities DEBUG 2024-11-03 06:49:43,227 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:43,228 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:43,239 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:43,312 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-03 06:49:43,404 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Working directory for job is: /galaxy/server/database/jobs_directory/000/200
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,418 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [200] queued (178.442 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:43,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Job dispatched
galaxy.jobs DEBUG 2024-11-03 06:49:43,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [196] prepared (227.260 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-03 06:49:43,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/196/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/196/registry.xml' '/galaxy/server/database/jobs_directory/000/196/upload_params.json' '271:/galaxy/server/database/objects/f/9/4/dataset_f940bbaa-9a7d-4fa8-abbb-cc81b3495ead_files:/galaxy/server/database/objects/f/9/4/dataset_f940bbaa-9a7d-4fa8-abbb-cc81b3495ead.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (196) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/196/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/196/galaxy_196.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 196 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,633 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 196 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 197
galaxy.jobs DEBUG 2024-11-03 06:49:43,842 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [197] prepared (131.707 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:43,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/197/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/197/registry.xml' '/galaxy/server/database/jobs_directory/000/197/upload_params.json' '272:/galaxy/server/database/objects/e/2/7/dataset_e27d9a1d-9f0f-46ea-9c1d-88426709d96c_files:/galaxy/server/database/objects/e/2/7/dataset_e27d9a1d-9f0f-46ea-9c1d-88426709d96c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:43,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (197) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/197/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/197/galaxy_197.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:43,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 197 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 197 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 198
galaxy.jobs DEBUG 2024-11-03 06:49:44,217 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [198] prepared (169.161 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:44,240 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/198/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/198/registry.xml' '/galaxy/server/database/jobs_directory/000/198/upload_params.json' '273:/galaxy/server/database/objects/3/9/f/dataset_39f4952d-abbd-497a-b997-031a45e346f5_files:/galaxy/server/database/objects/3/9/f/dataset_39f4952d-abbd-497a-b997-031a45e346f5.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:44,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (198) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/198/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/198/galaxy_198.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:49:44,424 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 202, 205, 204, 203, 201
tpv.core.entities DEBUG 2024-11-03 06:49:44,494 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:44,495 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:44,500 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:44,513 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 199
galaxy.jobs DEBUG 2024-11-03 06:49:44,532 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Working directory for job is: /galaxy/server/database/jobs_directory/000/201
galaxy.jobs.runners DEBUG 2024-11-03 06:49:44,539 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [201] queued (37.947 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:44,541 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Job dispatched
tpv.core.entities DEBUG 2024-11-03 06:49:44,605 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:44,606 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Mapped job to destination id: k8s
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n8q8p with k8s id: gxy-n8q8p succeeded
galaxy.jobs.handler DEBUG 2024-11-03 06:49:44,616 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qrn2l with k8s id: gxy-qrn2l succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sxh7s with k8s id: gxy-sxh7s succeeded
galaxy.jobs DEBUG 2024-11-03 06:49:44,709 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:44,797 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Working directory for job is: /galaxy/server/database/jobs_directory/000/202
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cpwhw with k8s id: gxy-cpwhw succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:49:44,810 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [202] queued (194.495 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:44,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g22dj with k8s id: gxy-g22dj succeeded
galaxy.jobs.handler INFO 2024-11-03 06:49:44,828 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Job dispatched
tpv.core.entities DEBUG 2024-11-03 06:49:44,850 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:44,894 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:44,901 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:44,916 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:44,947 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Working directory for job is: /galaxy/server/database/jobs_directory/000/203
galaxy.jobs DEBUG 2024-11-03 06:49:44,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [199] prepared (405.387 ms)
galaxy.jobs.runners DEBUG 2024-11-03 06:49:44,996 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [203] queued (94.959 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:45,001 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Job dispatched
tpv.core.entities DEBUG 2024-11-03 06:49:45,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:45,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:45,023 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Dispatching to k8s runner
galaxy.jobs.command_factory INFO 2024-11-03 06:49:45,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/199/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/199/registry.xml' '/galaxy/server/database/jobs_directory/000/199/upload_params.json' '274:/galaxy/server/database/objects/e/a/a/dataset_eaaa32ee-09c6-4738-984e-fd3f0dcb40a6_files:/galaxy/server/database/objects/e/a/a/dataset_eaaa32ee-09c6-4738-984e-fd3f0dcb40a6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:45,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (199) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/199/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/199/galaxy_199.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:49:45,036 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:45,102 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:49:45,111 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Working directory for job is: /galaxy/server/database/jobs_directory/000/204
galaxy.jobs.runners DEBUG 2024-11-03 06:49:45,121 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [204] queued (97.432 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:45,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler INFO 2024-11-03 06:49:45,126 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Job dispatched
tpv.core.entities DEBUG 2024-11-03 06:49:45,136 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:49:45,136 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:49:45,140 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:49:45,200 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:49:45,213 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Working directory for job is: /galaxy/server/database/jobs_directory/000/205
galaxy.jobs.runners DEBUG 2024-11-03 06:49:45,221 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [205] queued (80.283 ms)
galaxy.jobs.handler INFO 2024-11-03 06:49:45,223 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:45,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 200
galaxy.jobs DEBUG 2024-11-03 06:49:45,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [200] prepared (179.884 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:45,742 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/200/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/200/registry.xml' '/galaxy/server/database/jobs_directory/000/200/upload_params.json' '275:/galaxy/server/database/objects/3/c/1/dataset_3c1b7e3f-e041-4b82-b54c-8eed41d4b8b1_files:/galaxy/server/database/objects/3/c/1/dataset_3c1b7e3f-e041-4b82-b54c-8eed41d4b8b1.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:45,753 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (200) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/200/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/200/galaxy_200.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:45,796 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 200 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:45,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 200 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:46,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 201
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:46,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-03 06:49:46,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [201] prepared (196.738 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:49:46,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/201/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/201/registry.xml' '/galaxy/server/database/jobs_directory/000/201/upload_params.json' '276:/galaxy/server/database/objects/9/1/5/dataset_91596963-80ee-4e92-ab1d-dcef7cb2a1f6_files:/galaxy/server/database/objects/9/1/5/dataset_91596963-80ee-4e92-ab1d-dcef7cb2a1f6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:49:46,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (201) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/201/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/201/galaxy_201.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:46,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 201 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:46,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 201 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:46,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:47,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:47,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-03 06:49:47,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 179: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:47,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:49,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bmvms with k8s id: gxy-bmvms  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:49,314 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6h7jz with k8s id: gxy-6h7jz  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:49,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wj6mn with k8s id: gxy-wj6mn  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:50,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xtlvt with k8s id: gxy-xtlvt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:50,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bmvms with k8s id: gxy-bmvms  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:50,994 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6h7jz with k8s id: gxy-6h7jz  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:51,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:52,128 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jfj7x with k8s id: gxy-jfj7x succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:52,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cxk2j with k8s id: gxy-cxk2j succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:52,314 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tktpm with k8s id: gxy-tktpm succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:52,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:52,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:54,032 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-c5l9z with k8s id: gxy-c5l9z succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xv967 with k8s id: gxy-xv967 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,696 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rl7xv with k8s id: gxy-rl7xv succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6vhlh with k8s id: gxy-6vhlh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,729 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2sz2z with k8s id: gxy-2sz2z succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,796 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vbf6q with k8s id: gxy-vbf6q succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,806 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bd825 with k8s id: gxy-bd825 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:55,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7r5sx with k8s id: gxy-7r5sx succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:57,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7nq9r with k8s id: gxy-7nq9r succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:57,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zz8h6 with k8s id: gxy-zz8h6 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:49:58,128 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g5zs7 with k8s id: gxy-g5zs7 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:50:01,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 176 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:01,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 251
galaxy.jobs INFO 2024-11-03 06:50:01,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 176 in /galaxy/server/database/jobs_directory/000/176
galaxy.jobs DEBUG 2024-11-03 06:50:01,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 176 executed (196.362 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:01,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 177 finished
galaxy.jobs.runners DEBUG 2024-11-03 06:50:01,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 178 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:01,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 252
galaxy.jobs.runners DEBUG 2024-11-03 06:50:01,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 180: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-03 06:50:01,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 253
galaxy.jobs INFO 2024-11-03 06:50:01,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 177 in /galaxy/server/database/jobs_directory/000/177
galaxy.jobs INFO 2024-11-03 06:50:01,756 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 178 in /galaxy/server/database/jobs_directory/000/178
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bmvms with k8s id: gxy-bmvms succeeded
galaxy.jobs DEBUG 2024-11-03 06:50:01,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 177 executed (209.344 ms)
galaxy.jobs DEBUG 2024-11-03 06:50:01,845 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 178 executed (178.072 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6h7jz failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:01,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:02,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-6h7jz.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:02,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 200 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-03 06:50:02,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-03-06-12-1/jobs/gxy-6h7jz

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-6h7jz": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners DEBUG 2024-11-03 06:50:02,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 181: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:02,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wj6mn with k8s id: gxy-wj6mn succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:50:02,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 182: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:03,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 179 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:03,929 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 254
galaxy.jobs INFO 2024-11-03 06:50:04,005 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 179 in /galaxy/server/database/jobs_directory/000/179
galaxy.jobs DEBUG 2024-11-03 06:50:04,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 179 executed (206.140 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:04,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:04,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 202
galaxy.jobs DEBUG 2024-11-03 06:50:04,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [202] prepared (315.865 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:50:04,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/202/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/202/registry.xml' '/galaxy/server/database/jobs_directory/000/202/upload_params.json' '277:/galaxy/server/database/objects/a/0/2/dataset_a021aa72-c3bd-47fb-ab44-6cfaa363f6b6_files:/galaxy/server/database/objects/a/0/2/dataset_a021aa72-c3bd-47fb-ab44-6cfaa363f6b6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:50:04,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (202) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/202/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/202/galaxy_202.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:04,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:04,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:04,892 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 183: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:05,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:13,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-p8vr9 with k8s id: gxy-p8vr9 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:50:16,095 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 180 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:16,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 255
galaxy.jobs INFO 2024-11-03 06:50:16,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 180 in /galaxy/server/database/jobs_directory/000/180
galaxy.jobs DEBUG 2024-11-03 06:50:16,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 180 executed (187.636 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 203
galaxy.jobs DEBUG 2024-11-03 06:50:16,598 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [203] prepared (162.565 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:50:16,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/203/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/203/registry.xml' '/galaxy/server/database/jobs_directory/000/203/upload_params.json' '278:/galaxy/server/database/objects/d/4/1/dataset_d419a49a-8031-4fed-bd62-21c6d78eebf8_files:/galaxy/server/database/objects/d/4/1/dataset_d419a49a-8031-4fed-bd62-21c6d78eebf8.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:50:16,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (203) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/203/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/203/galaxy_203.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 204
galaxy.jobs DEBUG 2024-11-03 06:50:16,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [204] prepared (158.565 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:50:16,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/204/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/204/registry.xml' '/galaxy/server/database/jobs_directory/000/204/upload_params.json' '279:/galaxy/server/database/objects/c/9/1/dataset_c9197faf-4b75-41da-8d53-0e03d61d66a1_files:/galaxy/server/database/objects/c/9/1/dataset_c9197faf-4b75-41da-8d53-0e03d61d66a1.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:50:16,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (204) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/204/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/204/galaxy_204.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:16,994 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 205
galaxy.jobs DEBUG 2024-11-03 06:50:17,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [205] prepared (161.217 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:50:17,223 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/205/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/205/registry.xml' '/galaxy/server/database/jobs_directory/000/205/upload_params.json' '280:/galaxy/server/database/objects/d/d/4/dataset_dd4e8e3d-b8d9-4b56-9a86-32f80d217d44_files:/galaxy/server/database/objects/d/d/4/dataset_dd4e8e3d-b8d9-4b56-9a86-32f80d217d44.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:50:17,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (205) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/205/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/205/galaxy_205.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-03 06:50:17,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 181 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 06:50:17,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 256
galaxy.jobs INFO 2024-11-03 06:50:17,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 181 in /galaxy/server/database/jobs_directory/000/181
galaxy.jobs DEBUG 2024-11-03 06:50:17,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 181 executed (146.864 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,497 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:17,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 182 finished
galaxy.jobs.runners DEBUG 2024-11-03 06:50:17,572 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 184: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-03 06:50:17,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 257
galaxy.jobs INFO 2024-11-03 06:50:17,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 182 in /galaxy/server/database/jobs_directory/000/182
galaxy.jobs DEBUG 2024-11-03 06:50:17,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 182 executed (190.851 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:17,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 185: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:17,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:18,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-03 06:50:18,198 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 186: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:20,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 183 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:20,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 258
galaxy.jobs INFO 2024-11-03 06:50:20,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 183 in /galaxy/server/database/jobs_directory/000/183
galaxy.jobs DEBUG 2024-11-03 06:50:20,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 183 executed (213.832 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:20,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:20,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 187: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:26,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lp8lg with k8s id: gxy-lp8lg succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:26,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l9jqk with k8s id: gxy-l9jqk succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:27,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9rjk7 with k8s id: gxy-9rjk7 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:50:33,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 184 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:33,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 259
galaxy.jobs INFO 2024-11-03 06:50:33,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 184 in /galaxy/server/database/jobs_directory/000/184
galaxy.jobs DEBUG 2024-11-03 06:50:33,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 184 executed (186.610 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:33,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:33,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 185 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:33,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 260
galaxy.jobs INFO 2024-11-03 06:50:33,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 185 in /galaxy/server/database/jobs_directory/000/185
galaxy.jobs DEBUG 2024-11-03 06:50:33,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 185 executed (136.260 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:33,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:33,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 186 finished
galaxy.jobs.runners DEBUG 2024-11-03 06:50:33,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 188: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-03 06:50:33,638 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 261
galaxy.jobs INFO 2024-11-03 06:50:33,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 186 in /galaxy/server/database/jobs_directory/000/186
galaxy.jobs DEBUG 2024-11-03 06:50:33,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 186 executed (194.169 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:33,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:33,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 189: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:34,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 190: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:35,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 187 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:35,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 262
galaxy.jobs INFO 2024-11-03 06:50:35,527 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 187 in /galaxy/server/database/jobs_directory/000/187
galaxy.jobs DEBUG 2024-11-03 06:50:35,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 187 executed (194.913 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:35,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:35,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 192: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:48,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 188 finished
galaxy.jobs.runners DEBUG 2024-11-03 06:50:48,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 189 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:48,711 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 263
galaxy.jobs INFO 2024-11-03 06:50:48,817 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 188 in /galaxy/server/database/jobs_directory/000/188
galaxy.model.metadata DEBUG 2024-11-03 06:50:48,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 264
galaxy.jobs INFO 2024-11-03 06:50:48,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 189 in /galaxy/server/database/jobs_directory/000/189
galaxy.jobs DEBUG 2024-11-03 06:50:49,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 188 executed (389.000 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:49,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:50:49,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 189 executed (312.618 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:49,096 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:49,147 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 190 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:49,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 265
galaxy.jobs INFO 2024-11-03 06:50:49,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 190 in /galaxy/server/database/jobs_directory/000/190
galaxy.jobs.runners DEBUG 2024-11-03 06:50:49,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 191: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-03 06:50:49,334 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 190 executed (158.705 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:49,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:49,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 193: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:49,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 194: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:50:50,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 192 finished
galaxy.model.metadata DEBUG 2024-11-03 06:50:50,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 267
galaxy.jobs INFO 2024-11-03 06:50:50,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 192 in /galaxy/server/database/jobs_directory/000/192
galaxy.jobs DEBUG 2024-11-03 06:50:51,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 192 executed (204.671 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:50:51,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:50:51,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 195: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:03,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 191 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:03,946 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 266
galaxy.jobs.runners DEBUG 2024-11-03 06:51:04,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 193 finished
galaxy.jobs INFO 2024-11-03 06:51:04,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 191 in /galaxy/server/database/jobs_directory/000/191
galaxy.model.metadata DEBUG 2024-11-03 06:51:04,051 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 268
galaxy.jobs INFO 2024-11-03 06:51:04,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 193 in /galaxy/server/database/jobs_directory/000/193
galaxy.jobs DEBUG 2024-11-03 06:51:04,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 191 executed (198.191 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:04,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:51:04,194 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 193 executed (160.513 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:04,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:04,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 194 finished
galaxy.jobs.runners DEBUG 2024-11-03 06:51:04,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 197: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-03 06:51:04,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 269
galaxy.jobs INFO 2024-11-03 06:51:04,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 194 in /galaxy/server/database/jobs_directory/000/194
galaxy.jobs.runners DEBUG 2024-11-03 06:51:04,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 198: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-03 06:51:04,562 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 194 executed (166.975 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:04,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:04,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 196: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:05,834 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 195 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:05,929 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 270
galaxy.jobs INFO 2024-11-03 06:51:06,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 195 in /galaxy/server/database/jobs_directory/000/195
galaxy.jobs DEBUG 2024-11-03 06:51:06,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 195 executed (141.442 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:06,098 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 195 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:06,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 199: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:19,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 197 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:19,327 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 272
galaxy.jobs INFO 2024-11-03 06:51:19,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 197 in /galaxy/server/database/jobs_directory/000/197
galaxy.jobs DEBUG 2024-11-03 06:51:19,498 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 197 executed (190.832 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:19,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 197 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:19,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 198 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:19,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 273
galaxy.jobs INFO 2024-11-03 06:51:19,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 198 in /galaxy/server/database/jobs_directory/000/198
galaxy.jobs.runners DEBUG 2024-11-03 06:51:19,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 201: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:19,835 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 196 finished
galaxy.jobs DEBUG 2024-11-03 06:51:19,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 198 executed (144.487 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:19,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 06:51:19,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 271
galaxy.jobs INFO 2024-11-03 06:51:19,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 196 in /galaxy/server/database/jobs_directory/000/196
galaxy.jobs DEBUG 2024-11-03 06:51:20,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 196 executed (189.398 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:20,060 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 196 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:20,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 202: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:20,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 203: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:21,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 199 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:21,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 274
galaxy.jobs INFO 2024-11-03 06:51:21,328 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 199 in /galaxy/server/database/jobs_directory/000/199
galaxy.jobs DEBUG 2024-11-03 06:51:21,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 199 executed (183.951 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:21,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:21,711 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 204: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:34,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 201 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:34,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 276
galaxy.jobs INFO 2024-11-03 06:51:34,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 201 in /galaxy/server/database/jobs_directory/000/201
galaxy.jobs DEBUG 2024-11-03 06:51:34,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 201 executed (129.749 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-03 06:51:34,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] No k8s job found which matches job id 'gxy-wj6mn'. Ignoring...
galaxy.jobs.runners DEBUG 2024-11-03 06:51:34,742 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 205: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:34,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 202 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:34,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 277
galaxy.jobs INFO 2024-11-03 06:51:35,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 202 in /galaxy/server/database/jobs_directory/000/202
galaxy.jobs.runners DEBUG 2024-11-03 06:51:35,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 203 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:35,113 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 278
galaxy.jobs DEBUG 2024-11-03 06:51:35,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 202 executed (199.755 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-03 06:51:35,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 203 in /galaxy/server/database/jobs_directory/000/203
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,212 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (200/gxy-6h7jz) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (200/gxy-6h7jz) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (200/gxy-6h7jz) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (200/gxy-6h7jz) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-6h7jz.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 200 (gxy-6h7jz)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Could not find job with id gxy-6h7jz to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (200/gxy-6h7jz) Terminated at user's request
galaxy.jobs DEBUG 2024-11-03 06:51:35,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 203 executed (187.803 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:35,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:51:35,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 204 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:35,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 279
galaxy.jobs INFO 2024-11-03 06:51:35,982 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 204 in /galaxy/server/database/jobs_directory/000/204
galaxy.jobs DEBUG 2024-11-03 06:51:36,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 204 executed (96.972 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:36,040 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:51:36,841 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 207, 206
tpv.core.entities DEBUG 2024-11-03 06:51:36,864 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:51:36,865 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:51:36,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:51:36,879 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:51:36,894 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Working directory for job is: /galaxy/server/database/jobs_directory/000/206
galaxy.jobs.runners DEBUG 2024-11-03 06:51:36,901 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [206] queued (32.557 ms)
galaxy.jobs.handler INFO 2024-11-03 06:51:36,903 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:36,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 206
tpv.core.entities DEBUG 2024-11-03 06:51:36,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:51:36,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:51:36,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:51:36,927 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:51:36,954 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Working directory for job is: /galaxy/server/database/jobs_directory/000/207
galaxy.jobs.runners DEBUG 2024-11-03 06:51:36,960 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [207] queued (42.819 ms)
galaxy.jobs.handler INFO 2024-11-03 06:51:36,963 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:36,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 207
galaxy.jobs DEBUG 2024-11-03 06:51:37,008 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [206] prepared (91.250 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:51:37,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/206/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/206/registry.xml' '/galaxy/server/database/jobs_directory/000/206/upload_params.json' '281:/galaxy/server/database/objects/0/5/b/dataset_05bfd4fe-ea80-41d2-b7c4-0daf1f9212dc_files:/galaxy/server/database/objects/0/5/b/dataset_05bfd4fe-ea80-41d2-b7c4-0daf1f9212dc.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:51:37,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (206) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/206/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/206/galaxy_206.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:51:37,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [207] prepared (78.601 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:37,059 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:37,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:51:37,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/207/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/207/registry.xml' '/galaxy/server/database/jobs_directory/000/207/upload_params.json' '282:/galaxy/server/database/objects/8/9/a/dataset_89a1a65b-090d-42fc-bb7c-b0624abed662_files:/galaxy/server/database/objects/8/9/a/dataset_89a1a65b-090d-42fc-bb7c-b0624abed662.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:51:37,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (207) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/207/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/207/galaxy_207.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:37,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:37,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:38,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:38,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-03 06:51:42,230 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 205 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:42,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 280
galaxy.jobs INFO 2024-11-03 06:51:42,287 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 205 in /galaxy/server/database/jobs_directory/000/205
galaxy.jobs DEBUG 2024-11-03 06:51:42,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 205 executed (82.748 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:42,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:47,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-h48qt with k8s id: gxy-h48qt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:47,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kvwzj with k8s id: gxy-kvwzj succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:51:47,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 206: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:47,528 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 207: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:51:54,967 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 206 finished
galaxy.model.metadata DEBUG 2024-11-03 06:51:55,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 281
galaxy.jobs INFO 2024-11-03 06:51:55,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 206 in /galaxy/server/database/jobs_directory/000/206
galaxy.jobs DEBUG 2024-11-03 06:51:55,084 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 206 executed (94.477 ms)
galaxy.jobs.runners DEBUG 2024-11-03 06:51:55,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 207 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:55,097 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 06:51:55,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 282
galaxy.jobs INFO 2024-11-03 06:51:55,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 207 in /galaxy/server/database/jobs_directory/000/207
galaxy.jobs DEBUG 2024-11-03 06:51:55,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 207 executed (88.292 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:55,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:51:56,263 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 208
tpv.core.entities DEBUG 2024-11-03 06:51:56,289 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:51:56,289 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:51:56,292 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:51:56,301 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:51:56,313 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Working directory for job is: /galaxy/server/database/jobs_directory/000/208
galaxy.jobs.runners DEBUG 2024-11-03 06:51:56,320 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [208] queued (27.890 ms)
galaxy.jobs.handler INFO 2024-11-03 06:51:56,322 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:56,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 208
galaxy.jobs DEBUG 2024-11-03 06:51:56,385 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [208] prepared (53.338 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:51:56,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:51:56,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:51:56,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:51:56,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/208/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/208/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/custom_content_0 &&  ln -s '/galaxy/server/database/objects/0/5/b/dataset_05bfd4fe-ea80-41d2-b7c4-0daf1f9212dc.dat' 'multiqc_WDir/custom_content_0/file_0_0' && more /galaxy/server/database/objects/0/5/b/dataset_05bfd4fe-ea80-41d2-b7c4-0daf1f9212dc.dat && ln -s '/galaxy/server/database/objects/8/9/a/dataset_89a1a65b-090d-42fc-bb7c-b0624abed662.dat' 'multiqc_WDir/custom_content_0/file_0_1' && more /galaxy/server/database/objects/8/9/a/dataset_89a1a65b-090d-42fc-bb7c-b0624abed662.dat &&  multiqc multiqc_WDir --filename "report"      --config '/galaxy/server/database/jobs_directory/000/208/configs/tmp8gitp57j']
galaxy.jobs.runners DEBUG 2024-11-03 06:51:56,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (208) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/208/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/208/galaxy_208.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/208/working/report.html" -a -f "/galaxy/server/database/objects/3/5/3/dataset_3533ee0a-ed15-490a-98b9-6218b9724328.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/208/working/report.html" "/galaxy/server/database/objects/3/5/3/dataset_3533ee0a-ed15-490a-98b9-6218b9724328.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:56,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:51:56,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:51:56,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:51:56,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:56,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:51:57,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:04,575 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9fwlh with k8s id: gxy-9fwlh succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:52:04,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 208: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:52:11,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 208 finished
galaxy.model.store.discover DEBUG 2024-11-03 06:52:11,847 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (208) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/208/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (3.736 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:52:11,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (208) Add dynamic collection datasets to history for output [stats] (14.177 ms)
galaxy.model.metadata DEBUG 2024-11-03 06:52:11,874 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 283
galaxy.jobs INFO 2024-11-03 06:52:11,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 208 in /galaxy/server/database/jobs_directory/000/208
galaxy.jobs DEBUG 2024-11-03 06:52:11,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 208 executed (107.587 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:11,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:52:13,608 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 210, 209
tpv.core.entities DEBUG 2024-11-03 06:52:13,629 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:52:13,630 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:52:13,633 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:52:13,642 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:52:13,653 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Working directory for job is: /galaxy/server/database/jobs_directory/000/209
galaxy.jobs.runners DEBUG 2024-11-03 06:52:13,660 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [209] queued (27.285 ms)
galaxy.jobs.handler INFO 2024-11-03 06:52:13,662 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 209
tpv.core.entities DEBUG 2024-11-03 06:52:13,672 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:52:13,672 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:52:13,676 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:52:13,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:52:13,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Working directory for job is: /galaxy/server/database/jobs_directory/000/210
galaxy.jobs.runners DEBUG 2024-11-03 06:52:13,719 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [210] queued (42.581 ms)
galaxy.jobs.handler INFO 2024-11-03 06:52:13,722 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 210
galaxy.jobs DEBUG 2024-11-03 06:52:13,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [209] prepared (88.175 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:52:13,783 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/209/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/209/registry.xml' '/galaxy/server/database/jobs_directory/000/209/upload_params.json' '285:/galaxy/server/database/objects/a/0/0/dataset_a0044117-0ebc-4d51-a58e-254f4c93a413_files:/galaxy/server/database/objects/a/0/0/dataset_a0044117-0ebc-4d51-a58e-254f4c93a413.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:52:13,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (209) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/209/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/209/galaxy_209.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:52:13,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [210] prepared (69.961 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,806 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:52:13,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/210/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/210/registry.xml' '/galaxy/server/database/jobs_directory/000/210/upload_params.json' '286:/galaxy/server/database/objects/8/0/7/dataset_80711ef4-774d-49db-9ac2-5ac0295607a6_files:/galaxy/server/database/objects/8/0/7/dataset_80711ef4-774d-49db-9ac2-5ac0295607a6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:52:13,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (210) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/210/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/210/galaxy_210.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:13,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:14,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:14,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,876 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n7m4z failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,878 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-n7m4z.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-03 06:52:22,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-03-06-12-1/jobs/gxy-n7m4z

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-n7m4z": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (210/gxy-n7m4z) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (210/gxy-n7m4z) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (210/gxy-n7m4z) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (210/gxy-n7m4z) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-n7m4z.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 210 (gxy-n7m4z)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-n7m4z to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:22,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:23,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (210/gxy-n7m4z) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:23,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cbk5m with k8s id: gxy-cbk5m succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:52:24,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 209: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:52:31,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 209 finished
galaxy.model.metadata DEBUG 2024-11-03 06:52:31,171 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 285
galaxy.jobs INFO 2024-11-03 06:52:31,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 209 in /galaxy/server/database/jobs_directory/000/209
galaxy.jobs DEBUG 2024-11-03 06:52:31,254 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 209 executed (104.267 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:31,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:52:32,021 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 211
tpv.core.entities DEBUG 2024-11-03 06:52:32,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:52:32,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:52:32,049 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:52:32,059 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:52:32,073 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Working directory for job is: /galaxy/server/database/jobs_directory/000/211
galaxy.jobs.runners DEBUG 2024-11-03 06:52:32,080 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [211] queued (31.467 ms)
galaxy.jobs.handler INFO 2024-11-03 06:52:32,082 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:32,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 211
galaxy.jobs DEBUG 2024-11-03 06:52:32,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [211] prepared (71.084 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:52:32,185 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/211/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/211/registry.xml' '/galaxy/server/database/jobs_directory/000/211/upload_params.json' '287:/galaxy/server/database/objects/c/0/c/dataset_c0c53c6c-3650-48bb-8061-0dc2e3f2807c_files:/galaxy/server/database/objects/c/0/c/dataset_c0c53c6c-3650-48bb-8061-0dc2e3f2807c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:52:32,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (211) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/211/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/211/galaxy_211.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:32,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:32,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:32,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:41,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-277xz with k8s id: gxy-277xz succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:52:41,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 211: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:52:48,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 211 finished
galaxy.model.metadata DEBUG 2024-11-03 06:52:48,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 287
galaxy.jobs INFO 2024-11-03 06:52:48,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 211 in /galaxy/server/database/jobs_directory/000/211
galaxy.jobs DEBUG 2024-11-03 06:52:48,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 211 executed (112.149 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:48,388 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:52:49,360 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 212
tpv.core.entities DEBUG 2024-11-03 06:52:49,383 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:52:49,383 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:52:49,386 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:52:49,395 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:52:49,407 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Working directory for job is: /galaxy/server/database/jobs_directory/000/212
galaxy.jobs.runners DEBUG 2024-11-03 06:52:49,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [212] queued (27.562 ms)
galaxy.jobs.handler INFO 2024-11-03 06:52:49,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:49,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 212
galaxy.jobs DEBUG 2024-11-03 06:52:49,469 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [212] prepared (45.903 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:52:49,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:52:49,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:52:49,489 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:52:49,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/212/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/212/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/pycoqc_0 &&         grep -q '"pycoqc":' /galaxy/server/database/objects/c/0/c/dataset_c0c53c6c-3650-48bb-8061-0dc2e3f2807c.dat || die "Module 'pycoqc: '"pycoqc":' not found in the file 'pycoqc_json'" && ln -s '/galaxy/server/database/objects/c/0/c/dataset_c0c53c6c-3650-48bb-8061-0dc2e3f2807c.dat' 'multiqc_WDir/pycoqc_0/pycoqc_json'  &&    multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"]
galaxy.jobs.runners DEBUG 2024-11-03 06:52:49,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (212) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/212/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/212/galaxy_212.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/212/working/report.html" -a -f "/galaxy/server/database/objects/a/d/a/dataset_ada12914-8330-4cff-8c10-2da03b91e697.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/212/working/report.html" "/galaxy/server/database/objects/a/d/a/dataset_ada12914-8330-4cff-8c10-2da03b91e697.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:49,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:52:49,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:52:49,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:52:49,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:49,567 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:50,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:52:57,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l7rsx with k8s id: gxy-l7rsx succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:52:57,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 212: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:53:04,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 212 finished
galaxy.model.store.discover DEBUG 2024-11-03 06:53:04,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (212) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/212/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (2.882 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:53:04,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (212) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/212/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.423 ms)
galaxy.model.store.discover DEBUG 2024-11-03 06:53:04,737 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (212) Add dynamic collection datasets to history for output [stats] (28.171 ms)
galaxy.model.metadata DEBUG 2024-11-03 06:53:04,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 288
galaxy.jobs INFO 2024-11-03 06:53:04,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 212 in /galaxy/server/database/jobs_directory/000/212
galaxy.jobs DEBUG 2024-11-03 06:53:04,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 212 executed (139.835 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:04,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:53:08,756 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 213
tpv.core.entities DEBUG 2024-11-03 06:53:08,782 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:53:08,782 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:53:08,786 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:53:08,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:53:08,808 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Working directory for job is: /galaxy/server/database/jobs_directory/000/213
galaxy.jobs.runners DEBUG 2024-11-03 06:53:08,816 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [213] queued (29.830 ms)
galaxy.jobs.handler INFO 2024-11-03 06:53:08,818 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:08,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 213
galaxy.jobs DEBUG 2024-11-03 06:53:08,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [213] prepared (69.468 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:53:08,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/213/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/213/registry.xml' '/galaxy/server/database/jobs_directory/000/213/upload_params.json' '291:/galaxy/server/database/objects/7/b/7/dataset_7b71e619-7d63-4217-9285-9e4a8153033c_files:/galaxy/server/database/objects/7/b/7/dataset_7b71e619-7d63-4217-9285-9e4a8153033c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:53:08,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (213) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/213/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/213/galaxy_213.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:08,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:08,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:09,256 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:18,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xcjt9 with k8s id: gxy-xcjt9 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:53:18,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 213: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:53:25,663 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 213 finished
galaxy.model.metadata DEBUG 2024-11-03 06:53:25,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 291
galaxy.jobs INFO 2024-11-03 06:53:25,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 213 in /galaxy/server/database/jobs_directory/000/213
galaxy.jobs DEBUG 2024-11-03 06:53:25,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 213 executed (88.807 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:25,788 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:53:26,091 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 214
tpv.core.entities DEBUG 2024-11-03 06:53:26,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:53:26,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:53:26,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:53:26,130 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:53:26,146 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Working directory for job is: /galaxy/server/database/jobs_directory/000/214
galaxy.jobs.runners DEBUG 2024-11-03 06:53:26,154 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [214] queued (34.221 ms)
galaxy.jobs.handler INFO 2024-11-03 06:53:26,156 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:26,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 214
galaxy.jobs DEBUG 2024-11-03 06:53:26,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [214] prepared (50.086 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:53:26,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:53:26,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:53:26,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:53:26,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/214/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/214/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/7/b/7/dataset_7b71e619-7d63-4217-9285-9e4a8153033c.dat' './read_0.fastq.gz' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --fastq_rich read_0.fastq.gz --downsample 800 --plots kde        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-03 06:53:26,464 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (214) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/214/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/214/galaxy_214.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/214/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/2/b/6/dataset_2b638569-7f71-4e42-badb-908f99c59647.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/214/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/2/b/6/dataset_2b638569-7f71-4e42-badb-908f99c59647.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/214/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/c/5/4/dataset_c540b56b-21ef-4f9c-9a1b-f994969767fa.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/214/working/NanoStats.txt" "/galaxy/server/database/objects/c/5/4/dataset_c540b56b-21ef-4f9c-9a1b-f994969767fa.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/214/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/9/d/6/dataset_9d6e6a85-ac1f-4e2d-96c2-5b6fa66c116e.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/214/working/NanoPlot-report.html" "/galaxy/server/database/objects/9/d/6/dataset_9d6e6a85-ac1f-4e2d-96c2-5b6fa66c116e.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:26,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:53:26,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:53:26,478 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:53:26,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:26,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:53:27,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:10,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9l27d with k8s id: gxy-9l27d succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:54:10,217 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 214: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:54:17,482 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 214 finished
galaxy.model.metadata DEBUG 2024-11-03 06:54:17,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 294
galaxy.model.metadata DEBUG 2024-11-03 06:54:17,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 293
galaxy.model.metadata DEBUG 2024-11-03 06:54:17,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 292
galaxy.util WARNING 2024-11-03 06:54:17,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/2/b/6/dataset_2b638569-7f71-4e42-badb-908f99c59647.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/2/b/6/dataset_2b638569-7f71-4e42-badb-908f99c59647.dat'
galaxy.util WARNING 2024-11-03 06:54:17,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/c/5/4/dataset_c540b56b-21ef-4f9c-9a1b-f994969767fa.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/c/5/4/dataset_c540b56b-21ef-4f9c-9a1b-f994969767fa.dat'
galaxy.util WARNING 2024-11-03 06:54:17,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/9/d/6/dataset_9d6e6a85-ac1f-4e2d-96c2-5b6fa66c116e.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/9/d/6/dataset_9d6e6a85-ac1f-4e2d-96c2-5b6fa66c116e.dat'
galaxy.jobs INFO 2024-11-03 06:54:17,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 214 in /galaxy/server/database/jobs_directory/000/214
galaxy.jobs DEBUG 2024-11-03 06:54:17,621 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 214 executed (119.652 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:17,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:54:21,040 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 215
tpv.core.entities DEBUG 2024-11-03 06:54:21,063 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:54:21,064 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:54:21,067 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:54:21,077 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:54:21,090 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Working directory for job is: /galaxy/server/database/jobs_directory/000/215
galaxy.jobs.runners DEBUG 2024-11-03 06:54:21,097 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [215] queued (30.181 ms)
galaxy.jobs.handler INFO 2024-11-03 06:54:21,100 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:21,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 215
galaxy.jobs DEBUG 2024-11-03 06:54:21,176 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [215] prepared (67.871 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:54:21,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/215/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/215/registry.xml' '/galaxy/server/database/jobs_directory/000/215/upload_params.json' '295:/galaxy/server/database/objects/1/1/d/dataset_11d14827-d06e-430d-b880-e9f0cb3c182d_files:/galaxy/server/database/objects/1/1/d/dataset_11d14827-d06e-430d-b880-e9f0cb3c182d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:54:21,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (215) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/215/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/215/galaxy_215.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:21,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:21,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:22,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:32,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4jfq7 with k8s id: gxy-4jfq7 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:54:32,392 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 215: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:54:39,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 215 finished
galaxy.model.metadata DEBUG 2024-11-03 06:54:39,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 295
galaxy.jobs INFO 2024-11-03 06:54:39,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 215 in /galaxy/server/database/jobs_directory/000/215
galaxy.jobs DEBUG 2024-11-03 06:54:39,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 215 executed (95.450 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:39,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:54:40,428 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 216
tpv.core.entities DEBUG 2024-11-03 06:54:40,449 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:54:40,450 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:54:40,452 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:54:40,461 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:54:40,477 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Working directory for job is: /galaxy/server/database/jobs_directory/000/216
galaxy.jobs.runners DEBUG 2024-11-03 06:54:40,484 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [216] queued (31.460 ms)
galaxy.jobs.handler INFO 2024-11-03 06:54:40,486 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:40,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 216
galaxy.jobs DEBUG 2024-11-03 06:54:40,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [216] prepared (45.689 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:54:40,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:54:40,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:54:40,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:54:40,584 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/216/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/216/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/1/1/d/dataset_11d14827-d06e-430d-b880-e9f0cb3c182d.dat' './read_0.bam' && ln -s '/galaxy/server/database/objects/_metadata_files/f/0/7/metadata_f079e151-58aa-4312-a271-66f7749d9c9c.dat' './read_0.bam.bai' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --bam read_0.bam --maxlength 2000 --color yellow        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-03 06:54:40,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (216) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/216/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/216/galaxy_216.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/216/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/a/6/4/dataset_a64f02e2-79ff-46e1-9cef-826fd2876f26.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/216/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/a/6/4/dataset_a64f02e2-79ff-46e1-9cef-826fd2876f26.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/216/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/b/d/a/dataset_bda312d4-abfa-42c9-a8e1-c41577dcbf07.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/216/working/NanoStats.txt" "/galaxy/server/database/objects/b/d/a/dataset_bda312d4-abfa-42c9-a8e1-c41577dcbf07.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/216/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/b/7/8/dataset_b788c1af-319b-4b8b-83fd-1de03a53156a.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/216/working/NanoPlot-report.html" "/galaxy/server/database/objects/b/7/8/dataset_b788c1af-319b-4b8b-83fd-1de03a53156a.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:40,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:54:40,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:54:40,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:54:40,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:40,652 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:41,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:51,567 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wtx9b with k8s id: gxy-wtx9b succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:54:51,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 216: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:54:58,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 216 finished
galaxy.model.metadata DEBUG 2024-11-03 06:54:58,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 298
galaxy.model.metadata DEBUG 2024-11-03 06:54:58,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 297
galaxy.model.metadata DEBUG 2024-11-03 06:54:58,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 296
galaxy.util WARNING 2024-11-03 06:54:58,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/b/d/a/dataset_bda312d4-abfa-42c9-a8e1-c41577dcbf07.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/b/d/a/dataset_bda312d4-abfa-42c9-a8e1-c41577dcbf07.dat'
galaxy.util WARNING 2024-11-03 06:54:58,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/b/7/8/dataset_b788c1af-319b-4b8b-83fd-1de03a53156a.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/b/7/8/dataset_b788c1af-319b-4b8b-83fd-1de03a53156a.dat'
galaxy.jobs INFO 2024-11-03 06:54:58,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 216 in /galaxy/server/database/jobs_directory/000/216
galaxy.jobs DEBUG 2024-11-03 06:54:59,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 216 executed (168.085 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:54:59,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:55:00,812 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 217, 218
tpv.core.entities DEBUG 2024-11-03 06:55:00,837 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:55:00,838 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:55:00,841 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:55:00,852 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:55:00,867 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Working directory for job is: /galaxy/server/database/jobs_directory/000/217
galaxy.jobs.runners DEBUG 2024-11-03 06:55:00,874 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [217] queued (32.425 ms)
galaxy.jobs.handler INFO 2024-11-03 06:55:00,877 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:00,880 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 217
tpv.core.entities DEBUG 2024-11-03 06:55:00,891 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:55:00,892 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:55:00,897 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:55:00,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:55:00,935 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Working directory for job is: /galaxy/server/database/jobs_directory/000/218
galaxy.jobs.runners DEBUG 2024-11-03 06:55:00,944 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [218] queued (46.845 ms)
galaxy.jobs.handler INFO 2024-11-03 06:55:00,946 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:00,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 218
galaxy.jobs DEBUG 2024-11-03 06:55:00,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [217] prepared (98.217 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:55:01,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/217/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/217/registry.xml' '/galaxy/server/database/jobs_directory/000/217/upload_params.json' '299:/galaxy/server/database/objects/d/f/8/dataset_df8d41ec-c31e-462b-875e-994efac5b3f2_files:/galaxy/server/database/objects/d/f/8/dataset_df8d41ec-c31e-462b-875e-994efac5b3f2.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:55:01,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (217) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/217/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/217/galaxy_217.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:55:01,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [218] prepared (77.389 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:55:01,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/218/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/218/registry.xml' '/galaxy/server/database/jobs_directory/000/218/upload_params.json' '300:/galaxy/server/database/objects/4/a/8/dataset_4a834d87-60c5-4845-bf7a-e009e59b97dc_files:/galaxy/server/database/objects/4/a/8/dataset_4a834d87-60c5-4845-bf7a-e009e59b97dc.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:55:01,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (218) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/218/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/218/galaxy_218.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:01,651 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:10,878 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-57lkz with k8s id: gxy-57lkz succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:10,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5qnj6 with k8s id: gxy-5qnj6 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:55:11,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 217: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:55:11,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 218: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:55:18,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 218 finished
galaxy.model.metadata DEBUG 2024-11-03 06:55:18,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 300
galaxy.jobs.runners DEBUG 2024-11-03 06:55:18,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 217 finished
galaxy.jobs INFO 2024-11-03 06:55:18,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 218 in /galaxy/server/database/jobs_directory/000/218
galaxy.model.metadata DEBUG 2024-11-03 06:55:18,345 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 299
galaxy.jobs INFO 2024-11-03 06:55:18,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 217 in /galaxy/server/database/jobs_directory/000/217
galaxy.jobs DEBUG 2024-11-03 06:55:18,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 218 executed (146.154 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:18,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 06:55:18,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 217 executed (124.855 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:18,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:55:19,249 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 219
tpv.core.entities DEBUG 2024-11-03 06:55:19,275 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:55:19,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:55:19,280 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:55:19,291 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:55:19,309 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Working directory for job is: /galaxy/server/database/jobs_directory/000/219
galaxy.jobs.runners DEBUG 2024-11-03 06:55:19,319 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [219] queued (38.057 ms)
galaxy.jobs.handler INFO 2024-11-03 06:55:19,321 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:19,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 219
galaxy.jobs DEBUG 2024-11-03 06:55:19,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [219] prepared (52.503 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:19,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:55:19,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:19,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:55:19,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/219/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/219/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/d/f/8/dataset_df8d41ec-c31e-462b-875e-994efac5b3f2.dat' './read_0.fasta' &&  ln -s '/galaxy/server/database/objects/4/a/8/dataset_4a834d87-60c5-4845-bf7a-e009e59b97dc.dat' './read_1.fasta' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --fasta read_0.fasta read_1.fasta        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-03 06:55:19,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (219) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/219/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/219/galaxy_219.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/219/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/f/0/d/dataset_f0dd08c3-d45f-485d-9932-1f81b91413dd.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/219/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/f/0/d/dataset_f0dd08c3-d45f-485d-9932-1f81b91413dd.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/219/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/4/c/b/dataset_4cb3bd92-4c89-40b5-b8fc-6efc48d4194b.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/219/working/NanoStats.txt" "/galaxy/server/database/objects/4/c/b/dataset_4cb3bd92-4c89-40b5-b8fc-6efc48d4194b.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/219/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/8/4/8/dataset_8482a23f-97b3-4ec5-947c-ceceee7fa018.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/219/working/NanoPlot-report.html" "/galaxy/server/database/objects/8/4/8/dataset_8482a23f-97b3-4ec5-947c-ceceee7fa018.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:19,462 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:19,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:55:19,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:19,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:19,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:19,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:29,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-stcwp with k8s id: gxy-stcwp succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:55:29,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 219: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:55:36,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 219 finished
galaxy.model.metadata DEBUG 2024-11-03 06:55:36,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 303
galaxy.model.metadata DEBUG 2024-11-03 06:55:36,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 302
galaxy.model.metadata DEBUG 2024-11-03 06:55:36,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 301
galaxy.util WARNING 2024-11-03 06:55:36,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/4/c/b/dataset_4cb3bd92-4c89-40b5-b8fc-6efc48d4194b.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/4/c/b/dataset_4cb3bd92-4c89-40b5-b8fc-6efc48d4194b.dat'
galaxy.util WARNING 2024-11-03 06:55:36,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/8/4/8/dataset_8482a23f-97b3-4ec5-947c-ceceee7fa018.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/8/4/8/dataset_8482a23f-97b3-4ec5-947c-ceceee7fa018.dat'
galaxy.jobs INFO 2024-11-03 06:55:36,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 219 in /galaxy/server/database/jobs_directory/000/219
galaxy.jobs DEBUG 2024-11-03 06:55:36,481 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 219 executed (164.492 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:36,493 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:55:38,629 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 220
tpv.core.entities DEBUG 2024-11-03 06:55:38,650 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:55:38,651 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:55:38,653 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:55:38,662 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:55:38,675 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Working directory for job is: /galaxy/server/database/jobs_directory/000/220
galaxy.jobs.runners DEBUG 2024-11-03 06:55:38,681 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [220] queued (27.853 ms)
galaxy.jobs.handler INFO 2024-11-03 06:55:38,684 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:38,687 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 220
galaxy.jobs DEBUG 2024-11-03 06:55:38,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [220] prepared (78.793 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:55:38,794 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/220/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/220/registry.xml' '/galaxy/server/database/jobs_directory/000/220/upload_params.json' '304:/galaxy/server/database/objects/7/7/b/dataset_77bcdb94-eda9-4749-b27a-3fd95466ee9d_files:/galaxy/server/database/objects/7/7/b/dataset_77bcdb94-eda9-4749-b27a-3fd95466ee9d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:55:38,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (220) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/220/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/220/galaxy_220.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:38,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:38,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:39,070 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:49,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zqptx with k8s id: gxy-zqptx succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:55:49,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 220: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:55:56,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 220 finished
galaxy.model.metadata DEBUG 2024-11-03 06:55:56,577 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 304
galaxy.jobs INFO 2024-11-03 06:55:56,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 220 in /galaxy/server/database/jobs_directory/000/220
galaxy.jobs DEBUG 2024-11-03 06:55:56,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 220 executed (88.049 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:56,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:55:56,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 221
tpv.core.entities DEBUG 2024-11-03 06:55:56,982 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:55:56,982 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:55:56,985 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:55:56,993 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:55:57,006 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Working directory for job is: /galaxy/server/database/jobs_directory/000/221
galaxy.jobs.runners DEBUG 2024-11-03 06:55:57,013 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [221] queued (27.844 ms)
galaxy.jobs.handler INFO 2024-11-03 06:55:57,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:57,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 221
galaxy.jobs DEBUG 2024-11-03 06:55:57,068 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [221] prepared (43.154 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:57,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:55:57,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:57,273 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:55:57,295 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/221/tool_script.sh] for tool command [poretools fastq --type all --min-length 0 --max-length 1000000000  '/galaxy/server/database/objects/7/7/b/dataset_77bcdb94-eda9-4749-b27a-3fd95466ee9d.dat' > '/galaxy/server/database/objects/c/c/3/dataset_cc339812-92eb-4e67-a64f-c3b81691f174.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:55:57,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (221) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/221/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/221/galaxy_221.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:57,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:57,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:55:57,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-03 06:55:57,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:57,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:55:58,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:22,809 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-97hbh with k8s id: gxy-97hbh succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:56:22,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 221: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:56:30,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 221 finished
galaxy.model.metadata DEBUG 2024-11-03 06:56:30,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 305
galaxy.jobs INFO 2024-11-03 06:56:30,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 221 in /galaxy/server/database/jobs_directory/000/221
galaxy.jobs DEBUG 2024-11-03 06:56:30,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 221 executed (90.204 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:30,254 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:56:31,735 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 222
tpv.core.entities DEBUG 2024-11-03 06:56:31,762 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:56:31,762 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:56:31,766 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:56:31,777 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:56:31,789 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Working directory for job is: /galaxy/server/database/jobs_directory/000/222
galaxy.jobs.runners DEBUG 2024-11-03 06:56:31,796 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [222] queued (29.955 ms)
galaxy.jobs.handler INFO 2024-11-03 06:56:31,798 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:31,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 222
galaxy.jobs DEBUG 2024-11-03 06:56:31,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [222] prepared (75.021 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:56:31,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/222/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/222/registry.xml' '/galaxy/server/database/jobs_directory/000/222/upload_params.json' '306:/galaxy/server/database/objects/b/8/f/dataset_b8f55f84-b185-46f8-ae31-cd8b2853b09f_files:/galaxy/server/database/objects/b/8/f/dataset_b8f55f84-b185-46f8-ae31-cd8b2853b09f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:56:31,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (222) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/222/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/222/galaxy_222.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:31,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:31,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:32,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:40,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cpn2h with k8s id: gxy-cpn2h succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:56:41,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 222: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:56:48,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 222 finished
galaxy.model.metadata DEBUG 2024-11-03 06:56:48,252 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 306
galaxy.jobs INFO 2024-11-03 06:56:48,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 222 in /galaxy/server/database/jobs_directory/000/222
galaxy.jobs DEBUG 2024-11-03 06:56:48,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 222 executed (98.487 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:48,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:56:49,065 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 223
tpv.core.entities DEBUG 2024-11-03 06:56:49,090 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:56:49,091 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:56:49,094 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:56:49,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:56:49,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Working directory for job is: /galaxy/server/database/jobs_directory/000/223
galaxy.jobs.runners DEBUG 2024-11-03 06:56:49,125 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [223] queued (30.822 ms)
galaxy.jobs.handler INFO 2024-11-03 06:56:49,127 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:49,129 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 223
galaxy.jobs DEBUG 2024-11-03 06:56:49,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [223] prepared (41.090 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:56:49,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:56:49,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-03 06:56:49,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:56:49,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/223/tool_script.sh] for tool command [poretools fasta --type all --min-length 0 --max-length 1000000000  '/galaxy/server/database/objects/b/8/f/dataset_b8f55f84-b185-46f8-ae31-cd8b2853b09f.dat' > '/galaxy/server/database/objects/d/8/2/dataset_d82c6df4-01fc-4eed-89f0-343e5fc82b17.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:56:49,230 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (223) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/223/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/223/galaxy_223.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:49,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:56:49,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:56:49,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-03 06:56:49,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:49,287 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:49,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:56:54,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-nctg2 with k8s id: gxy-nctg2 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:56:54,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 223: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:57:01,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 223 finished
galaxy.model.metadata DEBUG 2024-11-03 06:57:01,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 307
galaxy.jobs INFO 2024-11-03 06:57:01,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 223 in /galaxy/server/database/jobs_directory/000/223
galaxy.jobs DEBUG 2024-11-03 06:57:01,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 223 executed (90.157 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:01,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:57:03,363 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 224
tpv.core.entities DEBUG 2024-11-03 06:57:03,387 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:57:03,387 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:57:03,390 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:57:03,400 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:57:03,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Working directory for job is: /galaxy/server/database/jobs_directory/000/224
galaxy.jobs.runners DEBUG 2024-11-03 06:57:03,420 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [224] queued (29.782 ms)
galaxy.jobs.handler INFO 2024-11-03 06:57:03,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:03,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 224
galaxy.jobs DEBUG 2024-11-03 06:57:03,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [224] prepared (69.223 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:57:03,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/224/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/224/registry.xml' '/galaxy/server/database/jobs_directory/000/224/upload_params.json' '308:/galaxy/server/database/objects/8/c/5/dataset_8c5731c7-c447-4b8e-9388-5a25879b0b78_files:/galaxy/server/database/objects/8/c/5/dataset_8c5731c7-c447-4b8e-9388-5a25879b0b78.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:57:03,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (224) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/224/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/224/galaxy_224.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:03,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:03,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:04,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:13,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kb8cb with k8s id: gxy-kb8cb succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:57:13,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 224: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:57:20,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 224 finished
galaxy.model.metadata DEBUG 2024-11-03 06:57:20,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 308
galaxy.jobs INFO 2024-11-03 06:57:20,454 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 224 in /galaxy/server/database/jobs_directory/000/224
galaxy.jobs DEBUG 2024-11-03 06:57:20,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 224 executed (105.029 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:20,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:57:21,738 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 225
tpv.core.entities DEBUG 2024-11-03 06:57:21,764 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:57:21,765 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:57:21,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:57:21,779 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:57:21,792 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Working directory for job is: /galaxy/server/database/jobs_directory/000/225
galaxy.jobs.runners DEBUG 2024-11-03 06:57:21,799 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [225] queued (29.456 ms)
galaxy.jobs.handler INFO 2024-11-03 06:57:21,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:21,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 225
galaxy.jobs DEBUG 2024-11-03 06:57:21,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [225] prepared (58.382 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:21,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:21,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-03 06:57:21,892 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/225/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/8/c/5/dataset_8c5731c7-c447-4b8e-9388-5a25879b0b78.dat --output=/galaxy/server/database/objects/0/d/8/dataset_0d8e1fc7-cbc7-4e25-aa01-4b5bc7b5d712.dat --coverage=3 --format=six --base="None" --seq_column="None" --loc_column="None" --base_column="None" --cvrg_column="None"]
galaxy.jobs.runners DEBUG 2024-11-03 06:57:21,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (225) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/225/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/225/galaxy_225.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:21,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:21,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:21,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:21,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:22,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:26,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntqg8 with k8s id: gxy-ntqg8 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:57:26,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 225: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:57:33,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 225 finished
galaxy.model.metadata DEBUG 2024-11-03 06:57:33,543 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 309
galaxy.jobs INFO 2024-11-03 06:57:33,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 225 in /galaxy/server/database/jobs_directory/000/225
galaxy.jobs DEBUG 2024-11-03 06:57:33,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 225 executed (81.801 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:33,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:57:34,999 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 226
tpv.core.entities DEBUG 2024-11-03 06:57:35,023 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:57:35,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:57:35,029 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:57:35,039 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:57:35,053 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Working directory for job is: /galaxy/server/database/jobs_directory/000/226
galaxy.jobs.runners DEBUG 2024-11-03 06:57:35,059 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [226] queued (30.340 ms)
galaxy.jobs.handler INFO 2024-11-03 06:57:35,061 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:35,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 226
galaxy.jobs DEBUG 2024-11-03 06:57:35,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [226] prepared (67.927 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:57:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/226/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/226/registry.xml' '/galaxy/server/database/jobs_directory/000/226/upload_params.json' '310:/galaxy/server/database/objects/b/e/9/dataset_be993803-b391-44ad-a24c-c1af8aa01030_files:/galaxy/server/database/objects/b/e/9/dataset_be993803-b391-44ad-a24c-c1af8aa01030.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:57:35,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (226) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/226/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/226/galaxy_226.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:35,178 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:35,193 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:35,351 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:44,474 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ltxvh with k8s id: gxy-ltxvh succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:57:44,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 226: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:57:51,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 226 finished
galaxy.model.metadata DEBUG 2024-11-03 06:57:51,790 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 310
galaxy.jobs INFO 2024-11-03 06:57:51,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 226 in /galaxy/server/database/jobs_directory/000/226
galaxy.jobs DEBUG 2024-11-03 06:57:51,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 226 executed (89.430 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:51,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:57:52,388 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 227
tpv.core.entities DEBUG 2024-11-03 06:57:52,415 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:57:52,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:57:52,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:57:52,429 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:57:52,443 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Working directory for job is: /galaxy/server/database/jobs_directory/000/227
galaxy.jobs.runners DEBUG 2024-11-03 06:57:52,451 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [227] queued (31.910 ms)
galaxy.jobs.handler INFO 2024-11-03 06:57:52,453 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:52,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 227
galaxy.jobs DEBUG 2024-11-03 06:57:52,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [227] prepared (44.606 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:52,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:52,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-03 06:57:52,526 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/227/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/b/e/9/dataset_be993803-b391-44ad-a24c-c1af8aa01030.dat --output=/galaxy/server/database/objects/7/3/3/dataset_73305566-36d0-4a1e-bae9-17aa3cb2bb2e.dat --coverage=3 --format=ten --base=first --seq_column="None" --loc_column="None" --base_column="None" --cvrg_column="None"]
galaxy.jobs.runners DEBUG 2024-11-03 06:57:52,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (227) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/227/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/227/galaxy_227.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:52,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:52,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:57:52,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:52,575 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:53,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:57:56,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wf2fl with k8s id: gxy-wf2fl succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:57:56,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 227: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:58:03,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 227 finished
galaxy.model.metadata DEBUG 2024-11-03 06:58:03,873 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 311
galaxy.jobs INFO 2024-11-03 06:58:03,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 227 in /galaxy/server/database/jobs_directory/000/227
galaxy.jobs DEBUG 2024-11-03 06:58:03,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 227 executed (100.344 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:03,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:58:05,659 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 228
tpv.core.entities DEBUG 2024-11-03 06:58:05,682 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:58:05,682 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:58:05,686 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:58:05,696 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:58:05,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Working directory for job is: /galaxy/server/database/jobs_directory/000/228
galaxy.jobs.runners DEBUG 2024-11-03 06:58:05,714 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [228] queued (28.525 ms)
galaxy.jobs.handler INFO 2024-11-03 06:58:05,716 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:05,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 228
galaxy.jobs DEBUG 2024-11-03 06:58:05,792 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [228] prepared (67.159 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:58:05,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/228/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/228/registry.xml' '/galaxy/server/database/jobs_directory/000/228/upload_params.json' '312:/galaxy/server/database/objects/b/5/0/dataset_b5052e47-0557-4a08-a293-b5be135fd9c8_files:/galaxy/server/database/objects/b/5/0/dataset_b5052e47-0557-4a08-a293-b5be135fd9c8.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:58:05,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (228) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/228/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/228/galaxy_228.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:05,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:05,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:06,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:15,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pt8qb with k8s id: gxy-pt8qb succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:58:15,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 228: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:58:22,831 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 228 finished
galaxy.model.metadata DEBUG 2024-11-03 06:58:22,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 312
galaxy.jobs INFO 2024-11-03 06:58:22,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 228 in /galaxy/server/database/jobs_directory/000/228
galaxy.jobs DEBUG 2024-11-03 06:58:22,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 228 executed (102.298 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:22,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:58:23,999 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 229
tpv.core.entities DEBUG 2024-11-03 06:58:24,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:58:24,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:58:24,028 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:58:24,037 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:58:24,048 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Working directory for job is: /galaxy/server/database/jobs_directory/000/229
galaxy.jobs.runners DEBUG 2024-11-03 06:58:24,056 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [229] queued (28.457 ms)
galaxy.jobs.handler INFO 2024-11-03 06:58:24,058 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:24,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 229
galaxy.jobs DEBUG 2024-11-03 06:58:24,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [229] prepared (46.197 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:24,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:24,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-03 06:58:24,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/229/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/b/5/0/dataset_b5052e47-0557-4a08-a293-b5be135fd9c8.dat --output=/galaxy/server/database/objects/9/9/2/dataset_992e83b9-f32b-433e-a066-7d87c552fcac.dat --coverage=3 --format=manual --base="None" --seq_column=1 --loc_column=2 --base_column=3 --cvrg_column=8]
galaxy.jobs.runners DEBUG 2024-11-03 06:58:24,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (229) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/229/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/229/galaxy_229.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:24,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:24,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:24,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:24,185 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:24,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:28,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-p2cpv with k8s id: gxy-p2cpv succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:58:28,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 229: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:58:35,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 229 finished
galaxy.model.metadata DEBUG 2024-11-03 06:58:35,946 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 313
galaxy.jobs INFO 2024-11-03 06:58:35,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 229 in /galaxy/server/database/jobs_directory/000/229
galaxy.jobs DEBUG 2024-11-03 06:58:36,020 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 229 executed (91.571 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:36,032 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:58:38,279 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 231, 230
tpv.core.entities DEBUG 2024-11-03 06:58:38,303 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:58:38,304 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:58:38,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:58:38,318 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:58:38,332 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Working directory for job is: /galaxy/server/database/jobs_directory/000/230
galaxy.jobs.runners DEBUG 2024-11-03 06:58:38,337 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [230] queued (30.015 ms)
galaxy.jobs.handler INFO 2024-11-03 06:58:38,340 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 230
tpv.core.entities DEBUG 2024-11-03 06:58:38,349 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:58:38,350 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:58:38,355 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:58:38,370 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:58:38,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Working directory for job is: /galaxy/server/database/jobs_directory/000/231
galaxy.jobs.runners DEBUG 2024-11-03 06:58:38,409 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [231] queued (54.221 ms)
galaxy.jobs.handler INFO 2024-11-03 06:58:38,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 231
galaxy.jobs DEBUG 2024-11-03 06:58:38,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [230] prepared (140.575 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:58:38,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/230/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/230/registry.xml' '/galaxy/server/database/jobs_directory/000/230/upload_params.json' '314:/galaxy/server/database/objects/e/b/5/dataset_eb5996c8-8252-46c5-a6d1-b51947430007_files:/galaxy/server/database/objects/e/b/5/dataset_eb5996c8-8252-46c5-a6d1-b51947430007.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:58:38,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (230) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/230/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/230/galaxy_230.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:58:38,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [231] prepared (116.297 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,546 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:58:38,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/231/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/231/registry.xml' '/galaxy/server/database/jobs_directory/000/231/upload_params.json' '315:/galaxy/server/database/objects/7/7/e/dataset_77ec9ce5-cb6f-498d-bbe1-89b120c9c5d6_files:/galaxy/server/database/objects/7/7/e/dataset_77ec9ce5-cb6f-498d-bbe1-89b120c9c5d6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:58:38,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (231) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/231/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/231/galaxy_231.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:38,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:48,472 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-87sfc with k8s id: gxy-87sfc succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:48,486 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lgs68 with k8s id: gxy-lgs68 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:58:48,648 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 230: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:58:48,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 231: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:58:55,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 231 finished
galaxy.model.metadata DEBUG 2024-11-03 06:58:55,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 315
galaxy.jobs INFO 2024-11-03 06:58:55,887 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 231 in /galaxy/server/database/jobs_directory/000/231
galaxy.jobs DEBUG 2024-11-03 06:58:55,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 231 executed (83.307 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:55,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 06:58:55,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 230 finished
galaxy.model.metadata DEBUG 2024-11-03 06:58:55,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 314
galaxy.jobs INFO 2024-11-03 06:58:56,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 230 in /galaxy/server/database/jobs_directory/000/230
galaxy.jobs DEBUG 2024-11-03 06:58:56,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 230 executed (100.729 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:56,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:58:56,732 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 232
tpv.core.entities DEBUG 2024-11-03 06:58:56,759 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:58:56,760 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:58:56,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:58:56,773 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:58:56,786 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Working directory for job is: /galaxy/server/database/jobs_directory/000/232
galaxy.jobs.runners DEBUG 2024-11-03 06:58:56,793 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [232] queued (29.540 ms)
galaxy.jobs.handler INFO 2024-11-03 06:58:56,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:56,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 232
galaxy.jobs DEBUG 2024-11-03 06:58:56,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [232] prepared (50.552 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:56,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:58:56,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:57,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:58:57,090 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/232/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/232/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/e/b/5/dataset_eb5996c8-8252-46c5-a6d1-b51947430007.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/5/3/4/metadata_53435656-2a7b-4122-b47e-7fe82ee64115.dat' '0.bai' &&   samtools depth  -b '/galaxy/server/database/objects/7/7/e/dataset_77ec9ce5-cb6f-498d-bbe1-89b120c9c5d6.dat' 0 > '/galaxy/server/database/objects/5/2/f/dataset_52f05e0f-8124-4ed1-8ce7-75dc26771b39.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:58:57,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (232) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/232/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/232/galaxy_232.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:57,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:57,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:58:57,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:58:57,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:57,153 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:58:57,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:04,623 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dg8ws with k8s id: gxy-dg8ws succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:59:04,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 232: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:59:11,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 232 finished
galaxy.model.metadata DEBUG 2024-11-03 06:59:11,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 316
galaxy.jobs INFO 2024-11-03 06:59:12,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 232 in /galaxy/server/database/jobs_directory/000/232
galaxy.jobs DEBUG 2024-11-03 06:59:12,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 232 executed (107.670 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:12,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:59:13,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 233
tpv.core.entities DEBUG 2024-11-03 06:59:13,068 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:59:13,069 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:59:13,072 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:59:13,082 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:59:13,095 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Working directory for job is: /galaxy/server/database/jobs_directory/000/233
galaxy.jobs.runners DEBUG 2024-11-03 06:59:13,101 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [233] queued (29.204 ms)
galaxy.jobs.handler INFO 2024-11-03 06:59:13,105 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:13,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 233
galaxy.jobs DEBUG 2024-11-03 06:59:13,185 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [233] prepared (72.664 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:59:13,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/233/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/233/registry.xml' '/galaxy/server/database/jobs_directory/000/233/upload_params.json' '317:/galaxy/server/database/objects/3/1/3/dataset_313499ba-79db-40e2-9d69-76d5724d1729_files:/galaxy/server/database/objects/3/1/3/dataset_313499ba-79db-40e2-9d69-76d5724d1729.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:59:13,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (233) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/233/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/233/galaxy_233.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:13,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:13,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:13,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:23,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cnwjw with k8s id: gxy-cnwjw succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:59:23,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 233: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:59:31,153 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 233 finished
galaxy.model.metadata DEBUG 2024-11-03 06:59:31,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 317
galaxy.jobs INFO 2024-11-03 06:59:31,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 233 in /galaxy/server/database/jobs_directory/000/233
galaxy.jobs DEBUG 2024-11-03 06:59:31,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 233 executed (110.270 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:31,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:59:31,400 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 234
tpv.core.entities DEBUG 2024-11-03 06:59:31,426 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:59:31,427 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:59:31,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:59:31,441 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:59:31,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Working directory for job is: /galaxy/server/database/jobs_directory/000/234
galaxy.jobs.runners DEBUG 2024-11-03 06:59:31,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [234] queued (33.413 ms)
galaxy.jobs.handler INFO 2024-11-03 06:59:31,467 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:31,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 234
galaxy.jobs DEBUG 2024-11-03 06:59:31,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [234] prepared (39.003 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 06:59:31,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:59:31,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:59:31,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 06:59:31,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/234/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/234/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/3/1/3/dataset_313499ba-79db-40e2-9d69-76d5724d1729.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/0/5/5/metadata_055a7a4e-da43-468a-81ca-cfca6ddd7111.dat' '0.bai' &&   samtools depth  -r eboVir3:500-1500 0 > '/galaxy/server/database/objects/e/9/f/dataset_e9f79e86-8cdd-41e3-bcea-b9e3e38497fc.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:59:31,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (234) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/234/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/234/galaxy_234.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:31,590 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 06:59:31,596 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 06:59:31,596 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 06:59:31,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:31,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:31,809 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:35,875 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-br98l with k8s id: gxy-br98l succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:59:35,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 234: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:59:43,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 234 finished
galaxy.model.metadata DEBUG 2024-11-03 06:59:43,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 318
galaxy.jobs INFO 2024-11-03 06:59:43,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 234 in /galaxy/server/database/jobs_directory/000/234
galaxy.jobs DEBUG 2024-11-03 06:59:43,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 234 executed (98.796 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:43,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 06:59:44,804 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 236, 235
tpv.core.entities DEBUG 2024-11-03 06:59:44,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:59:44,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:59:44,831 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:59:44,841 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:59:44,854 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Working directory for job is: /galaxy/server/database/jobs_directory/000/235
galaxy.jobs.runners DEBUG 2024-11-03 06:59:44,860 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [235] queued (28.953 ms)
galaxy.jobs.handler INFO 2024-11-03 06:59:44,862 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:44,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 235
tpv.core.entities DEBUG 2024-11-03 06:59:44,872 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 06:59:44,872 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 06:59:44,876 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 06:59:44,888 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 06:59:44,910 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Working directory for job is: /galaxy/server/database/jobs_directory/000/236
galaxy.jobs.runners DEBUG 2024-11-03 06:59:44,917 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [236] queued (40.782 ms)
galaxy.jobs.handler INFO 2024-11-03 06:59:44,919 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:44,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 236
galaxy.jobs DEBUG 2024-11-03 06:59:44,966 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [235] prepared (88.722 ms)
galaxy.jobs.command_factory INFO 2024-11-03 06:59:44,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/235/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/235/registry.xml' '/galaxy/server/database/jobs_directory/000/235/upload_params.json' '319:/galaxy/server/database/objects/a/c/b/dataset_acb30a53-0dd7-4bd5-bf96-443289266385_files:/galaxy/server/database/objects/a/c/b/dataset_acb30a53-0dd7-4bd5-bf96-443289266385.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:59:44,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (235) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/235/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/235/galaxy_235.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 06:59:45,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [236] prepared (78.812 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:45,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:45,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 06:59:45,035 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/236/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/236/registry.xml' '/galaxy/server/database/jobs_directory/000/236/upload_params.json' '320:/galaxy/server/database/objects/b/e/6/dataset_be6be639-a170-4599-b293-53b12d092cd6_files:/galaxy/server/database/objects/b/e/6/dataset_be6be639-a170-4599-b293-53b12d092cd6.dat']
galaxy.jobs.runners DEBUG 2024-11-03 06:59:45,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (236) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/236/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/236/galaxy_236.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:45,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:45,070 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:46,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:46,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:55,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l22lw with k8s id: gxy-l22lw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 06:59:55,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9q89c with k8s id: gxy-9q89c succeeded
galaxy.jobs.runners DEBUG 2024-11-03 06:59:55,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 235: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 06:59:55,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 236: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:00:03,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 235 finished
galaxy.model.metadata DEBUG 2024-11-03 07:00:03,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 319
galaxy.jobs.runners DEBUG 2024-11-03 07:00:03,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 236 finished
galaxy.jobs INFO 2024-11-03 07:00:03,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 235 in /galaxy/server/database/jobs_directory/000/235
galaxy.model.metadata DEBUG 2024-11-03 07:00:03,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 320
galaxy.jobs INFO 2024-11-03 07:00:03,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 236 in /galaxy/server/database/jobs_directory/000/236
galaxy.jobs DEBUG 2024-11-03 07:00:03,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 235 executed (160.335 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:03,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:00:03,436 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 236 executed (155.134 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:03,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:00:04,409 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 237
tpv.core.entities DEBUG 2024-11-03 07:00:04,439 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:00:04,440 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:00:04,444 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:00:04,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:00:04,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Working directory for job is: /galaxy/server/database/jobs_directory/000/237
galaxy.jobs.runners DEBUG 2024-11-03 07:00:04,485 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [237] queued (40.921 ms)
galaxy.jobs.handler INFO 2024-11-03 07:00:04,487 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:04,490 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 237
galaxy.jobs DEBUG 2024-11-03 07:00:04,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [237] prepared (61.022 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:04,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:00:04,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:04,588 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:00:04,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/237/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/237/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/a/c/b/dataset_acb30a53-0dd7-4bd5-bf96-443289266385.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/0/0/f/metadata_00f00343-773b-41b8-9502-21eec09f55d4.dat' '0.bai' && ln -s '/galaxy/server/database/objects/b/e/6/dataset_be6be639-a170-4599-b293-53b12d092cd6.dat' '1' && ln -s '/galaxy/server/database/objects/_metadata_files/a/4/6/metadata_a46c40a0-7f0b-476c-a292-55c009952010.dat' '1.bai' &&   samtools depth -a 0 1 > '/galaxy/server/database/objects/f/5/3/dataset_f53d2cc0-3416-4334-82e6-a864a0b1281b.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:00:04,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (237) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/237/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/237/galaxy_237.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:04,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:04,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:00:04,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:04,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:04,683 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:05,441 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:09,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5bwlh with k8s id: gxy-5bwlh succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:00:09,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 237: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:00:16,758 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 237 finished
galaxy.model.metadata DEBUG 2024-11-03 07:00:16,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 321
galaxy.jobs INFO 2024-11-03 07:00:16,847 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 237 in /galaxy/server/database/jobs_directory/000/237
galaxy.jobs DEBUG 2024-11-03 07:00:16,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 237 executed (117.319 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:16,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:00:18,720 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 238, 239
tpv.core.entities DEBUG 2024-11-03 07:00:18,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:00:18,743 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:00:18,747 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:00:18,758 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:00:18,773 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Working directory for job is: /galaxy/server/database/jobs_directory/000/238
galaxy.jobs.runners DEBUG 2024-11-03 07:00:18,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [238] queued (33.563 ms)
galaxy.jobs.handler INFO 2024-11-03 07:00:18,783 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:18,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 238
tpv.core.entities DEBUG 2024-11-03 07:00:18,793 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:00:18,793 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:00:18,798 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:00:18,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:00:18,838 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Working directory for job is: /galaxy/server/database/jobs_directory/000/239
galaxy.jobs.runners DEBUG 2024-11-03 07:00:18,846 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [239] queued (47.349 ms)
galaxy.jobs.handler INFO 2024-11-03 07:00:18,848 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:18,851 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 239
galaxy.jobs DEBUG 2024-11-03 07:00:18,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [238] prepared (98.537 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:00:18,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/238/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/238/registry.xml' '/galaxy/server/database/jobs_directory/000/238/upload_params.json' '322:/galaxy/server/database/objects/a/f/2/dataset_af217010-647a-45d5-8bb7-fd3b2692555c_files:/galaxy/server/database/objects/a/f/2/dataset_af217010-647a-45d5-8bb7-fd3b2692555c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:00:18,930 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (238) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/238/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/238/galaxy_238.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:00:18,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [239] prepared (78.126 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:18,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:18,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:00:18,966 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/239/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/239/registry.xml' '/galaxy/server/database/jobs_directory/000/239/upload_params.json' '323:/galaxy/server/database/objects/e/1/0/dataset_e10715e4-1ccf-4f3a-8300-aa9ddecf201d_files:/galaxy/server/database/objects/e/1/0/dataset_e10715e4-1ccf-4f3a-8300-aa9ddecf201d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:00:18,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (239) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/239/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/239/galaxy_239.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:18,990 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:19,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:19,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:19,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:28,787 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gpwjx with k8s id: gxy-gpwjx succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:00:28,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 238: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:29,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gnqs4 with k8s id: gxy-gnqs4 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:00:29,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 239: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:00:36,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 238 finished
galaxy.model.metadata DEBUG 2024-11-03 07:00:36,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 322
galaxy.jobs INFO 2024-11-03 07:00:36,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 238 in /galaxy/server/database/jobs_directory/000/238
galaxy.jobs DEBUG 2024-11-03 07:00:36,483 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 238 executed (129.462 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:36,497 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:00:37,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 239 finished
galaxy.model.metadata DEBUG 2024-11-03 07:00:37,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 323
galaxy.jobs INFO 2024-11-03 07:00:37,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 239 in /galaxy/server/database/jobs_directory/000/239
galaxy.jobs DEBUG 2024-11-03 07:00:37,469 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 239 executed (123.522 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:37,481 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:00:38,182 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 240
tpv.core.entities DEBUG 2024-11-03 07:00:38,211 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:00:38,211 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:00:38,216 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:00:38,229 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:00:38,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Working directory for job is: /galaxy/server/database/jobs_directory/000/240
galaxy.jobs.runners DEBUG 2024-11-03 07:00:38,256 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [240] queued (39.872 ms)
galaxy.jobs.handler INFO 2024-11-03 07:00:38,258 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:38,261 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 240
galaxy.jobs DEBUG 2024-11-03 07:00:38,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [240] prepared (52.922 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:38,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:00:38,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:38,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:00:38,372 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/240/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/240/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/a/f/2/dataset_af217010-647a-45d5-8bb7-fd3b2692555c.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/c/7/e/metadata_c7e17510-6751-40e0-b04d-ac85ee9ab9b7.dat' '0.bai' && ln -s '/galaxy/server/database/objects/e/1/0/dataset_e10715e4-1ccf-4f3a-8300-aa9ddecf201d.dat' '1' && ln -s '/galaxy/server/database/objects/_metadata_files/7/7/5/metadata_775ea17e-6e75-4ba1-be22-08904c10e35a.dat' '1.bai' &&   samtools depth  -l 10 -m 4 -q 11 -Q 12 0 1 > '/galaxy/server/database/objects/c/3/9/dataset_c39d114a-d225-401f-9c8b-5763e103acc9.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:00:38,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (240) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/240/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/240/galaxy_240.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:38,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:38,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:00:38,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-03 07:00:38,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:38,437 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:38,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:42,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bbq7w with k8s id: gxy-bbq7w succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:00:43,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 240: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:00:50,484 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 240 finished
galaxy.model.metadata DEBUG 2024-11-03 07:00:50,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 324
galaxy.jobs INFO 2024-11-03 07:00:50,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 240 in /galaxy/server/database/jobs_directory/000/240
galaxy.jobs DEBUG 2024-11-03 07:00:50,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 240 executed (98.911 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:50,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:00:52,490 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 241
tpv.core.entities DEBUG 2024-11-03 07:00:52,517 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:00:52,518 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:00:52,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:00:52,533 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:00:52,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Working directory for job is: /galaxy/server/database/jobs_directory/000/241
galaxy.jobs.runners DEBUG 2024-11-03 07:00:52,553 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [241] queued (31.475 ms)
galaxy.jobs.handler INFO 2024-11-03 07:00:52,557 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:52,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 241
galaxy.jobs DEBUG 2024-11-03 07:00:52,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [241] prepared (67.886 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:00:52,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/241/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/241/registry.xml' '/galaxy/server/database/jobs_directory/000/241/upload_params.json' '325:/galaxy/server/database/objects/4/6/1/dataset_4611334a-0f53-44da-8dcf-bb512e6c22f2_files:/galaxy/server/database/objects/4/6/1/dataset_4611334a-0f53-44da-8dcf-bb512e6c22f2.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:00:52,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (241) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/241/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/241/galaxy_241.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:52,673 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:52,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:00:53,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:03,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jpjrc with k8s id: gxy-jpjrc succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:01:03,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 241: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:01:10,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 241 finished
galaxy.model.metadata DEBUG 2024-11-03 07:01:10,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 325
galaxy.jobs INFO 2024-11-03 07:01:10,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 241 in /galaxy/server/database/jobs_directory/000/241
galaxy.jobs DEBUG 2024-11-03 07:01:10,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 241 executed (114.718 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:10,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:01:11,873 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 242
tpv.core.entities DEBUG 2024-11-03 07:01:11,899 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/.*, abstract=False, cores=1, mem=7.6, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:01:11,899 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:01:11,903 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:01:11,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:01:11,926 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Working directory for job is: /galaxy/server/database/jobs_directory/000/242
galaxy.jobs.runners DEBUG 2024-11-03 07:01:11,934 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [242] queued (30.375 ms)
galaxy.jobs.handler INFO 2024-11-03 07:01:11,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:11,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 242
galaxy.jobs DEBUG 2024-11-03 07:01:11,990 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [242] prepared (44.471 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:11,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:01:11,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/2.0.1: samtools:1.3.1
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:12,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.3.1--h0cf4675_11,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:01:12,040 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/242/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/242/outputs/COMMAND_VERSION 2>&1;
samtools rmdup  '/galaxy/server/database/objects/4/6/1/dataset_4611334a-0f53-44da-8dcf-bb512e6c22f2.dat' '/galaxy/server/database/objects/d/7/9/dataset_d7950109-69ca-4e9f-ae8e-2abd1b3aaeff.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:01:12,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (242) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/242/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/242/galaxy_242.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:12,073 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:12,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:01:12,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/2.0.1: samtools:1.3.1
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:12,106 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.3.1--h0cf4675_11,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:12,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:12,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:18,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-fbn2j with k8s id: gxy-fbn2j succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:01:18,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 242: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:01:25,812 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 242 finished
galaxy.model.metadata DEBUG 2024-11-03 07:01:25,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 326
galaxy.jobs INFO 2024-11-03 07:01:25,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 242 in /galaxy/server/database/jobs_directory/000/242
galaxy.jobs DEBUG 2024-11-03 07:01:25,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 242 executed (105.499 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:25,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:01:28,197 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 244, 243
tpv.core.entities DEBUG 2024-11-03 07:01:28,221 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:01:28,222 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:01:28,224 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:01:28,233 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:01:28,244 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Working directory for job is: /galaxy/server/database/jobs_directory/000/243
galaxy.jobs.runners DEBUG 2024-11-03 07:01:28,250 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [243] queued (25.422 ms)
galaxy.jobs.handler INFO 2024-11-03 07:01:28,252 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,255 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 243
tpv.core.entities DEBUG 2024-11-03 07:01:28,264 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:01:28,265 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:01:28,268 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:01:28,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:01:28,305 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Working directory for job is: /galaxy/server/database/jobs_directory/000/244
galaxy.jobs.runners DEBUG 2024-11-03 07:01:28,314 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [244] queued (45.579 ms)
galaxy.jobs.handler INFO 2024-11-03 07:01:28,316 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 244
galaxy.jobs DEBUG 2024-11-03 07:01:28,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [243] prepared (106.011 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:01:28,401 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/243/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/243/registry.xml' '/galaxy/server/database/jobs_directory/000/243/upload_params.json' '327:/galaxy/server/database/objects/0/4/3/dataset_0432ce75-b19b-4512-8187-9ea9f2bbdb10_files:/galaxy/server/database/objects/0/4/3/dataset_0432ce75-b19b-4512-8187-9ea9f2bbdb10.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:01:28,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (243) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/243/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/243/galaxy_243.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:01:28,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [244] prepared (93.673 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,447 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:01:28,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/244/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/244/registry.xml' '/galaxy/server/database/jobs_directory/000/244/upload_params.json' '328:/galaxy/server/database/objects/1/b/9/dataset_1b9b6461-7606-4f1f-afe3-95fce439b9be_files:/galaxy/server/database/objects/1/b/9/dataset_1b9b6461-7606-4f1f-afe3-95fce439b9be.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:01:28,460 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (244) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/244/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/244/galaxy_244.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,508 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:28,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:29,651 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:38,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5q8hg with k8s id: gxy-5q8hg succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:38,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dqk4d with k8s id: gxy-dqk4d succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:01:38,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 243: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:01:38,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 244: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:01:45,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 243 finished
galaxy.model.metadata DEBUG 2024-11-03 07:01:45,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 327
galaxy.jobs INFO 2024-11-03 07:01:45,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 243 in /galaxy/server/database/jobs_directory/000/243
galaxy.jobs.runners DEBUG 2024-11-03 07:01:45,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 244 finished
galaxy.jobs DEBUG 2024-11-03 07:01:45,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 243 executed (99.624 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:45,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-03 07:01:45,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 328
galaxy.jobs INFO 2024-11-03 07:01:45,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 244 in /galaxy/server/database/jobs_directory/000/244
galaxy.jobs DEBUG 2024-11-03 07:01:46,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 244 executed (109.147 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:46,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:01:46,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 245
tpv.core.entities DEBUG 2024-11-03 07:01:46,657 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:01:46,657 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:01:46,661 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:01:46,670 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:01:46,683 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Working directory for job is: /galaxy/server/database/jobs_directory/000/245
galaxy.jobs.runners DEBUG 2024-11-03 07:01:46,691 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [245] queued (29.394 ms)
galaxy.jobs.handler INFO 2024-11-03 07:01:46,692 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:46,695 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 245
galaxy.jobs DEBUG 2024-11-03 07:01:46,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [245] prepared (40.334 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:46,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:01:46,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:46,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:01:46,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/245/tool_script.sh] for tool command [python -c "import anndata as ad;print('anndata version: %s' % ad.__version__); import loompy;print('\nloompy version: %s' % loompy.__version__)" > /galaxy/server/database/jobs_directory/000/245/outputs/COMMAND_VERSION 2>&1;
cp '/galaxy/server/database/objects/0/4/3/dataset_0432ce75-b19b-4512-8187-9ea9f2bbdb10.dat' loom_add_out.loom && python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/05631436cdf1/modify_loom/modify_loom.py' -f 'loom_add_out.loom' -a cols -c '/galaxy/server/database/objects/1/b/9/dataset_1b9b6461-7606-4f1f-afe3-95fce439b9be.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:01:46,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (245) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/245/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/245/galaxy_245.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/245/working/loom_add_out.loom" -a -f "/galaxy/server/database/objects/f/4/f/dataset_f4fef709-e9ec-4339-8482-708272ef6d10.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/245/working/loom_add_out.loom" "/galaxy/server/database/objects/f/4/f/dataset_f4fef709-e9ec-4339-8482-708272ef6d10.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:46,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:46,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:01:46,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-03 07:01:47,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:47,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:01:47,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:01,478 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cml8m with k8s id: gxy-cml8m succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:02:01,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 245: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:02:08,648 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 245 finished
galaxy.model.metadata DEBUG 2024-11-03 07:02:08,685 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 329
galaxy.util WARNING 2024-11-03 07:02:08,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/f/4/f/dataset_f4fef709-e9ec-4339-8482-708272ef6d10.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/f/4/f/dataset_f4fef709-e9ec-4339-8482-708272ef6d10.dat'
galaxy.jobs INFO 2024-11-03 07:02:08,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 245 in /galaxy/server/database/jobs_directory/000/245
galaxy.jobs DEBUG 2024-11-03 07:02:08,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 245 executed (94.464 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:08,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:02:10,074 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 247, 246
tpv.core.entities DEBUG 2024-11-03 07:02:10,097 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:02:10,097 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:02:10,100 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:02:10,108 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:02:10,120 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Working directory for job is: /galaxy/server/database/jobs_directory/000/246
galaxy.jobs.runners DEBUG 2024-11-03 07:02:10,126 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [246] queued (26.106 ms)
galaxy.jobs.handler INFO 2024-11-03 07:02:10,128 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 246
tpv.core.entities DEBUG 2024-11-03 07:02:10,142 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:02:10,142 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:02:10,147 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:02:10,159 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:02:10,185 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Working directory for job is: /galaxy/server/database/jobs_directory/000/247
galaxy.jobs.runners DEBUG 2024-11-03 07:02:10,193 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [247] queued (45.232 ms)
galaxy.jobs.handler INFO 2024-11-03 07:02:10,196 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 247
galaxy.jobs DEBUG 2024-11-03 07:02:10,243 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [246] prepared (99.599 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:02:10,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/246/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/246/registry.xml' '/galaxy/server/database/jobs_directory/000/246/upload_params.json' '330:/galaxy/server/database/objects/b/0/e/dataset_b0e5b8c1-06d8-4b61-b604-dab71a23f239_files:/galaxy/server/database/objects/b/0/e/dataset_b0e5b8c1-06d8-4b61-b604-dab71a23f239.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:02:10,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (246) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/246/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/246/galaxy_246.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,292 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:02:10,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [247] prepared (86.987 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:02:10,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/247/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/247/registry.xml' '/galaxy/server/database/jobs_directory/000/247/upload_params.json' '331:/galaxy/server/database/objects/5/c/f/dataset_5cf53361-4fef-47de-be25-3096f795a395_files:/galaxy/server/database/objects/5/c/f/dataset_5cf53361-4fef-47de-be25-3096f795a395.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:02:10,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (247) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/247/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/247/galaxy_247.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:10,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9nqtw with k8s id: gxy-9nqtw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,884 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lpwwc failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-lpwwc.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-03 07:02:19,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-03-06-12-1/jobs/gxy-lpwwc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-lpwwc": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,963 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (247/gxy-lpwwc) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (247/gxy-lpwwc) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (247/gxy-lpwwc) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (247/gxy-lpwwc) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-lpwwc.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 247 (gxy-lpwwc)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-lpwwc to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:19,979 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:02:20,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 246: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:20,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (247/gxy-lpwwc) Terminated at user's request
galaxy.jobs.runners DEBUG 2024-11-03 07:02:26,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 246 finished
galaxy.model.metadata DEBUG 2024-11-03 07:02:27,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 330
galaxy.jobs INFO 2024-11-03 07:02:27,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 246 in /galaxy/server/database/jobs_directory/000/246
galaxy.jobs DEBUG 2024-11-03 07:02:27,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 246 executed (97.032 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:27,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:02:28,489 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 249, 248
tpv.core.entities DEBUG 2024-11-03 07:02:28,514 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:02:28,514 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:02:28,518 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:02:28,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:02:28,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Working directory for job is: /galaxy/server/database/jobs_directory/000/248
galaxy.jobs.runners DEBUG 2024-11-03 07:02:28,549 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [248] queued (31.114 ms)
galaxy.jobs.handler INFO 2024-11-03 07:02:28,552 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 248
tpv.core.entities DEBUG 2024-11-03 07:02:28,562 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:02:28,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:02:28,568 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:02:28,599 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:02:28,623 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Working directory for job is: /galaxy/server/database/jobs_directory/000/249
galaxy.jobs.runners DEBUG 2024-11-03 07:02:28,630 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [249] queued (61.815 ms)
galaxy.jobs.handler INFO 2024-11-03 07:02:28,632 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 249
galaxy.jobs DEBUG 2024-11-03 07:02:28,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [248] prepared (103.012 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:02:28,699 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/248/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/248/registry.xml' '/galaxy/server/database/jobs_directory/000/248/upload_params.json' '332:/galaxy/server/database/objects/c/1/a/dataset_c1aa01ad-f734-456a-87ce-44dde4030efa_files:/galaxy/server/database/objects/c/1/a/dataset_c1aa01ad-f734-456a-87ce-44dde4030efa.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:02:28,710 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (248) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/248/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/248/galaxy_248.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:02:28,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [249] prepared (88.618 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:02:28,751 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/249/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/249/registry.xml' '/galaxy/server/database/jobs_directory/000/249/upload_params.json' '333:/galaxy/server/database/objects/6/a/8/dataset_6a846598-1b20-4300-a0f5-971813708121_files:/galaxy/server/database/objects/6/a/8/dataset_6a846598-1b20-4300-a0f5-971813708121.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:02:28,759 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/249/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/249/galaxy_249.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:28,785 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:29,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:29,106 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:38,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-x7j7k with k8s id: gxy-x7j7k succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:38,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-m8q4k with k8s id: gxy-m8q4k succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:02:38,659 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 248: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:02:38,673 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 249: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:02:45,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 248 finished
galaxy.model.metadata DEBUG 2024-11-03 07:02:45,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 332
galaxy.jobs.runners DEBUG 2024-11-03 07:02:45,889 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 249 finished
galaxy.jobs INFO 2024-11-03 07:02:45,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 248 in /galaxy/server/database/jobs_directory/000/248
galaxy.model.metadata DEBUG 2024-11-03 07:02:45,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 333
galaxy.jobs INFO 2024-11-03 07:02:45,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 249 in /galaxy/server/database/jobs_directory/000/249
galaxy.jobs DEBUG 2024-11-03 07:02:45,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 248 executed (127.544 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:45,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:02:46,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 249 executed (104.318 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:46,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:02:46,934 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 250
tpv.core.entities DEBUG 2024-11-03 07:02:46,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:02:46,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:02:46,963 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:02:46,974 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:02:46,985 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Working directory for job is: /galaxy/server/database/jobs_directory/000/250
galaxy.jobs.runners DEBUG 2024-11-03 07:02:46,993 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [250] queued (29.756 ms)
galaxy.jobs.handler INFO 2024-11-03 07:02:46,995 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:46,997 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 250
galaxy.jobs DEBUG 2024-11-03 07:02:47,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [250] prepared (39.671 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:02:47,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:02:47,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-03 07:02:47,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:02:47,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/250/tool_script.sh] for tool command [python -c "import anndata as ad;print('anndata version: %s' % ad.__version__); import loompy;print('\nloompy version: %s' % loompy.__version__)" > /galaxy/server/database/jobs_directory/000/250/outputs/COMMAND_VERSION 2>&1;
cp '/galaxy/server/database/objects/c/1/a/dataset_c1aa01ad-f734-456a-87ce-44dde4030efa.dat' loom_add_out.loom && python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/05631436cdf1/modify_loom/modify_loom.py' -f 'loom_add_out.loom' -a layers -l '/galaxy/server/database/objects/6/a/8/dataset_6a846598-1b20-4300-a0f5-971813708121.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:02:47,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (250) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/250/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/250/galaxy_250.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/250/working/loom_add_out.loom" -a -f "/galaxy/server/database/objects/0/b/8/dataset_0b88c775-277e-4fde-a7df-7f255e055488.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/250/working/loom_add_out.loom" "/galaxy/server/database/objects/0/b/8/dataset_0b88c775-277e-4fde-a7df-7f255e055488.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:47,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:02:47,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:02:47,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-03 07:02:47,144 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:47,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:47,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:02:52,662 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-x8vt5 with k8s id: gxy-x8vt5 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:02:52,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 250: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:02:59,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 250 finished
galaxy.model.metadata DEBUG 2024-11-03 07:02:59,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 334
galaxy.util WARNING 2024-11-03 07:02:59,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/0/b/8/dataset_0b88c775-277e-4fde-a7df-7f255e055488.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/0/b/8/dataset_0b88c775-277e-4fde-a7df-7f255e055488.dat'
galaxy.jobs INFO 2024-11-03 07:02:59,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 250 in /galaxy/server/database/jobs_directory/000/250
galaxy.jobs DEBUG 2024-11-03 07:03:00,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 250 executed (98.056 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:00,083 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:03:02,239 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 251
tpv.core.entities DEBUG 2024-11-03 07:03:02,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:03:02,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:03:02,263 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:03:02,271 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:03:02,282 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Working directory for job is: /galaxy/server/database/jobs_directory/000/251
galaxy.jobs.runners DEBUG 2024-11-03 07:03:02,289 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [251] queued (26.399 ms)
galaxy.jobs.handler INFO 2024-11-03 07:03:02,291 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:02,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 251
galaxy.jobs DEBUG 2024-11-03 07:03:02,373 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [251] prepared (73.395 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:03:02,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/251/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/251/registry.xml' '/galaxy/server/database/jobs_directory/000/251/upload_params.json' '335:/galaxy/server/database/objects/f/1/7/dataset_f17020d4-cfd3-4886-979c-81e8ffc6da97_files:/galaxy/server/database/objects/f/1/7/dataset_f17020d4-cfd3-4886-979c-81e8ffc6da97.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:03:02,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (251) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/251/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/251/galaxy_251.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:02,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:02,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:02,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:12,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mk2v8 with k8s id: gxy-mk2v8 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:03:12,934 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 251: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:03:20,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 251 finished
galaxy.model.metadata DEBUG 2024-11-03 07:03:20,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 335
galaxy.jobs INFO 2024-11-03 07:03:20,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 251 in /galaxy/server/database/jobs_directory/000/251
galaxy.jobs DEBUG 2024-11-03 07:03:20,128 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 251 executed (84.203 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:20,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:03:20,710 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 252
tpv.core.entities DEBUG 2024-11-03 07:03:20,738 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:03:20,739 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:03:20,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:03:20,754 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:03:20,771 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Working directory for job is: /galaxy/server/database/jobs_directory/000/252
galaxy.jobs.runners DEBUG 2024-11-03 07:03:20,780 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [252] queued (37.564 ms)
galaxy.jobs.handler INFO 2024-11-03 07:03:20,782 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:20,785 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 252
galaxy.jobs DEBUG 2024-11-03 07:03:20,835 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [252] prepared (42.557 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:03:20,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:03:20,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/scater_plot_tsne/1.22.0: mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057
galaxy.tool_util.deps.containers INFO 2024-11-03 07:03:21,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:03:21,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/252/tool_script.sh] for tool command [Rscript '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/99f912d5af9f/scater_plot_tsne/scater-plot-tsne.R' -i '/galaxy/server/database/objects/f/1/7/dataset_f17020d4-cfd3-4886-979c-81e8ffc6da97.dat' --colour-by 'Treatment' --shape-by 'Mutation_Status' -o '/galaxy/server/database/objects/4/4/a/dataset_44af171e-ea3f-4a54-be5a-2bc00d653406.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:03:21,073 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (252) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/252/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/252/galaxy_252.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:21,087 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:03:21,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:03:21,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/scater_plot_tsne/1.22.0: mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057
galaxy.tool_util.deps.containers INFO 2024-11-03 07:03:21,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:21,128 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:21,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:03:59,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9rtsl with k8s id: gxy-9rtsl succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:03:59,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 252: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:04:06,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 252 finished
galaxy.model.metadata DEBUG 2024-11-03 07:04:06,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 336
galaxy.jobs INFO 2024-11-03 07:04:06,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 252 in /galaxy/server/database/jobs_directory/000/252
galaxy.jobs DEBUG 2024-11-03 07:04:06,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 252 executed (92.206 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:06,729 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:04:13,652 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 253, 254
tpv.core.entities DEBUG 2024-11-03 07:04:13,675 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:04:13,676 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:04:13,679 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:04:13,690 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:04:13,704 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Working directory for job is: /galaxy/server/database/jobs_directory/000/253
galaxy.jobs.runners DEBUG 2024-11-03 07:04:13,711 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [253] queued (32.548 ms)
galaxy.jobs.handler INFO 2024-11-03 07:04:13,714 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,717 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 253
tpv.core.entities DEBUG 2024-11-03 07:04:13,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:04:13,725 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:04:13,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:04:13,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:04:13,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Working directory for job is: /galaxy/server/database/jobs_directory/000/254
galaxy.jobs.runners DEBUG 2024-11-03 07:04:13,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [254] queued (45.403 ms)
galaxy.jobs.handler INFO 2024-11-03 07:04:13,776 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 254
galaxy.jobs DEBUG 2024-11-03 07:04:13,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [253] prepared (91.647 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:04:13,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/253/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/253/registry.xml' '/galaxy/server/database/jobs_directory/000/253/upload_params.json' '337:/galaxy/server/database/objects/f/d/a/dataset_fda584c4-ab04-40e8-9f2f-dc5dd8f6a4ed_files:/galaxy/server/database/objects/f/d/a/dataset_fda584c4-ab04-40e8-9f2f-dc5dd8f6a4ed.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:04:13,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (253) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/253/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/253/galaxy_253.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:04:13,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [254] prepared (75.442 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,869 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:04:13,888 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/254/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/254/registry.xml' '/galaxy/server/database/jobs_directory/000/254/upload_params.json' '338:/galaxy/server/database/objects/2/4/5/dataset_24577d97-4581-441a-ae4d-ea5ce3f3196c_files:/galaxy/server/database/objects/2/4/5/dataset_24577d97-4581-441a-ae4d-ea5ce3f3196c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:04:13,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (254) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/254/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/254/galaxy_254.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:13,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:14,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:14,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:23,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hdgbs with k8s id: gxy-hdgbs succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:23,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5f5tx with k8s id: gxy-5f5tx succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:04:23,851 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 253: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:04:23,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 254: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:04:31,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 254 finished
galaxy.jobs.runners DEBUG 2024-11-03 07:04:31,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 253 finished
galaxy.model.metadata DEBUG 2024-11-03 07:04:31,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 338
galaxy.model.metadata DEBUG 2024-11-03 07:04:31,379 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 337
galaxy.jobs INFO 2024-11-03 07:04:31,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 254 in /galaxy/server/database/jobs_directory/000/254
galaxy.jobs INFO 2024-11-03 07:04:31,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 253 in /galaxy/server/database/jobs_directory/000/253
galaxy.jobs DEBUG 2024-11-03 07:04:31,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 254 executed (117.151 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:31,462 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:04:31,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 253 executed (121.744 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:31,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:04:32,089 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 255
tpv.core.entities DEBUG 2024-11-03 07:04:32,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:04:32,117 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:04:32,120 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:04:32,131 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:04:32,143 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Working directory for job is: /galaxy/server/database/jobs_directory/000/255
galaxy.jobs.runners DEBUG 2024-11-03 07:04:32,154 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [255] queued (33.760 ms)
galaxy.jobs.handler INFO 2024-11-03 07:04:32,156 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:32,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 255
galaxy.jobs DEBUG 2024-11-03 07:04:32,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [255] prepared (80.030 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:04:32,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:04:32,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:04:32,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:04:32,478 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/255/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/255/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/2/4/5/dataset_24577d97-4581-441a-ae4d-ea5ce3f3196c.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/f/d/a/dataset_fda584c4-ab04-40e8-9f2f-dc5dd8f6a4ed.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/b/9/4/metadata_b9449c8f-4f27-404b-9775-bf8486b3ac6a.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/d/1/1/dataset_d119cfbc-8d81-436c-b274-f3c8ba072369.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:04:32,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (255) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/255/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/255/galaxy_255.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:32,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:04:32,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:04:32,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:04:32,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:32,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:32,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:44,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kp9m4 with k8s id: gxy-kp9m4 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:04:45,059 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 255: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:04:52,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 255 finished
galaxy.model.metadata DEBUG 2024-11-03 07:04:52,188 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 339
galaxy.jobs INFO 2024-11-03 07:04:52,221 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 255 in /galaxy/server/database/jobs_directory/000/255
galaxy.jobs DEBUG 2024-11-03 07:04:52,275 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 255 executed (110.118 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:52,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:04:53,493 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 257, 256
tpv.core.entities DEBUG 2024-11-03 07:04:53,515 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:04:53,516 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:04:53,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:04:53,531 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:04:53,544 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Working directory for job is: /galaxy/server/database/jobs_directory/000/256
galaxy.jobs.runners DEBUG 2024-11-03 07:04:53,552 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [256] queued (32.342 ms)
galaxy.jobs.handler INFO 2024-11-03 07:04:53,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 256
tpv.core.entities DEBUG 2024-11-03 07:04:53,565 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:04:53,566 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:04:53,569 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:04:53,580 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:04:53,604 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Working directory for job is: /galaxy/server/database/jobs_directory/000/257
galaxy.jobs.runners DEBUG 2024-11-03 07:04:53,610 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [257] queued (40.120 ms)
galaxy.jobs.handler INFO 2024-11-03 07:04:53,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 257
galaxy.jobs DEBUG 2024-11-03 07:04:53,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [256] prepared (90.123 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:04:53,682 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/256/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/256/registry.xml' '/galaxy/server/database/jobs_directory/000/256/upload_params.json' '340:/galaxy/server/database/objects/6/7/1/dataset_67101d10-9a39-4d1e-8cf4-995a6ece6285_files:/galaxy/server/database/objects/6/7/1/dataset_67101d10-9a39-4d1e-8cf4-995a6ece6285.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:04:53,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (256) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/256/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/256/galaxy_256.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:04:53,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [257] prepared (80.433 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:04:53,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/257/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/257/registry.xml' '/galaxy/server/database/jobs_directory/000/257/upload_params.json' '341:/galaxy/server/database/objects/6/c/6/dataset_6c61fafd-1608-475f-bd5c-00f3bda72042_files:/galaxy/server/database/objects/6/c/6/dataset_6c61fafd-1608-475f-bd5c-00f3bda72042.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:04:53,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (257) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/257/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/257/galaxy_257.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:53,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:04:54,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:03,598 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ncg74 with k8s id: gxy-ncg74 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:03,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mfhrk with k8s id: gxy-mfhrk succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:05:03,744 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 256: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:05:03,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 257: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:05:11,191 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 257 finished
galaxy.model.metadata DEBUG 2024-11-03 07:05:11,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 341
galaxy.jobs.runners DEBUG 2024-11-03 07:05:11,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 256 finished
galaxy.jobs INFO 2024-11-03 07:05:11,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 257 in /galaxy/server/database/jobs_directory/000/257
galaxy.model.metadata DEBUG 2024-11-03 07:05:11,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 340
galaxy.jobs INFO 2024-11-03 07:05:11,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 256 in /galaxy/server/database/jobs_directory/000/256
galaxy.jobs DEBUG 2024-11-03 07:05:11,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 257 executed (131.988 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:11,358 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:05:11,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 256 executed (114.818 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:11,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:05:11,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 258
tpv.core.entities DEBUG 2024-11-03 07:05:11,969 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:11,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:11,974 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:11,984 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:11,997 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Working directory for job is: /galaxy/server/database/jobs_directory/000/258
galaxy.jobs.runners DEBUG 2024-11-03 07:05:12,007 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [258] queued (33.269 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:12,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:12,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 258
galaxy.jobs DEBUG 2024-11-03 07:05:12,066 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [258] prepared (46.869 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:12,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:05:12,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:12,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:05:12,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/258/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/258/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/6/c/6/dataset_6c61fafd-1608-475f-bd5c-00f3bda72042.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/6/7/1/dataset_67101d10-9a39-4d1e-8cf4-995a6ece6285.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/a/1/c/metadata_a1cfa18e-1487-4ac4-8ab7-598c4d4e5fd6.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 14 --skip-coverage 0 --limit-coverage 0   --haplotype-length 0 --min-alternate-count 1 --min-alternate-fraction 0.05 --pooled-continuous --report-monomorphic --standard-filters  "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/d/3/b/dataset_d3bfdc3c-b767-4a71-856d-6271d9b82b8f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:12,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (258) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/258/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/258/galaxy_258.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:12,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:12,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:05:12,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:12,151 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:12,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:12,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:16,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xkwn8 with k8s id: gxy-xkwn8 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:05:16,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 258: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:05:23,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 258 finished
galaxy.model.metadata DEBUG 2024-11-03 07:05:23,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 342
galaxy.jobs INFO 2024-11-03 07:05:24,008 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 258 in /galaxy/server/database/jobs_directory/000/258
galaxy.jobs DEBUG 2024-11-03 07:05:24,059 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 258 executed (105.835 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:24,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:05:25,216 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 259, 260
tpv.core.entities DEBUG 2024-11-03 07:05:25,241 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:25,242 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:25,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:25,256 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:25,269 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Working directory for job is: /galaxy/server/database/jobs_directory/000/259
galaxy.jobs.runners DEBUG 2024-11-03 07:05:25,275 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [259] queued (29.083 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:25,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 259
tpv.core.entities DEBUG 2024-11-03 07:05:25,288 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:25,289 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:25,293 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:25,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:25,337 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Working directory for job is: /galaxy/server/database/jobs_directory/000/260
galaxy.jobs.runners DEBUG 2024-11-03 07:05:25,345 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [260] queued (50.979 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:25,348 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 260
galaxy.jobs DEBUG 2024-11-03 07:05:25,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [259] prepared (102.430 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:05:25,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/259/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/259/registry.xml' '/galaxy/server/database/jobs_directory/000/259/upload_params.json' '343:/galaxy/server/database/objects/2/a/a/dataset_2aa3c53e-9c3f-499d-97e7-074571935a8b_files:/galaxy/server/database/objects/2/a/a/dataset_2aa3c53e-9c3f-499d-97e7-074571935a8b.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:25,431 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (259) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/259/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/259/galaxy_259.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:05:25,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [260] prepared (79.394 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,446 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:05:25,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/260/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/260/registry.xml' '/galaxy/server/database/jobs_directory/000/260/upload_params.json' '344:/galaxy/server/database/objects/a/3/8/dataset_a387084d-99db-48b6-a334-aa69e4e3e8c4_files:/galaxy/server/database/objects/a/3/8/dataset_a387084d-99db-48b6-a334-aa69e4e3e8c4.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:25,476 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (260) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/260/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/260/galaxy_260.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,491 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:25,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:35,007 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dwzlm with k8s id: gxy-dwzlm succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:05:35,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 260: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:36,020 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-h752z with k8s id: gxy-h752z succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:05:36,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 259: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:05:42,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 260 finished
galaxy.model.metadata DEBUG 2024-11-03 07:05:42,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 344
galaxy.jobs INFO 2024-11-03 07:05:42,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 260 in /galaxy/server/database/jobs_directory/000/260
galaxy.jobs DEBUG 2024-11-03 07:05:42,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 260 executed (112.694 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:42,854 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:05:43,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 259 finished
galaxy.model.metadata DEBUG 2024-11-03 07:05:43,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 343
galaxy.jobs INFO 2024-11-03 07:05:43,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 259 in /galaxy/server/database/jobs_directory/000/259
galaxy.jobs DEBUG 2024-11-03 07:05:43,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 259 executed (125.964 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:43,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:05:44,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 261
tpv.core.entities DEBUG 2024-11-03 07:05:44,728 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:44,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:44,732 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:44,743 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:44,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Working directory for job is: /galaxy/server/database/jobs_directory/000/261
galaxy.jobs.runners DEBUG 2024-11-03 07:05:44,765 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [261] queued (32.615 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:44,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:44,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 261
galaxy.jobs DEBUG 2024-11-03 07:05:44,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [261] prepared (49.049 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:44,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:05:44,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:44,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:05:44,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/261/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/261/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/a/3/8/dataset_a387084d-99db-48b6-a334-aa69e4e3e8c4.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/2/a/a/dataset_2aa3c53e-9c3f-499d-97e7-074571935a8b.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/6/6/b/metadata_66b63d12-4686-4883-a7d3-2e22f4a09595.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 14 --skip-coverage 0 --limit-coverage 0   --haplotype-length 0 --min-alternate-count 1 --min-alternate-fraction 0.05 --pooled-continuous --report-monomorphic --standard-filters  "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/0/4/e/dataset_04edd9d8-14f2-4ea9-9de5-71f0fd3bdb0e.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:44,883 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (261) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/261/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/261/galaxy_261.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:44,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:44,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:05:44,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:05:44,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:44,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:46,146 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:50,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5gfqq with k8s id: gxy-5gfqq succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:05:50,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 261: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:05:57,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 261 finished
galaxy.model.metadata DEBUG 2024-11-03 07:05:57,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 345
galaxy.jobs INFO 2024-11-03 07:05:57,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 261 in /galaxy/server/database/jobs_directory/000/261
galaxy.jobs DEBUG 2024-11-03 07:05:57,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 261 executed (116.503 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:57,687 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:05:58,988 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 263, 262
tpv.core.entities DEBUG 2024-11-03 07:05:59,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:59,016 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:59,020 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:59,031 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:59,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Working directory for job is: /galaxy/server/database/jobs_directory/000/262
galaxy.jobs.runners DEBUG 2024-11-03 07:05:59,051 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [262] queued (30.689 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:59,053 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 262
tpv.core.entities DEBUG 2024-11-03 07:05:59,065 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:05:59,066 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:05:59,070 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:05:59,082 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:05:59,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Working directory for job is: /galaxy/server/database/jobs_directory/000/263
galaxy.jobs.runners DEBUG 2024-11-03 07:05:59,112 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [263] queued (42.377 ms)
galaxy.jobs.handler INFO 2024-11-03 07:05:59,115 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 263
galaxy.jobs DEBUG 2024-11-03 07:05:59,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [262] prepared (91.114 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:05:59,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/262/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/262/registry.xml' '/galaxy/server/database/jobs_directory/000/262/upload_params.json' '346:/galaxy/server/database/objects/5/6/f/dataset_56fd00e5-d8d6-4abb-86b7-8ba298b52941_files:/galaxy/server/database/objects/5/6/f/dataset_56fd00e5-d8d6-4abb-86b7-8ba298b52941.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:59,191 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (262) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/262/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/262/galaxy_262.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:05:59,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [263] prepared (73.216 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:05:59,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/263/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/263/registry.xml' '/galaxy/server/database/jobs_directory/000/263/upload_params.json' '347:/galaxy/server/database/objects/4/e/b/dataset_4eb5130c-af4c-47a1-8149-ba90508267b9_files:/galaxy/server/database/objects/4/e/b/dataset_4eb5130c-af4c-47a1-8149-ba90508267b9.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:05:59,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (263) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/263/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/263/galaxy_263.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:05:59,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:00,663 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:01,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:09,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ttkpp with k8s id: gxy-ttkpp succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:06:09,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 263: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:15,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pg2qs with k8s id: gxy-pg2qs succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:06:15,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 262: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:06:16,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 263 finished
galaxy.model.metadata DEBUG 2024-11-03 07:06:16,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 347
galaxy.jobs INFO 2024-11-03 07:06:16,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 263 in /galaxy/server/database/jobs_directory/000/263
galaxy.jobs DEBUG 2024-11-03 07:06:16,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 263 executed (96.507 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:16,691 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:06:22,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 262 finished
galaxy.model.metadata DEBUG 2024-11-03 07:06:22,671 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 346
galaxy.jobs INFO 2024-11-03 07:06:22,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 262 in /galaxy/server/database/jobs_directory/000/262
galaxy.jobs DEBUG 2024-11-03 07:06:22,756 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 262 executed (101.489 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:22,768 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:06:23,563 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 264
tpv.core.entities DEBUG 2024-11-03 07:06:23,587 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:06:23,588 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:06:23,591 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:06:23,601 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:06:23,613 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Working directory for job is: /galaxy/server/database/jobs_directory/000/264
galaxy.jobs.runners DEBUG 2024-11-03 07:06:23,622 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [264] queued (31.184 ms)
galaxy.jobs.handler INFO 2024-11-03 07:06:23,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:23,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 264
galaxy.jobs DEBUG 2024-11-03 07:06:23,683 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [264] prepared (47.930 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:06:23,683 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:06:23,683 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:06:23,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:06:23,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/264/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/264/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/4/e/b/dataset_4eb5130c-af4c-47a1-8149-ba90508267b9.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/5/6/f/dataset_56fd00e5-d8d6-4abb-86b7-8ba298b52941.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/d/8/4/metadata_d84f8a7a-187e-40c3-925c-6cfd22d2e760.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    --theta 0.001 --ploidy 1            "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/8/3/b/dataset_83b83669-021d-4968-9332-1c7ec0f8f793.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:06:23,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (264) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/264/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/264/galaxy_264.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:23,748 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:06:23,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:06:23,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:06:23,769 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:23,788 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:24,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:28,466 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bl68f with k8s id: gxy-bl68f succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:06:28,599 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 264: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:06:35,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 264 finished
galaxy.model.metadata DEBUG 2024-11-03 07:06:35,759 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 348
galaxy.jobs INFO 2024-11-03 07:06:35,789 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 264 in /galaxy/server/database/jobs_directory/000/264
galaxy.jobs DEBUG 2024-11-03 07:06:35,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 264 executed (104.563 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:35,858 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:06:37,849 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 265, 266
tpv.core.entities DEBUG 2024-11-03 07:06:37,871 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:06:37,871 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:06:37,876 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:06:37,885 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:06:37,896 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Working directory for job is: /galaxy/server/database/jobs_directory/000/265
galaxy.jobs.runners DEBUG 2024-11-03 07:06:37,902 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [265] queued (25.442 ms)
galaxy.jobs.handler INFO 2024-11-03 07:06:37,904 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:37,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 265
tpv.core.entities DEBUG 2024-11-03 07:06:37,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:06:37,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:06:37,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:06:37,928 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:06:37,946 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Working directory for job is: /galaxy/server/database/jobs_directory/000/266
galaxy.jobs.runners DEBUG 2024-11-03 07:06:37,954 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [266] queued (35.785 ms)
galaxy.jobs.handler INFO 2024-11-03 07:06:37,956 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:37,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 266
galaxy.jobs DEBUG 2024-11-03 07:06:38,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [265] prepared (84.951 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:06:38,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/265/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/265/registry.xml' '/galaxy/server/database/jobs_directory/000/265/upload_params.json' '349:/galaxy/server/database/objects/4/4/a/dataset_44a87b7b-aafe-46e3-aa91-c232602873e0_files:/galaxy/server/database/objects/4/4/a/dataset_44a87b7b-aafe-46e3-aa91-c232602873e0.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:06:38,035 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (265) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/265/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/265/galaxy_265.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:06:38,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [266] prepared (73.866 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:06:38,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/266/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/266/registry.xml' '/galaxy/server/database/jobs_directory/000/266/upload_params.json' '350:/galaxy/server/database/objects/7/2/b/dataset_72b93981-a493-4943-93f6-c0339288b7b2_files:/galaxy/server/database/objects/7/2/b/dataset_72b93981-a493-4943-93f6-c0339288b7b2.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:06:38,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (266) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/266/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/266/galaxy_266.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,493 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:38,528 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cp44m with k8s id: gxy-cp44m succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bmb4v failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-bmb4v.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-03 07:06:47,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-03-06-12-1/jobs/gxy-bmb4v

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-bmb4v": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266/gxy-bmb4v) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266/gxy-bmb4v) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266/gxy-bmb4v) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266/gxy-bmb4v) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-bmb4v.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Attempting to stop job 266 (gxy-bmb4v)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Found job with id gxy-bmb4v to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:47,963 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:06:48,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 265: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:48,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266/gxy-bmb4v) Terminated at user's request
galaxy.jobs.runners DEBUG 2024-11-03 07:06:55,092 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 265 finished
galaxy.model.metadata DEBUG 2024-11-03 07:06:55,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 349
galaxy.jobs INFO 2024-11-03 07:06:55,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 265 in /galaxy/server/database/jobs_directory/000/265
galaxy.jobs DEBUG 2024-11-03 07:06:55,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 265 executed (103.474 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:55,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:06:56,247 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 268, 267
tpv.core.entities DEBUG 2024-11-03 07:06:56,269 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:06:56,269 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:06:56,272 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:06:56,280 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:06:56,292 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Working directory for job is: /galaxy/server/database/jobs_directory/000/267
galaxy.jobs.runners DEBUG 2024-11-03 07:06:56,299 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [267] queued (27.565 ms)
galaxy.jobs.handler INFO 2024-11-03 07:06:56,302 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 267
tpv.core.entities DEBUG 2024-11-03 07:06:56,309 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:06:56,310 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:06:56,313 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:06:56,325 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:06:56,348 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Working directory for job is: /galaxy/server/database/jobs_directory/000/268
galaxy.jobs.runners DEBUG 2024-11-03 07:06:56,354 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [268] queued (41.517 ms)
galaxy.jobs.handler INFO 2024-11-03 07:06:56,358 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 268
galaxy.jobs DEBUG 2024-11-03 07:06:56,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [267] prepared (84.293 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:06:56,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/267/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/267/registry.xml' '/galaxy/server/database/jobs_directory/000/267/upload_params.json' '351:/galaxy/server/database/objects/7/4/b/dataset_74b459ed-f6d3-4226-88ef-be75fa9cba5d_files:/galaxy/server/database/objects/7/4/b/dataset_74b459ed-f6d3-4226-88ef-be75fa9cba5d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:06:56,436 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (267) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/267/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/267/galaxy_267.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:06:56,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [268] prepared (86.255 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,468 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:06:56,482 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/268/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/268/registry.xml' '/galaxy/server/database/jobs_directory/000/268/upload_params.json' '352:/galaxy/server/database/objects/0/3/d/dataset_03d2116c-6cea-4ada-9c93-7c91f1c44d7d_files:/galaxy/server/database/objects/0/3/d/dataset_03d2116c-6cea-4ada-9c93-7c91f1c44d7d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:06:56,491 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (268) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/268/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/268/galaxy_268.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:56,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:06:57,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:06,363 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tf94k with k8s id: gxy-tf94k succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:06,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2svnk with k8s id: gxy-2svnk succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:07:06,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 267: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:07:06,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 268: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:07:14,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 268 finished
galaxy.jobs.runners DEBUG 2024-11-03 07:07:14,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 267 finished
galaxy.model.metadata DEBUG 2024-11-03 07:07:14,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 352
galaxy.model.metadata DEBUG 2024-11-03 07:07:14,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 351
galaxy.jobs INFO 2024-11-03 07:07:14,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 268 in /galaxy/server/database/jobs_directory/000/268
galaxy.jobs INFO 2024-11-03 07:07:14,183 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 267 in /galaxy/server/database/jobs_directory/000/267
galaxy.jobs DEBUG 2024-11-03 07:07:14,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 268 executed (125.085 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:14,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:07:14,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 267 executed (134.158 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:14,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:07:14,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 269
tpv.core.entities DEBUG 2024-11-03 07:07:14,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:07:14,727 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:07:14,730 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:07:14,739 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:07:14,751 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Working directory for job is: /galaxy/server/database/jobs_directory/000/269
galaxy.jobs.runners DEBUG 2024-11-03 07:07:14,759 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [269] queued (28.517 ms)
galaxy.jobs.handler INFO 2024-11-03 07:07:14,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:14,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 269
galaxy.jobs DEBUG 2024-11-03 07:07:14,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [269] prepared (41.706 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:14,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:07:14,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:14,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:07:14,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/269/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/269/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/0/3/d/dataset_03d2116c-6cea-4ada-9c93-7c91f1c44d7d.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/7/4/b/dataset_74b459ed-f6d3-4226-88ef-be75fa9cba5d.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/a/f/1/metadata_af1724cf-fd78-4c54-8e15-e0f4dc87db9b.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 0 --skip-coverage 0 --limit-coverage 400    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/1/0/3/dataset_103d9147-ec75-40ce-951c-b4c9aa524420.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:07:14,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (269) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/269/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/269/galaxy_269.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:14,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:14,878 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:07:14,878 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:14,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:14,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:15,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:20,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7dhrv with k8s id: gxy-7dhrv succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:07:20,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 269: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:07:27,792 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 269 finished
galaxy.model.metadata DEBUG 2024-11-03 07:07:27,834 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 353
galaxy.jobs INFO 2024-11-03 07:07:27,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 269 in /galaxy/server/database/jobs_directory/000/269
galaxy.jobs DEBUG 2024-11-03 07:07:27,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 269 executed (103.857 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:27,930 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:07:28,995 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 270
tpv.core.entities DEBUG 2024-11-03 07:07:29,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:07:29,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:07:29,028 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:07:29,039 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:07:29,051 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Working directory for job is: /galaxy/server/database/jobs_directory/000/270
galaxy.jobs.runners DEBUG 2024-11-03 07:07:29,057 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [270] queued (29.023 ms)
galaxy.jobs.handler INFO 2024-11-03 07:07:29,060 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:29,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 270
galaxy.jobs DEBUG 2024-11-03 07:07:29,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [270] prepared (64.073 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:07:29,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/270/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/270/registry.xml' '/galaxy/server/database/jobs_directory/000/270/upload_params.json' '354:/galaxy/server/database/objects/8/b/1/dataset_8b1a7b5e-7bee-4a28-8c97-f7a7f7dc19ae_files:/galaxy/server/database/objects/8/b/1/dataset_8b1a7b5e-7bee-4a28-8c97-f7a7f7dc19ae.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:07:29,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/270/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/270/galaxy_270.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:29,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:29,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:29,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-03 07:07:30,065 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 271
tpv.core.entities DEBUG 2024-11-03 07:07:30,088 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:07:30,088 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:07:30,092 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:07:30,102 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:07:30,113 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Working directory for job is: /galaxy/server/database/jobs_directory/000/271
galaxy.jobs.runners DEBUG 2024-11-03 07:07:30,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [271] queued (27.220 ms)
galaxy.jobs.handler INFO 2024-11-03 07:07:30,122 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:30,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 271
galaxy.jobs DEBUG 2024-11-03 07:07:30,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [271] prepared (63.975 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:07:30,213 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/271/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/271/registry.xml' '/galaxy/server/database/jobs_directory/000/271/upload_params.json' '355:/galaxy/server/database/objects/8/3/8/dataset_838eb4ba-9a50-4b40-ba60-17e0732597e7_files:/galaxy/server/database/objects/8/3/8/dataset_838eb4ba-9a50-4b40-ba60-17e0732597e7.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:07:30,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (271) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/271/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/271/galaxy_271.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:30,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:30,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:31,717 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:38,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-nhdgv with k8s id: gxy-nhdgv succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:07:39,083 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 270: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:39,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-59fjm with k8s id: gxy-59fjm succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:07:40,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 271: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:07:46,493 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 270 finished
galaxy.model.metadata DEBUG 2024-11-03 07:07:46,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 354
galaxy.jobs INFO 2024-11-03 07:07:46,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 270 in /galaxy/server/database/jobs_directory/000/270
galaxy.jobs DEBUG 2024-11-03 07:07:46,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 270 executed (105.421 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:46,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:07:47,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 271 finished
galaxy.model.metadata DEBUG 2024-11-03 07:07:47,452 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 355
galaxy.jobs INFO 2024-11-03 07:07:47,482 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 271 in /galaxy/server/database/jobs_directory/000/271
galaxy.jobs DEBUG 2024-11-03 07:07:47,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 271 executed (97.439 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:47,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:07:48,435 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 272
tpv.core.entities DEBUG 2024-11-03 07:07:48,463 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:07:48,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:07:48,467 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:07:48,479 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:07:48,503 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Working directory for job is: /galaxy/server/database/jobs_directory/000/272
galaxy.jobs.runners DEBUG 2024-11-03 07:07:48,515 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [272] queued (47.260 ms)
galaxy.jobs.handler INFO 2024-11-03 07:07:48,517 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:48,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 272
galaxy.jobs DEBUG 2024-11-03 07:07:48,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [272] prepared (75.795 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:48,607 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:07:48,607 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:48,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:07:48,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/272/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/272/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/8/3/8/dataset_838eb4ba-9a50-4b40-ba60-17e0732597e7.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/8/b/1/dataset_8b1a7b5e-7bee-4a28-8c97-f7a7f7dc19ae.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/4/b/3/metadata_4b3e8a90-bf6d-40df-8aa6-0ec1e6c99a3e.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 0 --skip-coverage 100 --limit-coverage 0    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/4/6/7/dataset_46759504-3494-4ab8-9858-4c207e3ca06f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:07:48,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (272) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/272/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/272/galaxy_272.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:48,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:48,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:07:48,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:07:48,696 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:48,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:49,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:07:53,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9wqmc with k8s id: gxy-9wqmc succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:07:53,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 272: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:08:00,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 272 finished
galaxy.model.metadata DEBUG 2024-11-03 07:08:00,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 356
galaxy.jobs INFO 2024-11-03 07:08:00,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 272 in /galaxy/server/database/jobs_directory/000/272
galaxy.jobs DEBUG 2024-11-03 07:08:00,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 272 executed (122.948 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:00,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:08:01,735 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 274, 273
tpv.core.entities DEBUG 2024-11-03 07:08:01,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:08:01,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:08:01,761 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:08:01,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:08:01,788 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Working directory for job is: /galaxy/server/database/jobs_directory/000/273
galaxy.jobs.runners DEBUG 2024-11-03 07:08:01,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [273] queued (33.828 ms)
galaxy.jobs.handler INFO 2024-11-03 07:08:01,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:01,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 273
tpv.core.entities DEBUG 2024-11-03 07:08:01,810 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:08:01,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:08:01,816 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:08:01,829 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:08:01,855 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Working directory for job is: /galaxy/server/database/jobs_directory/000/274
galaxy.jobs.runners DEBUG 2024-11-03 07:08:01,863 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [274] queued (46.718 ms)
galaxy.jobs.handler INFO 2024-11-03 07:08:01,866 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:01,869 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 274
galaxy.jobs DEBUG 2024-11-03 07:08:01,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [273] prepared (102.964 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:08:01,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/273/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/273/registry.xml' '/galaxy/server/database/jobs_directory/000/273/upload_params.json' '357:/galaxy/server/database/objects/1/2/1/dataset_12143991-8297-4465-a293-3ab97fa38581_files:/galaxy/server/database/objects/1/2/1/dataset_12143991-8297-4465-a293-3ab97fa38581.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:08:01,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (273) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/273/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/273/galaxy_273.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:08:01,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [274] prepared (82.766 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:01,967 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:01,982 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:08:01,988 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/274/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/274/registry.xml' '/galaxy/server/database/jobs_directory/000/274/upload_params.json' '358:/galaxy/server/database/objects/a/0/7/dataset_a075715d-b70a-4440-a115-0a7d2c148edb_files:/galaxy/server/database/objects/a/0/7/dataset_a075715d-b70a-4440-a115-0a7d2c148edb.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:08:01,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (274) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/274/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/274/galaxy_274.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:02,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:02,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:02,178 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:03,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:11,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5zzgq with k8s id: gxy-5zzgq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:11,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xb8nz with k8s id: gxy-xb8nz succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:08:11,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 273: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:08:11,581 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 274: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:08:19,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 274 finished
galaxy.jobs.runners DEBUG 2024-11-03 07:08:19,166 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 273 finished
galaxy.model.metadata DEBUG 2024-11-03 07:08:19,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 358
galaxy.model.metadata DEBUG 2024-11-03 07:08:19,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 357
galaxy.jobs INFO 2024-11-03 07:08:19,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 274 in /galaxy/server/database/jobs_directory/000/274
galaxy.jobs INFO 2024-11-03 07:08:19,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 273 in /galaxy/server/database/jobs_directory/000/273
galaxy.jobs DEBUG 2024-11-03 07:08:19,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 274 executed (126.197 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:19,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:08:19,316 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 273 executed (128.137 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:19,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:08:20,147 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 275
tpv.core.entities DEBUG 2024-11-03 07:08:20,176 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:08:20,176 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:08:20,181 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:08:20,192 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:08:20,207 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Working directory for job is: /galaxy/server/database/jobs_directory/000/275
galaxy.jobs.runners DEBUG 2024-11-03 07:08:20,218 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [275] queued (36.905 ms)
galaxy.jobs.handler INFO 2024-11-03 07:08:20,220 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:20,223 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 275
galaxy.jobs DEBUG 2024-11-03 07:08:20,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [275] prepared (44.487 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:20,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:08:20,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:20,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:08:20,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/275/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/275/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/a/0/7/dataset_a075715d-b70a-4440-a115-0a7d2c148edb.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/1/2/1/dataset_12143991-8297-4465-a293-3ab97fa38581.dat' 'b_0.cram' && ln -s -f '/galaxy/server/database/objects/_metadata_files/5/6/e/metadata_56e4883f-27ef-49ae-afa1-c0211bf32cec.dat' 'b_0.cram.crai' &&   samtools view -H b_0.cram| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.cram' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/9/6/3/dataset_963fd0f0-a210-431b-95e6-c557e5480c6f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:08:20,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (275) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/275/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/275/galaxy_275.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:20,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:20,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:08:20,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.6+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:20,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:879ddaebc016378f34d1b42b2f9c0fbfb5835004-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:20,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:21,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:24,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lg7ds with k8s id: gxy-lg7ds succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:08:24,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 275: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:08:31,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 275 finished
galaxy.model.metadata DEBUG 2024-11-03 07:08:31,778 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 359
galaxy.jobs INFO 2024-11-03 07:08:31,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 275 in /galaxy/server/database/jobs_directory/000/275
galaxy.jobs DEBUG 2024-11-03 07:08:31,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 275 executed (117.072 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:31,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:08:34,452 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 276
tpv.core.entities DEBUG 2024-11-03 07:08:34,478 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:08:34,478 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:08:34,482 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:08:34,496 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:08:34,509 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Working directory for job is: /galaxy/server/database/jobs_directory/000/276
galaxy.jobs.runners DEBUG 2024-11-03 07:08:34,517 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [276] queued (34.064 ms)
galaxy.jobs.handler INFO 2024-11-03 07:08:34,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:34,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 276
galaxy.jobs DEBUG 2024-11-03 07:08:34,599 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [276] prepared (68.934 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:08:34,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/276/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/276/registry.xml' '/galaxy/server/database/jobs_directory/000/276/upload_params.json' '360:/galaxy/server/database/objects/d/8/0/dataset_d803b03c-f274-47a4-abf7-cf6d70b453ae_files:/galaxy/server/database/objects/d/8/0/dataset_d803b03c-f274-47a4-abf7-cf6d70b453ae.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:08:34,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (276) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/276/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/276/galaxy_276.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:34,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:34,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:35,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:44,697 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tgzqp with k8s id: gxy-tgzqp succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:08:44,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 276: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:08:52,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 276 finished
galaxy.model.metadata DEBUG 2024-11-03 07:08:52,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 360
galaxy.jobs INFO 2024-11-03 07:08:52,096 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 276 in /galaxy/server/database/jobs_directory/000/276
galaxy.jobs DEBUG 2024-11-03 07:08:52,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 276 executed (99.685 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:52,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:08:52,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 277
tpv.core.entities DEBUG 2024-11-03 07:08:52,826 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:08:52,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:08:52,830 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:08:52,839 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:08:52,857 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Working directory for job is: /galaxy/server/database/jobs_directory/000/277
galaxy.jobs.runners DEBUG 2024-11-03 07:08:52,866 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [277] queued (36.273 ms)
galaxy.jobs.handler INFO 2024-11-03 07:08:52,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:52,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 277
galaxy.jobs DEBUG 2024-11-03 07:08:52,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [277] prepared (64.267 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:52,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:08:52,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:53,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:08:53,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/277/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/277/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/d/8/0/dataset_d803b03c-f274-47a4-abf7-cf6d70b453ae.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp    -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/f/7/d/dataset_f7d7db4f-929e-4ace-a9de-db61adbc6ca7.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/b/a/5/dataset_ba52ef74-1c4f-4853-bfd9-76620ab08183.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/0/2/9/dataset_02920f81-917b-4e93-a4e9-833d90dfeb25.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/0/2/9/dataset_02920f81-917b-4e93-a4e9-833d90dfeb25.dat; python -m base64 $plot >> /galaxy/server/database/objects/0/2/9/dataset_02920f81-917b-4e93-a4e9-833d90dfeb25.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/0/2/9/dataset_02920f81-917b-4e93-a4e9-833d90dfeb25.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/0/2/9/dataset_02920f81-917b-4e93-a4e9-833d90dfeb25.dat;)]
galaxy.jobs.runners DEBUG 2024-11-03 07:08:53,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (277) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/277/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/277/galaxy_277.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:53,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:53,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:08:53,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:08:53,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:53,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:08:53,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:24,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-46szp with k8s id: gxy-46szp succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:09:24,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 277: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:09:31,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 277 finished
galaxy.model.metadata DEBUG 2024-11-03 07:09:31,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 361
galaxy.model.metadata DEBUG 2024-11-03 07:09:31,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 362
galaxy.model.metadata DEBUG 2024-11-03 07:09:31,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 363
galaxy.util WARNING 2024-11-03 07:09:31,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/f/7/d/dataset_f7d7db4f-929e-4ace-a9de-db61adbc6ca7.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/f/7/d/dataset_f7d7db4f-929e-4ace-a9de-db61adbc6ca7.dat'
galaxy.util WARNING 2024-11-03 07:09:31,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/b/a/5/dataset_ba52ef74-1c4f-4853-bfd9-76620ab08183.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/b/a/5/dataset_ba52ef74-1c4f-4853-bfd9-76620ab08183.dat'
galaxy.jobs INFO 2024-11-03 07:09:31,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 277 in /galaxy/server/database/jobs_directory/000/277
galaxy.jobs DEBUG 2024-11-03 07:09:31,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 277 executed (94.317 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:31,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:09:32,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 278
tpv.core.entities DEBUG 2024-11-03 07:09:32,589 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:09:32,590 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:09:32,593 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:09:32,604 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:09:32,618 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Working directory for job is: /galaxy/server/database/jobs_directory/000/278
galaxy.jobs.runners DEBUG 2024-11-03 07:09:32,626 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [278] queued (32.727 ms)
galaxy.jobs.handler INFO 2024-11-03 07:09:32,628 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:32,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 278
galaxy.jobs DEBUG 2024-11-03 07:09:32,712 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [278] prepared (75.084 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:09:32,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/278/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/278/registry.xml' '/galaxy/server/database/jobs_directory/000/278/upload_params.json' '364:/galaxy/server/database/objects/d/c/8/dataset_dc873bd2-c24e-4265-a8be-a335fede00ee_files:/galaxy/server/database/objects/d/c/8/dataset_dc873bd2-c24e-4265-a8be-a335fede00ee.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:09:32,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (278) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/278/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/278/galaxy_278.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:32,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:32,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:33,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:42,274 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4n4rp with k8s id: gxy-4n4rp succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:09:42,408 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 278: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:09:49,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 278 finished
galaxy.model.metadata DEBUG 2024-11-03 07:09:49,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 364
galaxy.jobs INFO 2024-11-03 07:09:49,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 278 in /galaxy/server/database/jobs_directory/000/278
galaxy.jobs DEBUG 2024-11-03 07:09:49,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 278 executed (104.726 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:49,748 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:09:50,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 279
tpv.core.entities DEBUG 2024-11-03 07:09:50,935 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:09:50,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:09:50,940 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:09:50,951 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:09:50,968 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Working directory for job is: /galaxy/server/database/jobs_directory/000/279
galaxy.jobs.runners DEBUG 2024-11-03 07:09:50,976 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [279] queued (36.456 ms)
galaxy.jobs.handler INFO 2024-11-03 07:09:50,978 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:50,981 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 279
galaxy.jobs DEBUG 2024-11-03 07:09:51,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [279] prepared (47.020 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:09:51,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:09:51,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:09:51,274 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:09:51,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/279/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/279/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/d/c/8/dataset_dc873bd2-c24e-4265-a8be-a335fede00ee.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp     --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/5/6/5/dataset_565ba4e4-5854-45ee-856f-29bbb14b8b45.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/c/1/4/dataset_c149431b-8215-40d5-8725-91fff97cec41.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:09:51,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (279) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/279/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/279/galaxy_279.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:51,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:09:51,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:09:51,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:09:51,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:51,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:52,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:09:56,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-k6x7v with k8s id: gxy-k6x7v succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:09:56,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 279: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:10:03,795 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 279 finished
galaxy.model.metadata DEBUG 2024-11-03 07:10:03,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 365
galaxy.model.metadata DEBUG 2024-11-03 07:10:03,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 366
galaxy.util WARNING 2024-11-03 07:10:03,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/5/6/5/dataset_565ba4e4-5854-45ee-856f-29bbb14b8b45.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/5/6/5/dataset_565ba4e4-5854-45ee-856f-29bbb14b8b45.dat'
galaxy.util WARNING 2024-11-03 07:10:03,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/c/1/4/dataset_c149431b-8215-40d5-8725-91fff97cec41.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/c/1/4/dataset_c149431b-8215-40d5-8725-91fff97cec41.dat'
galaxy.jobs INFO 2024-11-03 07:10:03,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 279 in /galaxy/server/database/jobs_directory/000/279
galaxy.jobs DEBUG 2024-11-03 07:10:03,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 279 executed (140.973 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:03,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:10:05,310 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 280
tpv.core.entities DEBUG 2024-11-03 07:10:05,333 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:10:05,333 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:10:05,337 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:10:05,346 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:10:05,361 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Working directory for job is: /galaxy/server/database/jobs_directory/000/280
galaxy.jobs.runners DEBUG 2024-11-03 07:10:05,369 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [280] queued (32.012 ms)
galaxy.jobs.handler INFO 2024-11-03 07:10:05,371 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:05,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 280
galaxy.jobs DEBUG 2024-11-03 07:10:05,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [280] prepared (84.800 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:10:05,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/280/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/280/registry.xml' '/galaxy/server/database/jobs_directory/000/280/upload_params.json' '367:/galaxy/server/database/objects/2/1/6/dataset_2166fd46-c324-4300-a678-6fec65868a3a_files:/galaxy/server/database/objects/2/1/6/dataset_2166fd46-c324-4300-a678-6fec65868a3a.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:10:05,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (280) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/280/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/280/galaxy_280.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:05,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:05,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:06,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:14,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rsv5z with k8s id: gxy-rsv5z succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:10:14,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 280: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:10:21,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 280 finished
galaxy.model.metadata DEBUG 2024-11-03 07:10:21,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 367
galaxy.jobs INFO 2024-11-03 07:10:21,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 280 in /galaxy/server/database/jobs_directory/000/280
galaxy.jobs DEBUG 2024-11-03 07:10:21,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 280 executed (113.640 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:22,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:10:22,657 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 281
tpv.core.entities DEBUG 2024-11-03 07:10:22,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:10:22,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:10:22,689 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:10:22,700 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:10:22,718 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Working directory for job is: /galaxy/server/database/jobs_directory/000/281
galaxy.jobs.runners DEBUG 2024-11-03 07:10:22,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [281] queued (37.595 ms)
galaxy.jobs.handler INFO 2024-11-03 07:10:22,728 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:22,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 281
galaxy.jobs DEBUG 2024-11-03 07:10:22,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [281] prepared (57.799 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:10:22,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:10:22,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:10:22,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:10:22,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/281/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/281/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/2/1/6/dataset_2166fd46-c324-4300-a678-6fec65868a3a.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp  -c 'test' -s 'test'   -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/2/c/f/dataset_2cf0eb76-11e1-4967-ad13-597c2fe6ca50.dat' && mv cnv_tmp/summary.tab '/galaxy/server/database/objects/5/d/0/dataset_5d063b04-bd0b-4f2f-9520-b1e551d34bac.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/1/d/b/dataset_1db4b098-3700-49c3-9638-1824cf72cb19.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/1/d/b/dataset_1db4b098-3700-49c3-9638-1824cf72cb19.dat; python -m base64 $plot >> /galaxy/server/database/objects/1/d/b/dataset_1db4b098-3700-49c3-9638-1824cf72cb19.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/1/d/b/dataset_1db4b098-3700-49c3-9638-1824cf72cb19.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/1/d/b/dataset_1db4b098-3700-49c3-9638-1824cf72cb19.dat;)]
galaxy.jobs.runners DEBUG 2024-11-03 07:10:22,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (281) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/281/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/281/galaxy_281.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:22,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:10:22,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:10:22,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:10:22,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:22,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:23,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:29,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4bnm9 with k8s id: gxy-4bnm9 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:10:29,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 281: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:10:37,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 281 finished
galaxy.model.metadata DEBUG 2024-11-03 07:10:37,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 368
galaxy.model.metadata DEBUG 2024-11-03 07:10:37,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 369
galaxy.model.metadata DEBUG 2024-11-03 07:10:37,169 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 370
galaxy.util WARNING 2024-11-03 07:10:37,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/2/c/f/dataset_2cf0eb76-11e1-4967-ad13-597c2fe6ca50.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/2/c/f/dataset_2cf0eb76-11e1-4967-ad13-597c2fe6ca50.dat'
galaxy.util WARNING 2024-11-03 07:10:37,174 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/5/d/0/dataset_5d063b04-bd0b-4f2f-9520-b1e551d34bac.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/5/d/0/dataset_5d063b04-bd0b-4f2f-9520-b1e551d34bac.dat'
galaxy.jobs INFO 2024-11-03 07:10:37,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 281 in /galaxy/server/database/jobs_directory/000/281
galaxy.jobs DEBUG 2024-11-03 07:10:37,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 281 executed (103.099 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:37,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:10:44,075 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 282
tpv.core.entities DEBUG 2024-11-03 07:10:44,101 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:10:44,102 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:10:44,106 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:10:44,118 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:10:44,132 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Working directory for job is: /galaxy/server/database/jobs_directory/000/282
galaxy.jobs.runners DEBUG 2024-11-03 07:10:44,139 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [282] queued (32.715 ms)
galaxy.jobs.handler INFO 2024-11-03 07:10:44,141 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:44,144 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 282
galaxy.jobs DEBUG 2024-11-03 07:10:44,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [282] prepared (79.714 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:10:44,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/282/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/282/registry.xml' '/galaxy/server/database/jobs_directory/000/282/upload_params.json' '371:/galaxy/server/database/objects/1/0/a/dataset_10a6180e-163d-4119-a25c-bef0644df833_files:/galaxy/server/database/objects/1/0/a/dataset_10a6180e-163d-4119-a25c-bef0644df833.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:10:44,262 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (282) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/282/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/282/galaxy_282.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:44,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:44,292 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:44,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:10:53,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cdrz8 with k8s id: gxy-cdrz8 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:10:54,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 282: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:11:01,313 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 282 finished
galaxy.model.metadata DEBUG 2024-11-03 07:11:01,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 371
galaxy.jobs INFO 2024-11-03 07:11:01,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 282 in /galaxy/server/database/jobs_directory/000/282
galaxy.jobs DEBUG 2024-11-03 07:11:01,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 282 executed (122.098 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:01,472 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:11:02,456 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 283
tpv.core.entities DEBUG 2024-11-03 07:11:02,485 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:11:02,486 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:11:02,490 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:11:02,502 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:11:02,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Working directory for job is: /galaxy/server/database/jobs_directory/000/283
galaxy.jobs.runners DEBUG 2024-11-03 07:11:02,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [283] queued (37.290 ms)
galaxy.jobs.handler INFO 2024-11-03 07:11:02,530 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:02,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 283
galaxy.jobs DEBUG 2024-11-03 07:11:02,585 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [283] prepared (45.755 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:02,585 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:11:02,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:02,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:11:02,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/283/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/283/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/1/0/a/dataset_10a6180e-163d-4119-a25c-bef0644df833.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp     --aberrant "1.0,1.0" --BAF-weight 1 --BAF-dev "0.04,0.04" --LRR-weight 0 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/6/c/b/dataset_6cbb9ab3-757d-4b11-a8d5-d015efded248.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/8/9/7/dataset_8979ff4c-8880-4969-93cb-312462baea43.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:11:02,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (283) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/283/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/283/galaxy_283.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:02,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:02,665 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:11:02,665 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:02,685 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:02,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:02,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:07,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lm925 with k8s id: gxy-lm925 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:11:08,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 283: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:11:15,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 283 finished
galaxy.model.metadata DEBUG 2024-11-03 07:11:15,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 372
galaxy.model.metadata DEBUG 2024-11-03 07:11:15,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 373
galaxy.util WARNING 2024-11-03 07:11:15,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/6/c/b/dataset_6cbb9ab3-757d-4b11-a8d5-d015efded248.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/6/c/b/dataset_6cbb9ab3-757d-4b11-a8d5-d015efded248.dat'
galaxy.util WARNING 2024-11-03 07:11:15,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/8/9/7/dataset_8979ff4c-8880-4969-93cb-312462baea43.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/8/9/7/dataset_8979ff4c-8880-4969-93cb-312462baea43.dat'
galaxy.jobs INFO 2024-11-03 07:11:15,454 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 283 in /galaxy/server/database/jobs_directory/000/283
galaxy.jobs DEBUG 2024-11-03 07:11:15,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 283 executed (123.190 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:15,543 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:11:16,755 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 284
tpv.core.entities DEBUG 2024-11-03 07:11:16,778 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:11:16,779 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:11:16,783 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:11:16,796 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:11:16,810 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Working directory for job is: /galaxy/server/database/jobs_directory/000/284
galaxy.jobs.runners DEBUG 2024-11-03 07:11:16,818 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [284] queued (34.141 ms)
galaxy.jobs.handler INFO 2024-11-03 07:11:16,820 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:16,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 284
galaxy.jobs DEBUG 2024-11-03 07:11:16,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [284] prepared (76.641 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:11:16,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/284/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/284/registry.xml' '/galaxy/server/database/jobs_directory/000/284/upload_params.json' '374:/galaxy/server/database/objects/0/f/4/dataset_0f4b0c49-a5df-49b4-9253-23aa2befaad2_files:/galaxy/server/database/objects/0/f/4/dataset_0f4b0c49-a5df-49b4-9253-23aa2befaad2.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:11:16,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (284) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/284/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/284/galaxy_284.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:16,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:16,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:18,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:27,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-p2q9p with k8s id: gxy-p2q9p succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:11:27,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 284: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:11:34,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 284 finished
galaxy.model.metadata DEBUG 2024-11-03 07:11:34,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 374
galaxy.jobs INFO 2024-11-03 07:11:34,578 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 284 in /galaxy/server/database/jobs_directory/000/284
galaxy.jobs DEBUG 2024-11-03 07:11:34,619 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 284 executed (94.720 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:34,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:11:35,199 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 285
tpv.core.entities DEBUG 2024-11-03 07:11:35,227 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:11:35,227 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:11:35,231 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:11:35,243 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:11:35,265 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Working directory for job is: /galaxy/server/database/jobs_directory/000/285
galaxy.jobs.runners DEBUG 2024-11-03 07:11:35,272 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [285] queued (41.113 ms)
galaxy.jobs.handler INFO 2024-11-03 07:11:35,275 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:35,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 285
galaxy.jobs DEBUG 2024-11-03 07:11:35,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [285] prepared (53.418 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:35,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:11:35,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:35,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:11:35,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/285/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/285/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/0/f/4/dataset_0f4b0c49-a5df-49b4-9253-23aa2befaad2.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp    -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09    --regions-overlap 1          input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/5/0/5/dataset_505da8a6-7f58-46e1-a83f-521d3896a90e.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/2/2/7/dataset_227d43c6-b6e8-4db3-b441-495d57c23258.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/a/1/d/dataset_a1da881c-74b5-4585-bcc0-5bc94ef65e8a.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/a/1/d/dataset_a1da881c-74b5-4585-bcc0-5bc94ef65e8a.dat; python -m base64 $plot >> /galaxy/server/database/objects/a/1/d/dataset_a1da881c-74b5-4585-bcc0-5bc94ef65e8a.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/a/1/d/dataset_a1da881c-74b5-4585-bcc0-5bc94ef65e8a.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/a/1/d/dataset_a1da881c-74b5-4585-bcc0-5bc94ef65e8a.dat;)]
galaxy.jobs.runners DEBUG 2024-11-03 07:11:35,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (285) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/285/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/285/galaxy_285.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:35,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:35,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:11:35,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-03 07:11:35,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:35,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:36,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:42,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ld9lt with k8s id: gxy-ld9lt succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:11:42,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 285: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:11:49,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 285 finished
galaxy.model.metadata DEBUG 2024-11-03 07:11:49,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 375
galaxy.model.metadata DEBUG 2024-11-03 07:11:49,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 376
galaxy.model.metadata DEBUG 2024-11-03 07:11:49,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 377
galaxy.util WARNING 2024-11-03 07:11:49,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/5/0/5/dataset_505da8a6-7f58-46e1-a83f-521d3896a90e.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/5/0/5/dataset_505da8a6-7f58-46e1-a83f-521d3896a90e.dat'
galaxy.util WARNING 2024-11-03 07:11:49,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/2/2/7/dataset_227d43c6-b6e8-4db3-b441-495d57c23258.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/2/2/7/dataset_227d43c6-b6e8-4db3-b441-495d57c23258.dat'
galaxy.jobs INFO 2024-11-03 07:11:49,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 285 in /galaxy/server/database/jobs_directory/000/285
galaxy.jobs DEBUG 2024-11-03 07:11:49,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 285 executed (93.666 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:49,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:11:51,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 286
tpv.core.entities DEBUG 2024-11-03 07:11:51,569 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:11:51,570 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:11:51,574 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:11:51,587 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:11:51,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Working directory for job is: /galaxy/server/database/jobs_directory/000/286
galaxy.jobs.runners DEBUG 2024-11-03 07:11:51,605 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [286] queued (30.817 ms)
galaxy.jobs.handler INFO 2024-11-03 07:11:51,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:51,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 286
galaxy.jobs DEBUG 2024-11-03 07:11:51,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [286] prepared (85.531 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:11:51,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/286/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/286/registry.xml' '/galaxy/server/database/jobs_directory/000/286/upload_params.json' '378:/galaxy/server/database/objects/a/7/f/dataset_a7f55aec-0890-47cd-be74-46bba6446fa4_files:/galaxy/server/database/objects/a/7/f/dataset_a7f55aec-0890-47cd-be74-46bba6446fa4.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:11:51,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (286) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/286/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/286/galaxy_286.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:51,750 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:51,766 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:11:52,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:01,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-th7bd with k8s id: gxy-th7bd succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:12:01,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 286: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:12:09,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 286 finished
galaxy.model.metadata DEBUG 2024-11-03 07:12:09,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 378
galaxy.jobs INFO 2024-11-03 07:12:09,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 286 in /galaxy/server/database/jobs_directory/000/286
galaxy.jobs DEBUG 2024-11-03 07:12:09,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 286 executed (97.144 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:09,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:12:09,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 287
tpv.core.entities DEBUG 2024-11-03 07:12:09,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:12:09,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:12:09,942 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:12:09,951 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:12:09,963 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Working directory for job is: /galaxy/server/database/jobs_directory/000/287
galaxy.jobs.runners DEBUG 2024-11-03 07:12:09,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [287] queued (27.742 ms)
galaxy.jobs.handler INFO 2024-11-03 07:12:09,972 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:09,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 287
galaxy.jobs DEBUG 2024-11-03 07:12:10,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [287] prepared (66.586 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:10,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:12:10,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:10,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:12:10,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/287/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/287/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/a/7/f/dataset_a7f55aec-0890-47cd-be74-46bba6446fa4.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"     --hw-to-az "6.7e-08" --az-to-hw "5e-09"                 input.vcf.gz  > '/galaxy/server/database/objects/f/b/f/dataset_fbf247d9-7acf-4f6d-b393-3e559788bb27.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:12:10,252 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (287) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/287/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/287/galaxy_287.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:10,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:10,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:12:10,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:10,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:10,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:10,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:20,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5jf2j with k8s id: gxy-5jf2j succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:12:20,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 287: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:12:27,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 287 finished
galaxy.model.metadata DEBUG 2024-11-03 07:12:27,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 379
galaxy.jobs INFO 2024-11-03 07:12:28,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 287 in /galaxy/server/database/jobs_directory/000/287
galaxy.jobs DEBUG 2024-11-03 07:12:28,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 287 executed (95.325 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:28,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:12:29,282 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 288
tpv.core.entities DEBUG 2024-11-03 07:12:29,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:12:29,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:12:29,310 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:12:29,322 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:12:29,336 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Working directory for job is: /galaxy/server/database/jobs_directory/000/288
galaxy.jobs.runners DEBUG 2024-11-03 07:12:29,343 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [288] queued (32.686 ms)
galaxy.jobs.handler INFO 2024-11-03 07:12:29,345 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:29,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 288
galaxy.jobs DEBUG 2024-11-03 07:12:29,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [288] prepared (72.704 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:12:29,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/288/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/288/registry.xml' '/galaxy/server/database/jobs_directory/000/288/upload_params.json' '380:/galaxy/server/database/objects/b/7/0/dataset_b70b1dc9-60a4-440f-ab20-e5cb24741f3f_files:/galaxy/server/database/objects/b/7/0/dataset_b70b1dc9-60a4-440f-ab20-e5cb24741f3f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:12:29,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (288) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/288/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/288/galaxy_288.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:29,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:29,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:29,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:38,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4hb2z with k8s id: gxy-4hb2z succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:12:39,005 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 288: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:12:46,241 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 288 finished
galaxy.model.metadata DEBUG 2024-11-03 07:12:46,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 380
galaxy.jobs INFO 2024-11-03 07:12:46,316 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 288 in /galaxy/server/database/jobs_directory/000/288
galaxy.jobs DEBUG 2024-11-03 07:12:46,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 288 executed (99.814 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:46,373 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:12:46,786 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 289
tpv.core.entities DEBUG 2024-11-03 07:12:46,813 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:12:46,813 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:12:46,817 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:12:46,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:12:46,840 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Working directory for job is: /galaxy/server/database/jobs_directory/000/289
galaxy.jobs.runners DEBUG 2024-11-03 07:12:46,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [289] queued (30.300 ms)
galaxy.jobs.handler INFO 2024-11-03 07:12:46,850 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:46,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 289
galaxy.jobs DEBUG 2024-11-03 07:12:46,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [289] prepared (49.978 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:46,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:12:46,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:46,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:12:46,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/289/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/289/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/b/7/0/dataset_b70b1dc9-60a4-440f-ab20-e5cb24741f3f.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"     --hw-to-az "6.7e-08" --az-to-hw "5e-09"               --output-type r   input.vcf.gz  > '/galaxy/server/database/objects/e/1/1/dataset_e11ed2f3-5b71-4dc3-97f9-18a6bbe66e47.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:12:46,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/289/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/289/galaxy_289.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:46,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:46,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:12:46,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:12:46,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:47,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:47,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:51,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6zgq with k8s id: gxy-n6zgq succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:12:52,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 289: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:12:59,193 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 289 finished
galaxy.model.metadata DEBUG 2024-11-03 07:12:59,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 381
galaxy.jobs INFO 2024-11-03 07:12:59,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 289 in /galaxy/server/database/jobs_directory/000/289
galaxy.jobs DEBUG 2024-11-03 07:12:59,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 289 executed (101.466 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:12:59,327 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:13:01,069 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 290
tpv.core.entities DEBUG 2024-11-03 07:13:01,093 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:13:01,093 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:13:01,098 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:13:01,108 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:13:01,120 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Working directory for job is: /galaxy/server/database/jobs_directory/000/290
galaxy.jobs.runners DEBUG 2024-11-03 07:13:01,126 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [290] queued (28.082 ms)
galaxy.jobs.handler INFO 2024-11-03 07:13:01,129 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:01,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 290
galaxy.jobs DEBUG 2024-11-03 07:13:01,213 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [290] prepared (74.115 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:13:01,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/290/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/290/registry.xml' '/galaxy/server/database/jobs_directory/000/290/upload_params.json' '382:/galaxy/server/database/objects/f/7/3/dataset_f7333315-fe38-4a9b-ba7d-021a1d3dd13d_files:/galaxy/server/database/objects/f/7/3/dataset_f7333315-fe38-4a9b-ba7d-021a1d3dd13d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:13:01,241 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (290) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/290/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/290/galaxy_290.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:01,255 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:01,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:02,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:10,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lp94b with k8s id: gxy-lp94b succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:13:10,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 290: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:13:17,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 290 finished
galaxy.model.metadata DEBUG 2024-11-03 07:13:17,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 382
galaxy.jobs INFO 2024-11-03 07:13:17,334 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 290 in /galaxy/server/database/jobs_directory/000/290
galaxy.jobs DEBUG 2024-11-03 07:13:17,384 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 290 executed (96.359 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:17,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:13:18,411 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 291
tpv.core.entities DEBUG 2024-11-03 07:13:18,437 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:13:18,437 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:13:18,441 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:13:18,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:13:18,469 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Working directory for job is: /galaxy/server/database/jobs_directory/000/291
galaxy.jobs.runners DEBUG 2024-11-03 07:13:18,492 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [291] queued (51.305 ms)
galaxy.jobs.handler INFO 2024-11-03 07:13:18,496 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:18,497 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 291
galaxy.jobs DEBUG 2024-11-03 07:13:18,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [291] prepared (46.359 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:18,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:13:18,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:18,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:13:18,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/291/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/291/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/f/7/3/dataset_f7333315-fe38-4a9b-ba7d-021a1d3dd13d.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"  --ignore-homref --include-noalt  --hw-to-az "6.7e-08" --az-to-hw "5e-09"               --output-type r   input.vcf.gz  > '/galaxy/server/database/objects/e/4/e/dataset_e4e9679b-5a6f-46d5-9418-73d3681e4a32.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:13:18,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (291) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/291/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/291/galaxy_291.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:18,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:18,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:13:18,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:18,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:18,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:19,163 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:23,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dqpcl with k8s id: gxy-dqpcl succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:13:23,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 291: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:13:30,584 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 291 finished
galaxy.model.metadata DEBUG 2024-11-03 07:13:30,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 383
galaxy.jobs INFO 2024-11-03 07:13:30,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 291 in /galaxy/server/database/jobs_directory/000/291
galaxy.jobs DEBUG 2024-11-03 07:13:30,712 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 291 executed (107.402 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:30,758 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:13:31,704 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 292
tpv.core.entities DEBUG 2024-11-03 07:13:31,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:13:31,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:13:31,733 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:13:31,745 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:13:31,760 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Working directory for job is: /galaxy/server/database/jobs_directory/000/292
galaxy.jobs.runners DEBUG 2024-11-03 07:13:31,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [292] queued (34.034 ms)
galaxy.jobs.handler INFO 2024-11-03 07:13:31,770 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:31,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 292
galaxy.jobs DEBUG 2024-11-03 07:13:31,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [292] prepared (78.399 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:13:31,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/292/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/292/registry.xml' '/galaxy/server/database/jobs_directory/000/292/upload_params.json' '384:/galaxy/server/database/objects/8/5/2/dataset_852e5ddd-48f3-41c2-9c98-22cd099c1edc_files:/galaxy/server/database/objects/8/5/2/dataset_852e5ddd-48f3-41c2-9c98-22cd099c1edc.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:13:31,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (292) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/292/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/292/galaxy_292.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:31,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:31,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:32,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:41,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zc4cf with k8s id: gxy-zc4cf succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:13:41,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 292: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:13:48,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 292 finished
galaxy.model.metadata DEBUG 2024-11-03 07:13:49,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 384
galaxy.jobs INFO 2024-11-03 07:13:49,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 292 in /galaxy/server/database/jobs_directory/000/292
galaxy.jobs DEBUG 2024-11-03 07:13:49,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 292 executed (112.704 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:49,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:13:50,060 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 293
tpv.core.entities DEBUG 2024-11-03 07:13:50,089 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:13:50,089 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:13:50,092 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:13:50,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:13:50,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Working directory for job is: /galaxy/server/database/jobs_directory/000/293
galaxy.jobs.runners DEBUG 2024-11-03 07:13:50,127 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [293] queued (34.486 ms)
galaxy.jobs.handler INFO 2024-11-03 07:13:50,129 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:50,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 293
galaxy.jobs DEBUG 2024-11-03 07:13:50,181 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [293] prepared (42.732 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:50,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:13:50,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:50,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:13:50,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/293/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/293/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/8/5/2/dataset_852e5ddd-48f3-41c2-9c98-22cd099c1edc.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"     --hw-to-az "6.7e-08" --az-to-hw "5e-09"     --regions-overlap 1             input.vcf.gz  > '/galaxy/server/database/objects/3/f/d/dataset_3fdeeb4b-cecf-4723-a9b0-bbc84b28da31.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:13:50,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (293) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/293/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/293/galaxy_293.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:50,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:50,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:13:50,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-03 07:13:50,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:50,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:50,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:13:54,480 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ppjbg with k8s id: gxy-ppjbg succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:13:54,596 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 293: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:14:01,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 293 finished
galaxy.model.metadata DEBUG 2024-11-03 07:14:01,788 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 385
galaxy.jobs INFO 2024-11-03 07:14:01,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 293 in /galaxy/server/database/jobs_directory/000/293
galaxy.jobs DEBUG 2024-11-03 07:14:01,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 293 executed (110.715 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:01,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:14:04,430 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 295, 294
tpv.core.entities DEBUG 2024-11-03 07:14:04,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:14:04,455 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:14:04,459 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:14:04,470 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:14:04,485 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Working directory for job is: /galaxy/server/database/jobs_directory/000/294
galaxy.jobs.runners DEBUG 2024-11-03 07:14:04,492 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [294] queued (33.037 ms)
galaxy.jobs.handler INFO 2024-11-03 07:14:04,495 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,498 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 294
tpv.core.entities DEBUG 2024-11-03 07:14:04,507 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:14:04,507 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:14:04,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:14:04,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:14:04,548 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Working directory for job is: /galaxy/server/database/jobs_directory/000/295
galaxy.jobs.runners DEBUG 2024-11-03 07:14:04,556 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [295] queued (44.524 ms)
galaxy.jobs.handler INFO 2024-11-03 07:14:04,559 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 295
galaxy.jobs DEBUG 2024-11-03 07:14:04,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [294] prepared (93.413 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:14:04,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/294/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/294/registry.xml' '/galaxy/server/database/jobs_directory/000/294/upload_params.json' '386:/galaxy/server/database/objects/9/0/6/dataset_906ef359-d217-4873-8187-f9e09da361c2_files:/galaxy/server/database/objects/9/0/6/dataset_906ef359-d217-4873-8187-f9e09da361c2.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:14:04,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (294) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/294/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/294/galaxy_294.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:14:04,648 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [295] prepared (77.117 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,651 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,665 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:14:04,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/295/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/295/registry.xml' '/galaxy/server/database/jobs_directory/000/295/upload_params.json' '387:/galaxy/server/database/objects/0/5/0/dataset_05038a81-c07d-45c2-97e0-3aad7f65d74c_files:/galaxy/server/database/objects/0/5/0/dataset_05038a81-c07d-45c2-97e0-3aad7f65d74c.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:14:04,681 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (295) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/295/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/295/galaxy_295.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:04,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:05,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:05,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:14,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rh5s9 with k8s id: gxy-rh5s9 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:14,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ckgc5 with k8s id: gxy-ckgc5 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:14:14,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 294: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:14:14,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 295: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:14:22,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 295 finished
galaxy.model.metadata DEBUG 2024-11-03 07:14:22,527 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 387
galaxy.jobs.runners DEBUG 2024-11-03 07:14:22,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 294 finished
galaxy.jobs INFO 2024-11-03 07:14:22,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 295 in /galaxy/server/database/jobs_directory/000/295
galaxy.model.metadata DEBUG 2024-11-03 07:14:22,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 386
galaxy.jobs INFO 2024-11-03 07:14:22,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 294 in /galaxy/server/database/jobs_directory/000/294
galaxy.jobs DEBUG 2024-11-03 07:14:22,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 295 executed (117.566 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:22,638 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:14:22,673 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 294 executed (112.249 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:22,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:14:23,926 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 296
tpv.core.entities DEBUG 2024-11-03 07:14:23,955 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:14:23,955 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:14:23,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:14:23,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:14:23,981 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Working directory for job is: /galaxy/server/database/jobs_directory/000/296
galaxy.jobs.runners DEBUG 2024-11-03 07:14:23,991 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [296] queued (30.894 ms)
galaxy.jobs.handler INFO 2024-11-03 07:14:23,993 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:23,995 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 296
galaxy.jobs DEBUG 2024-11-03 07:14:24,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [296] prepared (45.691 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:14:24,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:14:24,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:14:24,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:14:24,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/296/tool_script.sh] for tool command [vcfintersect -b '/galaxy/server/database/objects/0/5/0/dataset_05038a81-c07d-45c2-97e0-3aad7f65d74c.dat'  '/galaxy/server/database/objects/9/0/6/dataset_906ef359-d217-4873-8187-f9e09da361c2.dat' > '/galaxy/server/database/objects/9/9/4/dataset_994f9e1f-2f9e-4b98-8787-f5ca003da2f0.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:14:24,289 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (296) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/296/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/296/galaxy_296.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:24,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:14:24,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:14:24,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:14:24,328 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:24,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:24,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:35,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mv7zw with k8s id: gxy-mv7zw succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:14:36,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 296: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:14:43,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 296 finished
galaxy.model.metadata DEBUG 2024-11-03 07:14:43,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 388
galaxy.jobs INFO 2024-11-03 07:14:43,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 296 in /galaxy/server/database/jobs_directory/000/296
galaxy.jobs DEBUG 2024-11-03 07:14:43,388 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 296 executed (102.261 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:43,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:14:44,332 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 297
tpv.core.entities DEBUG 2024-11-03 07:14:44,356 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:14:44,356 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:14:44,359 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:14:44,369 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:14:44,383 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Working directory for job is: /galaxy/server/database/jobs_directory/000/297
galaxy.jobs.runners DEBUG 2024-11-03 07:14:44,390 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [297] queued (30.077 ms)
galaxy.jobs.handler INFO 2024-11-03 07:14:44,392 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:44,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 297
galaxy.jobs DEBUG 2024-11-03 07:14:44,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [297] prepared (73.650 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:14:44,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/297/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/297/registry.xml' '/galaxy/server/database/jobs_directory/000/297/upload_params.json' '389:/galaxy/server/database/objects/2/f/2/dataset_2f2cc08d-380e-4db9-bc72-7b4fc65587b9_files:/galaxy/server/database/objects/2/f/2/dataset_2f2cc08d-380e-4db9-bc72-7b4fc65587b9.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:14:44,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (297) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/297/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/297/galaxy_297.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:44,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:44,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:45,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:14:53,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-h6sks with k8s id: gxy-h6sks succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:14:53,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 297: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:15:01,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 297 finished
galaxy.model.metadata DEBUG 2024-11-03 07:15:01,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 389
galaxy.jobs INFO 2024-11-03 07:15:01,098 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 297 in /galaxy/server/database/jobs_directory/000/297
galaxy.jobs DEBUG 2024-11-03 07:15:01,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 297 executed (101.679 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:01,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:15:01,693 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 298
tpv.core.entities DEBUG 2024-11-03 07:15:01,722 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:01,723 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:01,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:01,739 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:01,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Working directory for job is: /galaxy/server/database/jobs_directory/000/298
galaxy.jobs.runners DEBUG 2024-11-03 07:15:01,765 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [298] queued (38.372 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:01,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:01,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 298
galaxy.jobs DEBUG 2024-11-03 07:15:01,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [298] prepared (51.526 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:01,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:15:01,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:02,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:15:02,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/298/tool_script.sh] for tool command [vcfintersect -R '20:1-30000'  '/galaxy/server/database/objects/2/f/2/dataset_2f2cc08d-380e-4db9-bc72-7b4fc65587b9.dat' > '/galaxy/server/database/objects/f/a/1/dataset_fa175f41-19ea-420a-a29b-f649d72a85a4.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:02,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (298) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/298/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/298/galaxy_298.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:02,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:02,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:15:02,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:02,284 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:02,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:02,621 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:06,696 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pj9w7 with k8s id: gxy-pj9w7 succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:15:06,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 298: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:15:14,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 298 finished
galaxy.model.metadata DEBUG 2024-11-03 07:15:14,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 390
galaxy.jobs INFO 2024-11-03 07:15:14,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 298 in /galaxy/server/database/jobs_directory/000/298
galaxy.jobs DEBUG 2024-11-03 07:15:14,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 298 executed (104.599 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:14,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:15:16,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 299
tpv.core.entities DEBUG 2024-11-03 07:15:16,034 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:16,034 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:16,038 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:16,049 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:16,063 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Working directory for job is: /galaxy/server/database/jobs_directory/000/299
galaxy.jobs.runners DEBUG 2024-11-03 07:15:16,069 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [299] queued (31.498 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:16,072 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:16,073 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 299
galaxy.jobs DEBUG 2024-11-03 07:15:16,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [299] prepared (74.883 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:15:16,175 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/299/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/299/registry.xml' '/galaxy/server/database/jobs_directory/000/299/upload_params.json' '391:/galaxy/server/database/objects/7/a/3/dataset_7a3f6a2b-4799-4415-ab6a-fc0b3cc312eb_files:/galaxy/server/database/objects/7/a/3/dataset_7a3f6a2b-4799-4415-ab6a-fc0b3cc312eb.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:16,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (299) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/299/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/299/galaxy_299.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:16,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:16,217 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:16,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-03 07:15:17,075 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 301, 300
tpv.core.entities DEBUG 2024-11-03 07:15:17,101 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:17,102 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:17,105 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:17,117 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:17,132 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Working directory for job is: /galaxy/server/database/jobs_directory/000/300
galaxy.jobs.runners DEBUG 2024-11-03 07:15:17,140 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [300] queued (34.459 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:17,142 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 300
tpv.core.entities DEBUG 2024-11-03 07:15:17,152 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:17,152 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:17,157 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:17,169 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:17,195 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Working directory for job is: /galaxy/server/database/jobs_directory/000/301
galaxy.jobs.runners DEBUG 2024-11-03 07:15:17,202 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [301] queued (44.338 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:17,205 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 301
galaxy.jobs DEBUG 2024-11-03 07:15:17,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [300] prepared (103.515 ms)
galaxy.jobs.command_factory INFO 2024-11-03 07:15:17,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/300/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/300/registry.xml' '/galaxy/server/database/jobs_directory/000/300/upload_params.json' '392:/galaxy/server/database/objects/b/1/e/dataset_b1eb570c-d761-467d-9f99-e7843fbe570b_files:/galaxy/server/database/objects/b/1/e/dataset_b1eb570c-d761-467d-9f99-e7843fbe570b.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:17,297 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (300) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/300/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/300/galaxy_300.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:15:17,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [301] prepared (88.691 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,313 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,328 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:15:17,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/301/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/301/registry.xml' '/galaxy/server/database/jobs_directory/000/301/upload_params.json' '393:/galaxy/server/database/objects/0/f/3/dataset_0f31e048-f265-42a7-a9f8-d643bc305c8d_files:/galaxy/server/database/objects/0/f/3/dataset_0f31e048-f265-42a7-a9f8-d643bc305c8d.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:17,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (301) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/301/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/301/galaxy_301.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,796 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:17,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:27,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bzz62 with k8s id: gxy-bzz62 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:27,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vszzm with k8s id: gxy-vszzm succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:15:27,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 299: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:15:27,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 300: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:28,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ddxnq with k8s id: gxy-ddxnq succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:15:28,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 301: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:15:38,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 299 finished
galaxy.jobs.runners DEBUG 2024-11-03 07:15:38,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 300 finished
galaxy.model.metadata DEBUG 2024-11-03 07:15:38,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 391
galaxy.model.metadata DEBUG 2024-11-03 07:15:38,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 392
galaxy.jobs INFO 2024-11-03 07:15:38,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 299 in /galaxy/server/database/jobs_directory/000/299
galaxy.jobs INFO 2024-11-03 07:15:38,181 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 300 in /galaxy/server/database/jobs_directory/000/300
galaxy.jobs DEBUG 2024-11-03 07:15:38,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 299 executed (128.526 ms)
galaxy.jobs DEBUG 2024-11-03 07:15:38,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 300 executed (121.148 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:38,243 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:38,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:15:39,095 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 301 finished
galaxy.model.metadata DEBUG 2024-11-03 07:15:39,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 393
galaxy.jobs INFO 2024-11-03 07:15:39,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 301 in /galaxy/server/database/jobs_directory/000/301
galaxy.jobs DEBUG 2024-11-03 07:15:39,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 301 executed (100.085 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:39,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:15:39,835 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 302
tpv.core.entities DEBUG 2024-11-03 07:15:39,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:39,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:39,871 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:39,882 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:39,898 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Working directory for job is: /galaxy/server/database/jobs_directory/000/302
galaxy.jobs.runners DEBUG 2024-11-03 07:15:39,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [302] queued (37.298 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:39,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:39,913 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 302
galaxy.jobs DEBUG 2024-11-03 07:15:39,969 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [302] prepared (47.661 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:39,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:15:39,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:39,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:15:40,020 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/302/tool_script.sh] for tool command [ln -s '/galaxy/server/database/objects/0/f/3/dataset_0f31e048-f265-42a7-a9f8-d643bc305c8d.dat' 'localref.fa' &&  vcfintersect   -r 'localref.fa' -w "30" -i '/galaxy/server/database/objects/7/a/3/dataset_7a3f6a2b-4799-4415-ab6a-fc0b3cc312eb.dat' '/galaxy/server/database/objects/b/1/e/dataset_b1eb570c-d761-467d-9f99-e7843fbe570b.dat' > '/galaxy/server/database/objects/d/4/e/dataset_d4e07c65-b482-48be-8860-8645b29fb2de.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:40,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (302) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/302/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/302/galaxy_302.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:40,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:40,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:15:40,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:15:40,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:40,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:40,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:45,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hwzsw with k8s id: gxy-hwzsw succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:15:45,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 302: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:15:52,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 302 finished
galaxy.model.metadata DEBUG 2024-11-03 07:15:52,787 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 394
galaxy.jobs INFO 2024-11-03 07:15:52,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 302 in /galaxy/server/database/jobs_directory/000/302
galaxy.jobs DEBUG 2024-11-03 07:15:52,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 302 executed (90.474 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:52,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:15:54,121 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 305, 304, 303
tpv.core.entities DEBUG 2024-11-03 07:15:54,146 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:54,146 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:54,150 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:54,163 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:54,179 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Working directory for job is: /galaxy/server/database/jobs_directory/000/303
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,187 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [303] queued (37.448 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:54,190 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,194 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 303
tpv.core.entities DEBUG 2024-11-03 07:15:54,202 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:54,202 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:54,206 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:54,217 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:54,238 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Working directory for job is: /galaxy/server/database/jobs_directory/000/304
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [304] queued (39.158 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:54,248 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,252 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 304
tpv.core.entities DEBUG 2024-11-03 07:15:54,266 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:15:54,267 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:15:54,270 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:15:54,282 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:15:54,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [303] prepared (100.070 ms)
galaxy.jobs DEBUG 2024-11-03 07:15:54,312 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Working directory for job is: /galaxy/server/database/jobs_directory/000/305
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,321 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [305] queued (50.536 ms)
galaxy.jobs.handler INFO 2024-11-03 07:15:54,324 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,327 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 305
galaxy.jobs.command_factory INFO 2024-11-03 07:15:54,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/303/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/303/registry.xml' '/galaxy/server/database/jobs_directory/000/303/upload_params.json' '395:/galaxy/server/database/objects/e/2/1/dataset_e21085f0-7081-4914-b665-f07427f201f3_files:/galaxy/server/database/objects/e/2/1/dataset_e21085f0-7081-4914-b665-f07427f201f3.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (303) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/303/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/303/galaxy_303.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-03 07:15:54,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [304] prepared (88.645 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:15:54,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/304/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/304/registry.xml' '/galaxy/server/database/jobs_directory/000/304/upload_params.json' '396:/galaxy/server/database/objects/a/e/a/dataset_aead7d4d-0d2c-4686-8339-c52a84ca9709_files:/galaxy/server/database/objects/a/e/a/dataset_aead7d4d-0d2c-4686-8339-c52a84ca9709.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (304) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/304/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/304/galaxy_304.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-03 07:15:54,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [305] prepared (88.444 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-03 07:15:54,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/305/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/305/registry.xml' '/galaxy/server/database/jobs_directory/000/305/upload_params.json' '397:/galaxy/server/database/objects/f/0/1/dataset_f014de4f-e326-40aa-a937-3c948e07df2f_files:/galaxy/server/database/objects/f/0/1/dataset_f014de4f-e326-40aa-a937-3c948e07df2f.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:15:54,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (305) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/305/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/305/galaxy_305.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,464 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:54,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:55,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:55,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:15:55,484 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:03,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tssnx with k8s id: gxy-tssnx succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:16:04,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 303: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:04,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lfr4b with k8s id: gxy-lfr4b succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:04,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-chwhj with k8s id: gxy-chwhj succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:16:05,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 304: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:16:05,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 305: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:16:14,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 303 finished
galaxy.model.metadata DEBUG 2024-11-03 07:16:14,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 395
galaxy.jobs INFO 2024-11-03 07:16:14,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 303 in /galaxy/server/database/jobs_directory/000/303
galaxy.jobs DEBUG 2024-11-03 07:16:14,958 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 303 executed (140.938 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:14,971 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:16:15,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 304 finished
galaxy.model.metadata DEBUG 2024-11-03 07:16:15,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 396
galaxy.jobs INFO 2024-11-03 07:16:15,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 304 in /galaxy/server/database/jobs_directory/000/304
galaxy.jobs DEBUG 2024-11-03 07:16:15,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 304 executed (100.152 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:15,873 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-03 07:16:15,874 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 305 finished
galaxy.model.metadata DEBUG 2024-11-03 07:16:15,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 397
galaxy.jobs INFO 2024-11-03 07:16:15,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 305 in /galaxy/server/database/jobs_directory/000/305
galaxy.jobs DEBUG 2024-11-03 07:16:15,997 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 305 executed (100.983 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:16,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-03 07:16:16,812 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 306
tpv.core.entities DEBUG 2024-11-03 07:16:16,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-03 07:16:16,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (306) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-03 07:16:16,852 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (306) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-03 07:16:16,865 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (306) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-03 07:16:16,882 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (306) Working directory for job is: /galaxy/server/database/jobs_directory/000/306
galaxy.jobs.runners DEBUG 2024-11-03 07:16:16,892 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [306] queued (39.447 ms)
galaxy.jobs.handler INFO 2024-11-03 07:16:16,894 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (306) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:16,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 306
galaxy.jobs DEBUG 2024-11-03 07:16:16,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [306] prepared (52.016 ms)
galaxy.tool_util.deps.containers INFO 2024-11-03 07:16:16,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:16:16,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:16:16,981 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-03 07:16:17,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/306/tool_script.sh] for tool command [ln -s '/galaxy/server/database/objects/f/0/1/dataset_f014de4f-e326-40aa-a937-3c948e07df2f.dat' 'localref.fa' &&  vcfintersect   -r 'localref.fa' -w "30" -u '/galaxy/server/database/objects/e/2/1/dataset_e21085f0-7081-4914-b665-f07427f201f3.dat' '/galaxy/server/database/objects/a/e/a/dataset_aead7d4d-0d2c-4686-8339-c52a84ca9709.dat' > '/galaxy/server/database/objects/b/d/b/dataset_bdba8777-6c88-4126-bba0-3cc77c3d2702.dat']
galaxy.jobs.runners DEBUG 2024-11-03 07:16:17,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (306) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/306/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/306/galaxy_306.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:17,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 306 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-03 07:16:17,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-03 07:16:17,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-03 07:16:17,051 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:17,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 306 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:18,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:22,090 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-c9mbc with k8s id: gxy-c9mbc succeeded
galaxy.jobs.runners DEBUG 2024-11-03 07:16:22,243 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 306: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-03 07:16:29,574 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 306 finished
galaxy.model.metadata DEBUG 2024-11-03 07:16:29,619 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 398
galaxy.jobs INFO 2024-11-03 07:16:29,654 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 306 in /galaxy/server/database/jobs_directory/000/306
galaxy.jobs DEBUG 2024-11-03 07:16:29,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 306 executed (108.022 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-03 07:16:29,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 306 is an interactive tool. guest ports: []. interactive entry points: []
