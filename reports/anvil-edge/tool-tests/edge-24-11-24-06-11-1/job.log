galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:34:54,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2mtsp with k8s id: gxy-2mtsp succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:34:55,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 33: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:02,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 33 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_cutadapt_trimmed_sequences_plot_Counts.txt] with element identifier [cutadapt_trimmed_sequences_plot_Counts] for output [plots] (39.480 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,203 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_cutadapt_trimmed_sequences_plot_Obs_Exp.txt] with element identifier [cutadapt_trimmed_sequences_plot_Obs_Exp] for output [plots] (0.498 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,203 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-duprates-plot_1.txt] with element identifier [fastp-duprates-plot_1] for output [plots] (0.399 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-insert-size-plot_1.txt] with element identifier [fastp-insert-size-plot_1] for output [plots] (0.340 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-gc-plot_Read_1_After_filtering.txt] with element identifier [fastp-seq-content-gc-plot_Read_1_After_filtering] for output [plots] (0.390 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-gc-plot_Read_1_Before_filtering.txt] with element identifier [fastp-seq-content-gc-plot_Read_1_Before_filtering] for output [plots] (0.341 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-gc-plot_Read_2_After_filtering.txt] with element identifier [fastp-seq-content-gc-plot_Read_2_After_filtering] for output [plots] (0.683 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-gc-plot_Read_2_Before_filtering.txt] with element identifier [fastp-seq-content-gc-plot_Read_2_Before_filtering] for output [plots] (0.594 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-n-plot_Read_1_After_filtering.txt] with element identifier [fastp-seq-content-n-plot_Read_1_After_filtering] for output [plots] (0.384 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-n-plot_Read_1_Before_filtering.txt] with element identifier [fastp-seq-content-n-plot_Read_1_Before_filtering] for output [plots] (0.498 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-n-plot_Read_2_After_filtering.txt] with element identifier [fastp-seq-content-n-plot_Read_2_After_filtering] for output [plots] (0.365 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-content-n-plot_Read_2_Before_filtering.txt] with element identifier [fastp-seq-content-n-plot_Read_2_Before_filtering] for output [plots] (0.363 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-quality-plot_Read_1_After_filtering.txt] with element identifier [fastp-seq-quality-plot_Read_1_After_filtering] for output [plots] (0.322 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-quality-plot_Read_1_Before_filtering.txt] with element identifier [fastp-seq-quality-plot_Read_1_Before_filtering] for output [plots] (0.346 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-quality-plot_Read_2_After_filtering.txt] with element identifier [fastp-seq-quality-plot_Read_2_After_filtering] for output [plots] (0.346 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp-seq-quality-plot_Read_2_Before_filtering.txt] with element identifier [fastp-seq-quality-plot_Read_2_Before_filtering] for output [plots] (0.365 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastp_filtered_reads_plot_1.txt] with element identifier [fastp_filtered_reads_plot_1] for output [plots] (0.331 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_per_base_n_content_plot_1.txt] with element identifier [fastqc_per_base_n_content_plot_1] for output [plots] (0.326 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_per_base_sequence_quality_plot_1.txt] with element identifier [fastqc_per_base_sequence_quality_plot_1] for output [plots] (0.351 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Counts.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Counts] for output [plots] (0.333 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Percentages.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Percentages] for output [plots] (0.332 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_per_sequence_quality_scores_plot_1.txt] with element identifier [fastqc_per_sequence_quality_scores_plot_1] for output [plots] (0.339 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_sequence_counts_plot_1.txt] with element identifier [fastqc_sequence_counts_plot_1] for output [plots] (2.396 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_fastqc_sequence_duplication_levels_plot_1.txt] with element identifier [fastqc_sequence_duplication_levels_plot_1] for output [plots] (0.382 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_flexbar_plot_1.txt] with element identifier [flexbar_plot_1] for output [plots] (0.347 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_overallratesplot_Minus_Strand_-.txt] with element identifier [overallratesplot_Minus_Strand_-] for output [plots] (0.321 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_overallratesplot_Plus_Strand_.txt] with element identifier [overallratesplot_Plus_Strand_] for output [plots] (0.337 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_sortmerna-detailed-plot_1.txt] with element identifier [sortmerna-detailed-plot_1] for output [plots] (0.334 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/mqc_trimmomatic_plot_1.txt] with element identifier [trimmomatic_plot_1] for output [plots] (0.324 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,490 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Add dynamic collection datasets to history for output [plots] (271.784 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_cutadapt.txt] with element identifier [cutadapt] for output [stats] (0.633 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_fastp.txt] with element identifier [fastp] for output [stats] (0.463 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_fastqc.txt] with element identifier [fastqc] for output [stats] (0.401 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_flexbar.txt] with element identifier [flexbar] for output [stats] (0.381 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (0.548 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_slamdunk_readrates_minus.txt] with element identifier [slamdunk_readrates_minus] for output [stats] (0.376 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_slamdunk_readrates_plus.txt] with element identifier [slamdunk_readrates_plus] for output [stats] (0.346 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_sortmerna.txt] with element identifier [sortmerna] for output [stats] (0.353 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.361 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/33/working/report_data/multiqc_trimmomatic.txt] with element identifier [trimmomatic] for output [stats] (0.344 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:35:02,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (33) Add dynamic collection datasets to history for output [stats] (81.236 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:35:02,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 33
galaxy.model.metadata DEBUG 2024-11-24 06:35:02,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 34
galaxy.jobs INFO 2024-11-24 06:35:02,972 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 33 in /galaxy/server/database/jobs_directory/000/33
galaxy.jobs DEBUG 2024-11-24 06:35:03,001 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 33 executed (863.389 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:03,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 33 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:35:11,573 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 34, 35, 36, 37
tpv.core.entities DEBUG 2024-11-24 06:35:11,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:11,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (34) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:11,601 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (34) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:11,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (34) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:11,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (34) Working directory for job is: /galaxy/server/database/jobs_directory/000/34
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,632 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [34] queued (30.778 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:11,634 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (34) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 34
tpv.core.entities DEBUG 2024-11-24 06:35:11,643 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:11,643 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (35) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:11,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (35) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:11,657 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (35) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:11,683 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (35) Working directory for job is: /galaxy/server/database/jobs_directory/000/35
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,689 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [35] queued (42.599 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:11,693 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (35) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 35
tpv.core.entities DEBUG 2024-11-24 06:35:11,709 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:11,709 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (36) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:11,712 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (36) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:11,725 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (36) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:11,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [34] prepared (95.865 ms)
galaxy.jobs DEBUG 2024-11-24 06:35:11,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (36) Working directory for job is: /galaxy/server/database/jobs_directory/000/36
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,764 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [36] queued (51.394 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:11,767 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (36) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,769 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 36
galaxy.jobs.command_factory INFO 2024-11-24 06:35:11,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/34/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/34/registry.xml' '/galaxy/server/database/jobs_directory/000/34/upload_params.json' '74:/galaxy/server/database/objects/8/0/7/dataset_8073aec6-641d-4517-9220-32413af17689_files:/galaxy/server/database/objects/8/0/7/dataset_8073aec6-641d-4517-9220-32413af17689.dat']
tpv.core.entities DEBUG 2024-11-24 06:35:11,780 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:11,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (37) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (34) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/34/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/34/galaxy_34.ec; sh -c "exit $return_code"
galaxy.jobs.handler DEBUG 2024-11-24 06:35:11,787 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (37) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:11,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (37) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 34 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:11,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [35] prepared (107.264 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 34 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:11,854 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (37) Working directory for job is: /galaxy/server/database/jobs_directory/000/37
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,862 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [37] queued (73.681 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:35:11,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/35/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/35/registry.xml' '/galaxy/server/database/jobs_directory/000/35/upload_params.json' '75:/galaxy/server/database/objects/0/f/9/dataset_0f9ca391-6e76-48b2-96ef-b008ca8c6311_files:/galaxy/server/database/objects/0/f/9/dataset_0f9ca391-6e76-48b2-96ef-b008ca8c6311.dat']
galaxy.jobs.handler INFO 2024-11-24 06:35:11,865 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (37) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 37
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (35) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/35/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/35/galaxy_35.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:35:11,899 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [36] prepared (110.142 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 35 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:35:11,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/36/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/36/registry.xml' '/galaxy/server/database/jobs_directory/000/36/upload_params.json' '76:/galaxy/server/database/objects/6/3/0/dataset_630e46fe-81d1-4fce-8eb4-5ec58b12bab3_files:/galaxy/server/database/objects/6/3/0/dataset_630e46fe-81d1-4fce-8eb4-5ec58b12bab3.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:11,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (36) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/36/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/36/galaxy_36.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 35 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 36 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:11,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [37] prepared (103.821 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:11,990 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 36 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:35:12,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/37/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/37/registry.xml' '/galaxy/server/database/jobs_directory/000/37/upload_params.json' '77:/galaxy/server/database/objects/0/3/3/dataset_0334e77f-de34-41f1-a0e8-aedacef64c1d_files:/galaxy/server/database/objects/0/3/3/dataset_0334e77f-de34-41f1-a0e8-aedacef64c1d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:12,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (37) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/37/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/37/galaxy_37.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:12,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 37 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:12,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 37 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:12,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:35:12,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 38, 39, 40, 41, 42
tpv.core.entities DEBUG 2024-11-24 06:35:12,892 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:12,893 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (38) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:12,896 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (38) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:12,907 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (38) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:12,919 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (38) Working directory for job is: /galaxy/server/database/jobs_directory/000/38
galaxy.jobs.runners DEBUG 2024-11-24 06:35:12,927 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [38] queued (30.333 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:12,929 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (38) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:12,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 38
tpv.core.entities DEBUG 2024-11-24 06:35:12,937 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:12,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (39) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:12,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (39) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:12,954 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (39) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:12,978 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (39) Working directory for job is: /galaxy/server/database/jobs_directory/000/39
galaxy.jobs.runners DEBUG 2024-11-24 06:35:12,985 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [39] queued (43.561 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:12,987 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (39) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:12,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 39
tpv.core.entities DEBUG 2024-11-24 06:35:13,002 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:13,002 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (40) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:13,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (40) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:13,019 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (40) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:13,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [38] prepared (98.783 ms)
galaxy.jobs DEBUG 2024-11-24 06:35:13,049 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (40) Working directory for job is: /galaxy/server/database/jobs_directory/000/40
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,059 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [40] queued (50.540 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:13,062 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (40) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,066 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 40
galaxy.jobs.command_factory INFO 2024-11-24 06:35:13,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/38/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/38/registry.xml' '/galaxy/server/database/jobs_directory/000/38/upload_params.json' '78:/galaxy/server/database/objects/8/6/7/dataset_867f0283-aad5-4ddc-8d1a-45b0dcc60e61_files:/galaxy/server/database/objects/8/6/7/dataset_867f0283-aad5-4ddc-8d1a-45b0dcc60e61.dat']
tpv.core.entities DEBUG 2024-11-24 06:35:13,080 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:13,080 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (41) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (38) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/38/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/38/galaxy_38.ec; sh -c "exit $return_code"
galaxy.jobs.handler DEBUG 2024-11-24 06:35:13,086 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (41) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:13,099 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (41) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 38 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:13,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [39] prepared (118.184 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 38 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:13,147 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (41) Working directory for job is: /galaxy/server/database/jobs_directory/000/41
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,156 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [41] queued (69.343 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:13,159 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (41) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:35:13,161 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/39/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/39/registry.xml' '/galaxy/server/database/jobs_directory/000/39/upload_params.json' '79:/galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb_files:/galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 41
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (39) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/39/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/39/galaxy_39.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:35:13,184 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:13,185 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (42) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:13,189 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (42) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 39 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:13,209 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (42) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:13,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [40] prepared (130.032 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,231 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 39 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:13,255 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (42) Working directory for job is: /galaxy/server/database/jobs_directory/000/42
galaxy.jobs.command_factory INFO 2024-11-24 06:35:13,258 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/40/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/40/registry.xml' '/galaxy/server/database/jobs_directory/000/40/upload_params.json' '80:/galaxy/server/database/objects/2/e/9/dataset_2e9ae701-85cb-41b9-93c6-759ba6835e59_files:/galaxy/server/database/objects/2/e/9/dataset_2e9ae701-85cb-41b9-93c6-759ba6835e59.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,265 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [42] queued (75.971 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:13,269 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (42) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,284 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 42
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (40) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/40/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/40/galaxy_40.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:35:13,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [41] prepared (142.699 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 40 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:35:13,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/41/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/41/registry.xml' '/galaxy/server/database/jobs_directory/000/41/upload_params.json' '81:/galaxy/server/database/objects/7/3/a/dataset_73a6ed1d-8d42-4c66-81e6-1eba2c0eda42_files:/galaxy/server/database/objects/7/3/a/dataset_73a6ed1d-8d42-4c66-81e6-1eba2c0eda42.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (41) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/41/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/41/galaxy_41.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 40 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 41 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 41 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:13,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [42] prepared (172.050 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:35:13,492 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/42/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/42/registry.xml' '/galaxy/server/database/jobs_directory/000/42/upload_params.json' '82:/galaxy/server/database/objects/0/c/2/dataset_0c25ac74-9c27-45fb-acf3-f2cba16c5b1d_files:/galaxy/server/database/objects/0/c/2/dataset_0c25ac74-9c27-45fb-acf3-f2cba16c5b1d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:13,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (42) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/42/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/42/galaxy_42.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,514 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 42 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 42 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:13,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,273 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 43, 44, 45, 46, 47
tpv.core.entities DEBUG 2024-11-24 06:35:14,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:14,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (43) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,311 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (43) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:14,328 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (43) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:14,341 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (43) Working directory for job is: /galaxy/server/database/jobs_directory/000/43
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,348 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [43] queued (36.786 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:14,350 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (43) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 43
tpv.core.entities DEBUG 2024-11-24 06:35:14,358 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:14,359 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (44) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,363 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (44) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:14,376 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (44) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:14,399 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (44) Working directory for job is: /galaxy/server/database/jobs_directory/000/44
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,409 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [44] queued (46.466 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:14,412 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (44) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 44
tpv.core.entities DEBUG 2024-11-24 06:35:14,434 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:14,434 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (45) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,439 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (45) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:35:14,453 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (45) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:35:14,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [43] prepared (105.035 ms)
galaxy.jobs DEBUG 2024-11-24 06:35:14,494 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (45) Working directory for job is: /galaxy/server/database/jobs_directory/000/45
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,504 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [45] queued (64.554 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:14,509 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (45) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:35:14,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/43/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/43/registry.xml' '/galaxy/server/database/jobs_directory/000/43/upload_params.json' '83:/galaxy/server/database/objects/f/0/d/dataset_f0d497a6-b9e6-46d1-afe6-9e8595264a83_files:/galaxy/server/database/objects/f/0/d/dataset_f0d497a6-b9e6-46d1-afe6-9e8595264a83.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 45
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (43) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/43/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/43/galaxy_43.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:35:14,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:14,541 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (46) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (46) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 43 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,566 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (46) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 43 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,589 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [44] prepared (156.528 ms)
galaxy.jobs DEBUG 2024-11-24 06:35:14,608 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (46) Working directory for job is: /galaxy/server/database/jobs_directory/000/46
galaxy.jobs.command_factory INFO 2024-11-24 06:35:14,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/44/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/44/registry.xml' '/galaxy/server/database/jobs_directory/000/44/upload_params.json' '84:/galaxy/server/database/objects/2/2/1/dataset_221ac837-431a-431d-a38a-c877a4402426_files:/galaxy/server/database/objects/2/2/1/dataset_221ac837-431a-431d-a38a-c877a4402426.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,621 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [46] queued (76.401 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:14,627 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (46) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (44) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/44/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/44/galaxy_44.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 46
tpv.core.entities DEBUG 2024-11-24 06:35:14,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:35:14,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (47) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:35:14,653 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (47) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 44 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,670 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (47) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,678 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 44 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,684 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [45] prepared (145.369 ms)
galaxy.jobs DEBUG 2024-11-24 06:35:14,707 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (47) Working directory for job is: /galaxy/server/database/jobs_directory/000/47
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,715 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [47] queued (61.656 ms)
galaxy.jobs.handler INFO 2024-11-24 06:35:14,717 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (47) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:35:14,717 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/45/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/45/registry.xml' '/galaxy/server/database/jobs_directory/000/45/upload_params.json' '85:/galaxy/server/database/objects/b/1/d/dataset_b1d76188-8af4-4064-9918-352bf71d7f2a_files:/galaxy/server/database/objects/b/1/d/dataset_b1d76188-8af4-4064-9918-352bf71d7f2a.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (45) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/45/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/45/galaxy_45.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 45 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,764 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [46] prepared (109.987 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 45 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 47
galaxy.jobs.command_factory INFO 2024-11-24 06:35:14,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/46/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/46/registry.xml' '/galaxy/server/database/jobs_directory/000/46/upload_params.json' '86:/galaxy/server/database/objects/6/6/8/dataset_6684b415-8316-4951-858a-205844295871_files:/galaxy/server/database/objects/6/6/8/dataset_6684b415-8316-4951-858a-205844295871.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,812 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (46) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/46/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/46/galaxy_46.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 46 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 46 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:14,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [47] prepared (96.400 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:35:14,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/47/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/47/registry.xml' '/galaxy/server/database/jobs_directory/000/47/upload_params.json' '87:/galaxy/server/database/objects/2/7/e/dataset_27e307bf-86ea-422c-b0df-a95142b2e455_files:/galaxy/server/database/objects/2/7/e/dataset_27e307bf-86ea-422c-b0df-a95142b2e455.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:35:14,934 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (47) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/47/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/47/galaxy_47.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 47 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:14,967 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 47 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:15,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:15,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:15,336 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:16,547 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:16,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:16,648 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:16,700 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:16,764 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:23,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-fd4rs with k8s id: gxy-fd4rs succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:35:23,751 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 34: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:24,899 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g8nm2 with k8s id: gxy-g8nm2 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:24,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9gz2t with k8s id: gxy-9gz2t succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:24,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b8h82 with k8s id: gxy-b8h82 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:25,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g88b7 with k8s id: gxy-g88b7 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:35:25,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 35: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:25,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 36: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:25,112 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 37: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:25,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8dzm4 with k8s id: gxy-8dzm4 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:25,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5k4md with k8s id: gxy-5k4md succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:26,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l2mxh with k8s id: gxy-l2mxh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:26,514 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gbn9r with k8s id: gxy-gbn9r succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:26,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-98gdt with k8s id: gxy-98gdt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:26,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6tz6x with k8s id: gxy-6tz6x succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:26,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zqdzh with k8s id: gxy-zqdzh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:27,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8tssr with k8s id: gxy-8tssr succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:27,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-nptgk with k8s id: gxy-nptgk succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:35:37,231 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 34 finished
galaxy.model.metadata DEBUG 2024-11-24 06:35:37,316 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 74
galaxy.jobs INFO 2024-11-24 06:35:37,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 34 in /galaxy/server/database/jobs_directory/000/34
galaxy.jobs DEBUG 2024-11-24 06:35:37,454 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 34 executed (206.835 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:37,466 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 34 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:35:37,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 38: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:39,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 35 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:35:39,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 36 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:35:39,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 37 finished
galaxy.model.metadata DEBUG 2024-11-24 06:35:39,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 75
galaxy.model.metadata DEBUG 2024-11-24 06:35:39,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 76
galaxy.model.metadata DEBUG 2024-11-24 06:35:39,963 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 77
galaxy.jobs INFO 2024-11-24 06:35:39,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 35 in /galaxy/server/database/jobs_directory/000/35
galaxy.jobs INFO 2024-11-24 06:35:39,971 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 36 in /galaxy/server/database/jobs_directory/000/36
galaxy.jobs INFO 2024-11-24 06:35:40,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 37 in /galaxy/server/database/jobs_directory/000/37
galaxy.jobs DEBUG 2024-11-24 06:35:40,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 35 executed (181.271 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:40,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 35 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:40,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 36 executed (190.696 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:40,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 36 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:40,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 37 executed (129.454 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:40,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 37 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:35:40,258 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 39: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:40,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 40: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:40,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 41: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:51,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 38 finished
galaxy.model.metadata DEBUG 2024-11-24 06:35:51,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 78
galaxy.jobs INFO 2024-11-24 06:35:52,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 38 in /galaxy/server/database/jobs_directory/000/38
galaxy.jobs DEBUG 2024-11-24 06:35:52,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 38 executed (279.498 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:52,217 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 38 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:35:52,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 42: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 39 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 40 finished
galaxy.model.metadata DEBUG 2024-11-24 06:35:55,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 79
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 41 finished
galaxy.model.metadata DEBUG 2024-11-24 06:35:55,221 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 80
galaxy.jobs INFO 2024-11-24 06:35:55,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 39 in /galaxy/server/database/jobs_directory/000/39
galaxy.jobs INFO 2024-11-24 06:35:55,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 40 in /galaxy/server/database/jobs_directory/000/40
galaxy.model.metadata DEBUG 2024-11-24 06:35:55,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 81
galaxy.jobs INFO 2024-11-24 06:35:55,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 41 in /galaxy/server/database/jobs_directory/000/41
galaxy.jobs DEBUG 2024-11-24 06:35:55,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 39 executed (199.795 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:55,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 39 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:55,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 40 executed (195.682 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:55,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 40 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:35:55,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 41 executed (123.891 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:35:55,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 41 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 44: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,738 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 43: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:35:55,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 46: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:36:06,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 42 finished
galaxy.model.metadata DEBUG 2024-11-24 06:36:06,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 82
galaxy.jobs INFO 2024-11-24 06:36:07,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 42 in /galaxy/server/database/jobs_directory/000/42
galaxy.jobs DEBUG 2024-11-24 06:36:07,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 42 executed (188.356 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:07,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 42 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:36:07,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 45: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:36:09,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 44 finished
galaxy.model.metadata DEBUG 2024-11-24 06:36:09,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 84
galaxy.jobs INFO 2024-11-24 06:36:09,913 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 44 in /galaxy/server/database/jobs_directory/000/44
galaxy.jobs DEBUG 2024-11-24 06:36:09,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 44 executed (129.578 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:36:10,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 43 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:10,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 44 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:36:10,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 83
galaxy.jobs INFO 2024-11-24 06:36:10,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 43 in /galaxy/server/database/jobs_directory/000/43
galaxy.jobs DEBUG 2024-11-24 06:36:10,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 43 executed (134.198 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:36:10,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 46 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:10,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 43 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:36:10,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 86
galaxy.jobs.runners DEBUG 2024-11-24 06:36:10,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 47: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:36:10,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 46 in /galaxy/server/database/jobs_directory/000/46
galaxy.jobs DEBUG 2024-11-24 06:36:10,431 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 46 executed (218.163 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:10,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 46 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:36:16,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 45 finished
galaxy.model.metadata DEBUG 2024-11-24 06:36:16,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 85
galaxy.jobs INFO 2024-11-24 06:36:16,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 45 in /galaxy/server/database/jobs_directory/000/45
galaxy.jobs DEBUG 2024-11-24 06:36:16,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 45 executed (83.847 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:16,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 45 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:36:17,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 47 finished
galaxy.model.metadata DEBUG 2024-11-24 06:36:17,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 87
galaxy.jobs INFO 2024-11-24 06:36:17,737 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 47 in /galaxy/server/database/jobs_directory/000/47
galaxy.jobs DEBUG 2024-11-24 06:36:17,782 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 47 executed (90.528 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:17,792 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 47 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:36:18,882 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 48
tpv.core.entities DEBUG 2024-11-24 06:36:18,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:18,921 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (48) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:18,925 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (48) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:18,937 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (48) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:18,948 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (48) Working directory for job is: /galaxy/server/database/jobs_directory/000/48
galaxy.jobs.runners DEBUG 2024-11-24 06:36:18,961 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [48] queued (35.774 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:18,964 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (48) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:18,966 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 48
galaxy.jobs DEBUG 2024-11-24 06:36:19,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [48] prepared (120.408 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:36:19,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:36:19,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:36:19,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:36:19,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/48/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/48/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/bismark_0 &&    mkdir 'multiqc_WDir/bismark_0/align_0' &&     ln -s '/galaxy/server/database/objects/8/0/7/dataset_8073aec6-641d-4517-9220-32413af17689.dat' 'multiqc_WDir/bismark_0/align_0/bismark_txt_SE_report.txt' && mkdir multiqc_WDir/bowtie2_1 &&         grep -q '% overall alignment rate' /galaxy/server/database/objects/0/f/9/dataset_0f9ca391-6e76-48b2-96ef-b008ca8c6311.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_1_txt'" && ln -s '/galaxy/server/database/objects/0/f/9/dataset_0f9ca391-6e76-48b2-96ef-b008ca8c6311.dat' 'multiqc_WDir/bowtie2_1/bowtie2_1_txt'  &&       grep -q '% overall alignment rate' /galaxy/server/database/objects/6/3/0/dataset_630e46fe-81d1-4fce-8eb4-5ec58b12bab3.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_2_txt'" && ln -s '/galaxy/server/database/objects/6/3/0/dataset_630e46fe-81d1-4fce-8eb4-5ec58b12bab3.dat' 'multiqc_WDir/bowtie2_1/bowtie2_2_txt'  &&   mkdir multiqc_WDir/hisat2_2 &&         grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/0/3/3/dataset_0334e77f-de34-41f1-a0e8-aedacef64c1d.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_1_txt'" && ln -s '/galaxy/server/database/objects/0/3/3/dataset_0334e77f-de34-41f1-a0e8-aedacef64c1d.dat' 'multiqc_WDir/hisat2_2/hisat2_1_txt'  &&       grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/8/6/7/dataset_867f0283-aad5-4ddc-8d1a-45b0dcc60e61.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_2_txt'" && ln -s '/galaxy/server/database/objects/8/6/7/dataset_867f0283-aad5-4ddc-8d1a-45b0dcc60e61.dat' 'multiqc_WDir/hisat2_2/hisat2_2_txt'  &&   mkdir multiqc_WDir/hicexplorer_3 &&         grep -q 'Min rest. site distance' /galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/6/3/b/dataset_63bdc731-183f-4f0b-9925-37eeafa57bfb.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log_1'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/2/e/9/dataset_2e9ae701-85cb-41b9-93c6-759ba6835e59.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer2_log'" && ln -s '/galaxy/server/database/objects/2/e/9/dataset_2e9ae701-85cb-41b9-93c6-759ba6835e59.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer2_log'  &&   mkdir multiqc_WDir/kallisto_4 &&         grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/7/3/a/dataset_73a6ed1d-8d42-4c66-81e6-1eba2c0eda42.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_1_txt'" && ln -s '/galaxy/server/database/objects/7/3/a/dataset_73a6ed1d-8d42-4c66-81e6-1eba2c0eda42.dat' 'multiqc_WDir/kallisto_4/kallisto_1_txt'  &&       grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/0/c/2/dataset_0c25ac74-9c27-45fb-acf3-f2cba16c5b1d.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_2_txt'" && ln -s '/galaxy/server/database/objects/0/c/2/dataset_0c25ac74-9c27-45fb-acf3-f2cba16c5b1d.dat' 'multiqc_WDir/kallisto_4/kallisto_2_txt'  &&   mkdir multiqc_WDir/macs2_5 &&     grep -q "# This file is generated by MACS" /galaxy/server/database/objects/f/0/d/dataset_f0d497a6-b9e6-46d1-afe6-9e8595264a83.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/f/0/d/dataset_f0d497a6-b9e6-46d1-afe6-9e8595264a83.dat' 'multiqc_WDir/macs2_5/macs_1_txt_peaks.xls' &&    grep -q "# This file is generated by MACS" /galaxy/server/database/objects/2/2/1/dataset_221ac837-431a-431d-a38a-c877a4402426.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/2/2/1/dataset_221ac837-431a-431d-a38a-c877a4402426.dat' 'multiqc_WDir/macs2_5/macs_2_txt_peaks.xls' && mkdir multiqc_WDir/star_6 &&    mkdir 'multiqc_WDir/star_6/log_0' &&     ln -s '/galaxy/server/database/objects/b/1/d/dataset_b1d76188-8af4-4064-9918-352bf71d7f2a.dat' 'multiqc_WDir/star_6/log_0/star_log_txt_Log.final.out' &&   mkdir 'multiqc_WDir/star_6/genecounts_1' &&     ln -s '/galaxy/server/database/objects/6/6/8/dataset_6684b415-8316-4951-858a-205844295871.dat' 'multiqc_WDir/star_6/genecounts_1/star_counts_txt_ReadsPerGene.out.tab' && mkdir multiqc_WDir/tophat_7 &&     ln -s '/galaxy/server/database/objects/2/7/e/dataset_27e307bf-86ea-422c-b0df-a95142b2e455.dat' 'multiqc_WDir/tophat_7/tophat_txtalign_summary.txt' &&  multiqc multiqc_WDir --filename "report"]
galaxy.jobs.runners DEBUG 2024-11-24 06:36:19,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/48/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/48/galaxy_48.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/48/working/report.html" -a -f "/galaxy/server/database/objects/b/7/8/dataset_b785c039-0c47-40a0-b47a-e689003eef81.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/48/working/report.html" "/galaxy/server/database/objects/b/7/8/dataset_b785c039-0c47-40a0-b47a-e689003eef81.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:19,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 48 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:36:19,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:36:19,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:36:19,177 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:19,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 48 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:19,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:27,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mx5 with k8s id: gxy-92mx5 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:36:28,106 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 48: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:36:35,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 48 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_bismark_alignment.txt] with element identifier [bismark_alignment] for output [stats] (16.012 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_bowtie2.txt] with element identifier [bowtie2] for output [stats] (0.501 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_cutadapt.txt] with element identifier [cutadapt] for output [stats] (0.469 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (0.429 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_hicexplorer.txt] with element identifier [hicexplorer] for output [stats] (0.437 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_hisat2.txt] with element identifier [hisat2] for output [stats] (0.403 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_kallisto.txt] with element identifier [kallisto] for output [stats] (0.382 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_macs.txt] with element identifier [macs] for output [stats] (0.403 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.391 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_star.txt] with element identifier [star] for output [stats] (0.537 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,268 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/48/working/report_data/multiqc_tophat.txt.txt] with element identifier [tophat.txt] for output [stats] (0.387 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:36:35,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (48) Add dynamic collection datasets to history for output [stats] (80.245 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:36:35,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 88
galaxy.jobs INFO 2024-11-24 06:36:35,468 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 48 in /galaxy/server/database/jobs_directory/000/48
galaxy.jobs DEBUG 2024-11-24 06:36:35,496 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 48 executed (267.605 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:35,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 48 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:36:38,306 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 51, 50, 49, 52
tpv.core.entities DEBUG 2024-11-24 06:36:38,328 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:38,328 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (49) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:38,331 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (49) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:38,340 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (49) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:38,354 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (49) Working directory for job is: /galaxy/server/database/jobs_directory/000/49
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,360 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [49] queued (28.342 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:38,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (49) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,364 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 49
tpv.core.entities DEBUG 2024-11-24 06:36:38,373 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:38,373 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (50) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:38,377 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (50) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:38,387 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (50) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:38,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (50) Working directory for job is: /galaxy/server/database/jobs_directory/000/50
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,420 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [50] queued (42.789 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:38,422 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (50) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 50
tpv.core.entities DEBUG 2024-11-24 06:36:38,436 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:38,437 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (51) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:38,442 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (51) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:38,458 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (51) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:38,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [49] prepared (96.762 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:38,495 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (51) Working directory for job is: /galaxy/server/database/jobs_directory/000/51
galaxy.jobs.command_factory INFO 2024-11-24 06:36:38,498 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/49/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/49/registry.xml' '/galaxy/server/database/jobs_directory/000/49/upload_params.json' '100:/galaxy/server/database/objects/b/a/2/dataset_ba29cfc9-750a-49e6-81b6-e1d686f2bc65_files:/galaxy/server/database/objects/b/a/2/dataset_ba29cfc9-750a-49e6-81b6-e1d686f2bc65.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,506 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [51] queued (63.955 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (49) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/49/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/49/galaxy_49.ec; sh -c "exit $return_code"
galaxy.jobs.handler INFO 2024-11-24 06:36:38,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (51) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 51
tpv.core.entities DEBUG 2024-11-24 06:36:38,523 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:38,523 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (52) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:38,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (52) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 49 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:38,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [50] prepared (101.772 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:38,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (52) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 49 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:38,572 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/50/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/50/registry.xml' '/galaxy/server/database/jobs_directory/000/50/upload_params.json' '101:/galaxy/server/database/objects/e/3/4/dataset_e347a884-7bee-4409-ba33-6d689d06fe5c_files:/galaxy/server/database/objects/e/3/4/dataset_e347a884-7bee-4409-ba33-6d689d06fe5c.dat']
galaxy.jobs DEBUG 2024-11-24 06:36:38,595 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (52) Working directory for job is: /galaxy/server/database/jobs_directory/000/52
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (50) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/50/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/50/galaxy_50.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,604 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [52] queued (76.650 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:38,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (52) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 52
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 50 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:38,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [51] prepared (120.090 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 50 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:38,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/51/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/51/registry.xml' '/galaxy/server/database/jobs_directory/000/51/upload_params.json' '102:/galaxy/server/database/objects/0/b/6/dataset_0b6e4020-7f79-4c5c-b5ea-34c82b742b86_files:/galaxy/server/database/objects/0/b/6/dataset_0b6e4020-7f79-4c5c-b5ea-34c82b742b86.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (51) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/51/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/51/galaxy_51.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 51 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 51 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:38,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [52] prepared (102.610 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:36:38,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/52/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/52/registry.xml' '/galaxy/server/database/jobs_directory/000/52/upload_params.json' '103:/galaxy/server/database/objects/1/e/b/dataset_1ebb85d4-bd3a-42d5-9c3b-d6cd46ac4964_files:/galaxy/server/database/objects/1/e/b/dataset_1ebb85d4-bd3a-42d5-9c3b-d6cd46ac4964.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:38,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (52) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/52/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/52/galaxy_52.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 52 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:38,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 52 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,096 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:39,611 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 55, 54, 56, 53
tpv.core.entities DEBUG 2024-11-24 06:36:39,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:39,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (53) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:39,639 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (53) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:39,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (53) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:39,662 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (53) Working directory for job is: /galaxy/server/database/jobs_directory/000/53
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [53] queued (29.670 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:39,671 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (53) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 53
tpv.core.entities DEBUG 2024-11-24 06:36:39,682 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:39,682 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (54) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:39,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (54) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:39,699 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (54) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:39,722 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (54) Working directory for job is: /galaxy/server/database/jobs_directory/000/54
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [54] queued (42.140 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:39,732 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (54) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,737 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 54
tpv.core.entities DEBUG 2024-11-24 06:36:39,748 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:39,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (55) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:39,752 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (55) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:39,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (55) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:39,784 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [53] prepared (96.191 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:39,793 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (55) Working directory for job is: /galaxy/server/database/jobs_directory/000/55
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [55] queued (48.370 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:39,804 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (55) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 55
galaxy.jobs.command_factory INFO 2024-11-24 06:36:39,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/53/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/53/registry.xml' '/galaxy/server/database/jobs_directory/000/53/upload_params.json' '104:/galaxy/server/database/objects/a/b/8/dataset_ab84abd8-6149-4eba-837f-e40a10ad2caf_files:/galaxy/server/database/objects/a/b/8/dataset_ab84abd8-6149-4eba-837f-e40a10ad2caf.dat']
tpv.core.entities DEBUG 2024-11-24 06:36:39,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:39,820 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (56) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:39,825 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (56) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (53) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/53/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/53/galaxy_53.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:39,838 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (56) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 53 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:39,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [54] prepared (109.102 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 53 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:39,879 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (56) Working directory for job is: /galaxy/server/database/jobs_directory/000/56
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,886 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [56] queued (60.812 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:39,890 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (56) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 56
galaxy.jobs.command_factory INFO 2024-11-24 06:36:39,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/54/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/54/registry.xml' '/galaxy/server/database/jobs_directory/000/54/upload_params.json' '105:/galaxy/server/database/objects/2/9/d/dataset_29d558a6-9cf7-4eee-944e-66969c673856_files:/galaxy/server/database/objects/2/9/d/dataset_29d558a6-9cf7-4eee-944e-66969c673856.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (54) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/54/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/54/galaxy_54.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 54 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:39,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [55] prepared (118.805 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 54 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:39,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/55/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/55/registry.xml' '/galaxy/server/database/jobs_directory/000/55/upload_params.json' '106:/galaxy/server/database/objects/a/0/1/dataset_a0184e08-dbf6-4087-a27a-43b21221d758_files:/galaxy/server/database/objects/a/0/1/dataset_a0184e08-dbf6-4087-a27a-43b21221d758.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:39,980 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (55) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/55/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/55/galaxy_55.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:39,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 55 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:40,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [56] prepared (100.092 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 55 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:40,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/56/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/56/registry.xml' '/galaxy/server/database/jobs_directory/000/56/upload_params.json' '107:/galaxy/server/database/objects/2/b/4/dataset_2b4e2eda-efa2-4bc2-92a4-391cf8fca390_files:/galaxy/server/database/objects/2/b/4/dataset_2b4e2eda-efa2-4bc2-92a4-391cf8fca390.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:40,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (56) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/56/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/56/galaxy_56.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 56 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 56 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:40,895 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 58, 59, 57
tpv.core.entities DEBUG 2024-11-24 06:36:40,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:40,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (57) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:40,922 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (57) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:40,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (57) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:40,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (57) Working directory for job is: /galaxy/server/database/jobs_directory/000/57
galaxy.jobs.runners DEBUG 2024-11-24 06:36:40,944 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [57] queued (22.453 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:40,947 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (57) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 57
tpv.core.entities DEBUG 2024-11-24 06:36:40,955 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:40,955 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (58) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:40,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (58) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:40,968 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (58) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:40,987 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (58) Working directory for job is: /galaxy/server/database/jobs_directory/000/58
galaxy.jobs.runners DEBUG 2024-11-24 06:36:40,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [58] queued (34.729 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:40,996 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (58) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:40,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 58
tpv.core.entities DEBUG 2024-11-24 06:36:41,013 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:41,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (59) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:41,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (59) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:41,029 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (59) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:41,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [57] prepared (96.065 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:41,064 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (59) Working directory for job is: /galaxy/server/database/jobs_directory/000/59
galaxy.jobs.runners DEBUG 2024-11-24 06:36:41,070 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [59] queued (51.569 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:41,073 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (59) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,075 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 59
galaxy.jobs.command_factory INFO 2024-11-24 06:36:41,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/57/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/57/registry.xml' '/galaxy/server/database/jobs_directory/000/57/upload_params.json' '108:/galaxy/server/database/objects/8/e/4/dataset_8e445ec0-1f96-4118-85c2-b4dc14eef609_files:/galaxy/server/database/objects/8/e/4/dataset_8e445ec0-1f96-4118-85c2-b4dc14eef609.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:41,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (57) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/57/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/57/galaxy_57.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:41,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [58] prepared (94.951 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 57 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 57 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:41,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/58/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/58/registry.xml' '/galaxy/server/database/jobs_directory/000/58/upload_params.json' '109:/galaxy/server/database/objects/3/6/e/dataset_36e491a5-5295-4b53-a3ae-761c7abc4437_files:/galaxy/server/database/objects/3/6/e/dataset_36e491a5-5295-4b53-a3ae-761c7abc4437.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:41,149 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (58) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/58/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/58/galaxy_58.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 58 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:41,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [59] prepared (94.850 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 58 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:41,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/59/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/59/registry.xml' '/galaxy/server/database/jobs_directory/000/59/upload_params.json' '110:/galaxy/server/database/objects/f/a/0/dataset_fa0b8755-0629-415e-a7d6-e36b0935d2fd_files:/galaxy/server/database/objects/f/a/0/dataset_fa0b8755-0629-415e-a7d6-e36b0935d2fd.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:41,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (59) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/59/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/59/galaxy_59.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 59 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 59 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:41,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,077 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 64, 63, 61, 62, 60
tpv.core.entities DEBUG 2024-11-24 06:36:42,112 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:42,112 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (60) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (60) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:42,128 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (60) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:42,141 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (60) Working directory for job is: /galaxy/server/database/jobs_directory/000/60
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,150 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [60] queued (32.971 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:42,153 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (60) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 60
tpv.core.entities DEBUG 2024-11-24 06:36:42,165 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:42,166 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (61) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,170 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (61) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:42,206 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (61) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:42,231 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (61) Working directory for job is: /galaxy/server/database/jobs_directory/000/61
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,239 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [61] queued (68.936 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:42,242 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (61) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 61
tpv.core.entities DEBUG 2024-11-24 06:36:42,261 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:42,262 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (62) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,300 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (62) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:42,315 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (62) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:42,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [60] prepared (183.521 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:42,358 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (62) Working directory for job is: /galaxy/server/database/jobs_directory/000/62
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,368 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [62] queued (68.418 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:42,404 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (62) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 62
tpv.core.entities DEBUG 2024-11-24 06:36:42,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:42,424 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (63) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,429 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (63) Dispatching to k8s runner
galaxy.jobs.command_factory INFO 2024-11-24 06:36:42,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/60/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/60/registry.xml' '/galaxy/server/database/jobs_directory/000/60/upload_params.json' '111:/galaxy/server/database/objects/7/c/6/dataset_7c6c10ce-769a-49d5-a1ce-08f09559e052_files:/galaxy/server/database/objects/7/c/6/dataset_7c6c10ce-769a-49d5-a1ce-08f09559e052.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (60) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/60/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/60/galaxy_60.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:42,455 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (63) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:42,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [61] prepared (203.771 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,480 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 60 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:42,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/61/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/61/registry.xml' '/galaxy/server/database/jobs_directory/000/61/upload_params.json' '112:/galaxy/server/database/objects/4/1/f/dataset_41f439de-86a8-4a2e-93c3-cfda9f7b4b96_files:/galaxy/server/database/objects/4/1/f/dataset_41f439de-86a8-4a2e-93c3-cfda9f7b4b96.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 60 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:42,520 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (63) Working directory for job is: /galaxy/server/database/jobs_directory/000/63
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,527 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (61) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/61/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/61/galaxy_61.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,531 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [63] queued (99.325 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:42,534 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (63) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 63
tpv.core.entities DEBUG 2024-11-24 06:36:42,553 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:42,553 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (64) Mapped job to destination id: k8s
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 61 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:36:42,561 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (64) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 61 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:42,584 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (64) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:42,594 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [62] prepared (166.237 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:42,622 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (64) Working directory for job is: /galaxy/server/database/jobs_directory/000/64
galaxy.jobs.command_factory INFO 2024-11-24 06:36:42,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/62/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/62/registry.xml' '/galaxy/server/database/jobs_directory/000/62/upload_params.json' '113:/galaxy/server/database/objects/2/6/1/dataset_261fc6bc-dbea-405b-b6e8-ab9929d85f53_files:/galaxy/server/database/objects/2/6/1/dataset_261fc6bc-dbea-405b-b6e8-ab9929d85f53.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,634 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [64] queued (73.186 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:42,637 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (64) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 64
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (62) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/62/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/62/galaxy_62.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 62 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,686 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 62 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:42,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [63] prepared (149.338 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:36:42,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/63/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/63/registry.xml' '/galaxy/server/database/jobs_directory/000/63/upload_params.json' '114:/galaxy/server/database/objects/9/4/d/dataset_94d3c318-5a24-4831-9881-34efe3746f1b_files:/galaxy/server/database/objects/9/4/d/dataset_94d3c318-5a24-4831-9881-34efe3746f1b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (63) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/63/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/63/galaxy_63.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:42,767 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [64] prepared (106.218 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 63 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,790 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 63 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:42,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/64/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/64/registry.xml' '/galaxy/server/database/jobs_directory/000/64/upload_params.json' '115:/galaxy/server/database/objects/3/b/d/dataset_3bddf169-9647-4b31-806a-5bc1ba624062_files:/galaxy/server/database/objects/3/b/d/dataset_3bddf169-9647-4b31-806a-5bc1ba624062.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:42,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (64) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/64/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/64/galaxy_64.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 64 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:42,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 64 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:43,643 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 69, 66, 70, 65, 67, 68
tpv.core.entities DEBUG 2024-11-24 06:36:43,673 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:43,674 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (65) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:43,678 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (65) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:43,690 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (65) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:43,705 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (65) Working directory for job is: /galaxy/server/database/jobs_directory/000/65
galaxy.jobs.runners DEBUG 2024-11-24 06:36:43,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [65] queued (35.609 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:43,716 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (65) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 65
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
tpv.core.entities DEBUG 2024-11-24 06:36:43,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:43,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (66) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:43,750 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (66) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:43,764 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (66) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:43,794 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (66) Working directory for job is: /galaxy/server/database/jobs_directory/000/66
galaxy.jobs.runners DEBUG 2024-11-24 06:36:43,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [66] queued (49.979 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:43,803 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (66) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 66
tpv.core.entities DEBUG 2024-11-24 06:36:43,824 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:43,824 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (67) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:43,828 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (67) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:43,841 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (67) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:43,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [65] prepared (128.885 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:43,876 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (67) Working directory for job is: /galaxy/server/database/jobs_directory/000/67
galaxy.jobs.runners DEBUG 2024-11-24 06:36:43,884 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [67] queued (55.929 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:43,888 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (67) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 67
galaxy.jobs.command_factory INFO 2024-11-24 06:36:43,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/65/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/65/registry.xml' '/galaxy/server/database/jobs_directory/000/65/upload_params.json' '116:/galaxy/server/database/objects/4/f/f/dataset_4ffd45e8-f604-442d-a52e-e2815d298f36_files:/galaxy/server/database/objects/4/f/f/dataset_4ffd45e8-f604-442d-a52e-e2815d298f36.dat']
tpv.core.entities DEBUG 2024-11-24 06:36:43,906 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:43,907 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (68) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:43,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (68) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:36:43,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (65) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/65/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/65/galaxy_65.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:43,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (68) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:43,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [66] prepared (115.217 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 65 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 65 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:43,975 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (68) Working directory for job is: /galaxy/server/database/jobs_directory/000/68
galaxy.jobs.runners DEBUG 2024-11-24 06:36:43,984 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [68] queued (70.560 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:36:43,986 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/66/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/66/registry.xml' '/galaxy/server/database/jobs_directory/000/66/upload_params.json' '117:/galaxy/server/database/objects/b/c/2/dataset_bc261b05-e3bf-4097-b9fd-19f43d375705_files:/galaxy/server/database/objects/b/c/2/dataset_bc261b05-e3bf-4097-b9fd-19f43d375705.dat']
galaxy.jobs.handler INFO 2024-11-24 06:36:43,990 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (68) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:43,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 68
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (66) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/66/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/66/galaxy_66.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:36:44,024 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:44,025 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (69) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:44,029 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (69) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 66 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:44,053 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (69) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 66 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:44,090 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [67] prepared (181.790 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:44,115 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (69) Working directory for job is: /galaxy/server/database/jobs_directory/000/69
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,123 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [69] queued (93.457 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:44,125 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (69) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:36:44,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/67/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/67/registry.xml' '/galaxy/server/database/jobs_directory/000/67/upload_params.json' '118:/galaxy/server/database/objects/8/e/6/dataset_8e60152b-07cc-4102-8db0-6879a69c88f4_files:/galaxy/server/database/objects/8/e/6/dataset_8e60152b-07cc-4102-8db0-6879a69c88f4.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 69
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,145 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (67) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/67/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/67/galaxy_67.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:36:44,159 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:44,162 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (70) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:44,171 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (70) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:44,175 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [68] prepared (157.697 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 67 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:44,194 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (70) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,212 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 67 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:44,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/68/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/68/registry.xml' '/galaxy/server/database/jobs_directory/000/68/upload_params.json' '119:/galaxy/server/database/objects/7/9/b/dataset_79b5ee60-52c8-4e03-a1d6-b002d618df7b_files:/galaxy/server/database/objects/7/9/b/dataset_79b5ee60-52c8-4e03-a1d6-b002d618df7b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (68) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/68/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/68/galaxy_68.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:44,233 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (70) Working directory for job is: /galaxy/server/database/jobs_directory/000/70
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,241 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [70] queued (69.644 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:44,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (70) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 70
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 68 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 68 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:44,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [69] prepared (141.247 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:36:44,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/69/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/69/registry.xml' '/galaxy/server/database/jobs_directory/000/69/upload_params.json' '120:/galaxy/server/database/objects/6/1/8/dataset_6185e629-8393-4b7a-ac26-968f238d1921_files:/galaxy/server/database/objects/6/1/8/dataset_6185e629-8393-4b7a-ac26-968f238d1921.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (69) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/69/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/69/galaxy_69.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,358 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 69 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:44,362 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [70] prepared (103.192 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,374 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 69 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:44,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/70/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/70/registry.xml' '/galaxy/server/database/jobs_directory/000/70/upload_params.json' '121:/galaxy/server/database/objects/2/9/f/dataset_29f38db1-0413-4241-bb5f-8f2295c0dbef_files:/galaxy/server/database/objects/2/9/f/dataset_29f38db1-0413-4241-bb5f-8f2295c0dbef.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:44,392 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (70) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/70/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/70/galaxy_70.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 70 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:44,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 70 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhrhp with k8s id: gxy-bhrhp  pending...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,250 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 76, 75, 74, 72, 71, 73
tpv.core.entities DEBUG 2024-11-24 06:36:45,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (71) Mapped job to destination id: k8s
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7kctr with k8s id: gxy-7kctr  pending...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,283 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (71) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:45,297 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (71) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:45,312 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (71) Working directory for job is: /galaxy/server/database/jobs_directory/000/71
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,319 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [71] queued (35.672 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:45,324 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (71) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 71
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xr2mh with k8s id: gxy-xr2mh  pending...
tpv.core.entities DEBUG 2024-11-24 06:36:45,340 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,342 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (72) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,350 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (72) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:45,366 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (72) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,379 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-npd9d with k8s id: gxy-npd9d  pending...
galaxy.jobs DEBUG 2024-11-24 06:36:45,403 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (72) Working directory for job is: /galaxy/server/database/jobs_directory/000/72
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6tcq with k8s id: gxy-n6tcq  pending...
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,417 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [72] queued (65.806 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:45,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (72) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 72
tpv.core.entities DEBUG 2024-11-24 06:36:45,443 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,444 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (73) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,448 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (73) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vkwwn with k8s id: gxy-vkwwn  pending...
galaxy.jobs DEBUG 2024-11-24 06:36:45,470 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (73) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:45,484 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [71] prepared (140.827 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs DEBUG 2024-11-24 06:36:45,521 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (73) Working directory for job is: /galaxy/server/database/jobs_directory/000/73
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,530 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [73] queued (81.167 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:45,532 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (73) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:36:45,533 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/71/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/71/registry.xml' '/galaxy/server/database/jobs_directory/000/71/upload_params.json' '122:/galaxy/server/database/objects/f/b/3/dataset_fb317675-d3b7-4e05-93ee-9ec37420dbdf_files:/galaxy/server/database/objects/f/b/3/dataset_fb317675-d3b7-4e05-93ee-9ec37420dbdf.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 73
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (71) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/71/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/71/galaxy_71.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:36:45,558 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,559 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (74) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,563 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (74) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:45,580 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (74) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,587 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 71 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 71 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:45,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [72] prepared (182.845 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:45,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (74) Working directory for job is: /galaxy/server/database/jobs_directory/000/74
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,641 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [74] queued (76.925 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 74
galaxy.jobs.handler INFO 2024-11-24 06:36:45,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (74) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:36:45,671 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/72/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/72/registry.xml' '/galaxy/server/database/jobs_directory/000/72/upload_params.json' '123:/galaxy/server/database/objects/3/f/8/dataset_3f87ec80-1272-4666-b0d5-a61d3195e89e_files:/galaxy/server/database/objects/3/f/8/dataset_3f87ec80-1272-4666-b0d5-a61d3195e89e.dat']
tpv.core.entities DEBUG 2024-11-24 06:36:45,679 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,680 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (75) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (75) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (72) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/72/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/72/galaxy_72.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:45,703 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (75) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 72 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:45,737 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [73] prepared (164.991 ms)
galaxy.jobs DEBUG 2024-11-24 06:36:45,761 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (75) Working directory for job is: /galaxy/server/database/jobs_directory/000/75
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [75] queued (88.987 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:45,778 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (75) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 75
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,783 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 72 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:45,785 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/73/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/73/registry.xml' '/galaxy/server/database/jobs_directory/000/73/upload_params.json' '124:/galaxy/server/database/objects/d/5/1/dataset_d51efc6d-0362-402d-ae88-89dfa22e9b37_files:/galaxy/server/database/objects/d/5/1/dataset_d51efc6d-0362-402d-ae88-89dfa22e9b37.dat']
tpv.core.entities DEBUG 2024-11-24 06:36:45,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:45,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (76) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:45,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (76) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (73) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/73/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/73/galaxy_73.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:45,818 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (76) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 73 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:45,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [74] prepared (169.406 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 73 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:45,867 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (76) Working directory for job is: /galaxy/server/database/jobs_directory/000/76
galaxy.jobs.command_factory INFO 2024-11-24 06:36:45,876 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/74/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/74/registry.xml' '/galaxy/server/database/jobs_directory/000/74/upload_params.json' '125:/galaxy/server/database/objects/8/0/d/dataset_80d8043c-3357-43cd-b647-7f200e43d2dd_files:/galaxy/server/database/objects/8/0/d/dataset_80d8043c-3357-43cd-b647-7f200e43d2dd.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,883 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [76] queued (81.539 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:45,890 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (76) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 76
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (74) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/74/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/74/galaxy_74.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 74 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:45,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 74 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:36:45,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [75] prepared (137.244 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:36:45,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/75/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/75/registry.xml' '/galaxy/server/database/jobs_directory/000/75/upload_params.json' '126:/galaxy/server/database/objects/8/8/4/dataset_884af56d-4ae0-45f0-8c28-f0ea32f9eb64_files:/galaxy/server/database/objects/8/8/4/dataset_884af56d-4ae0-45f0-8c28-f0ea32f9eb64.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:45,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (75) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/75/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/75/galaxy_75.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:46,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [76] prepared (110.391 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 75 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:46,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/76/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/76/registry.xml' '/galaxy/server/database/jobs_directory/000/76/upload_params.json' '127:/galaxy/server/database/objects/3/f/e/dataset_3fe08b5f-a8e7-414f-97fe-c98d40300b95_files:/galaxy/server/database/objects/3/f/e/dataset_3fe08b5f-a8e7-414f-97fe-c98d40300b95.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 75 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:36:46,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (76) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/76/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/76/galaxy_76.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,071 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 76 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 76 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhrhp with k8s id: gxy-bhrhp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,871 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7kctr with k8s id: gxy-7kctr  pending...
galaxy.jobs.handler DEBUG 2024-11-24 06:36:46,895 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 78, 77
tpv.core.entities DEBUG 2024-11-24 06:36:46,928 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,930 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xr2mh with k8s id: gxy-xr2mh  pending...
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:46,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (77) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:46,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (77) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:46,951 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (77) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:36:46,965 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (77) Working directory for job is: /galaxy/server/database/jobs_directory/000/77
galaxy.jobs.runners DEBUG 2024-11-24 06:36:46,974 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [77] queued (38.258 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:46,977 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (77) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 77
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:46,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-npd9d with k8s id: gxy-npd9d  pending...
tpv.core.entities DEBUG 2024-11-24 06:36:46,990 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:36:46,991 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (78) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:36:46,995 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (78) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:36:47,012 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (78) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6tcq with k8s id: gxy-n6tcq  pending...
galaxy.jobs DEBUG 2024-11-24 06:36:47,039 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (78) Working directory for job is: /galaxy/server/database/jobs_directory/000/78
galaxy.jobs.runners DEBUG 2024-11-24 06:36:47,052 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [78] queued (57.256 ms)
galaxy.jobs.handler INFO 2024-11-24 06:36:47,056 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (78) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,060 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 78
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vkwwn with k8s id: gxy-vkwwn  pending...
galaxy.jobs DEBUG 2024-11-24 06:36:47,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [77] prepared (119.406 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.command_factory INFO 2024-11-24 06:36:47,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/77/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/77/registry.xml' '/galaxy/server/database/jobs_directory/000/77/upload_params.json' '128:/galaxy/server/database/objects/6/8/2/dataset_6829594c-1ad0-4791-9d29-a008af24182b_files:/galaxy/server/database/objects/6/8/2/dataset_6829594c-1ad0-4791-9d29-a008af24182b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:47,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (77) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/77/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/77/galaxy_77.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:36:47,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [78] prepared (98.925 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,176 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 77 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,189 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-glbz5 with k8s id: gxy-glbz5  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 77 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:36:47,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/78/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/78/registry.xml' '/galaxy/server/database/jobs_directory/000/78/upload_params.json' '129:/galaxy/server/database/objects/b/b/7/dataset_bb7f64d6-c0e3-4706-9a85-ce8cf68f8990_files:/galaxy/server/database/objects/b/b/7/dataset_bb7f64d6-c0e3-4706-9a85-ce8cf68f8990.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:36:47,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (78) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/78/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/78/galaxy_78.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,224 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 78 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 78 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hs578 with k8s id: gxy-hs578  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,528 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:47,681 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-v9pbm with k8s id: gxy-v9pbm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7kctr with k8s id: gxy-7kctr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xr2mh with k8s id: gxy-xr2mh  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-npd9d with k8s id: gxy-npd9d  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,148 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6tcq with k8s id: gxy-n6tcq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vkwwn with k8s id: gxy-vkwwn  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hs578 with k8s id: gxy-hs578  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-v9pbm with k8s id: gxy-v9pbm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:49,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5mhb7 with k8s id: gxy-5mhb7  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:50,792 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-85hdg with k8s id: gxy-85hdg succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:50,806 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-57467 with k8s id: gxy-57467 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:50,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jzhzw with k8s id: gxy-jzhzw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:50,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rqwdd with k8s id: gxy-rqwdd succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:36:51,020 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 49: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:36:51,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 50: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:36:51,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 51: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7kctr with k8s id: gxy-7kctr  pending...
galaxy.jobs.runners DEBUG 2024-11-24 06:36:51,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 52: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,146 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xr2mh with k8s id: gxy-xr2mh  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-npd9d with k8s id: gxy-npd9d  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6tcq with k8s id: gxy-n6tcq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vkwwn with k8s id: gxy-vkwwn  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:51,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:52,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mrn4q with k8s id: gxy-mrn4q succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5q6tc with k8s id: gxy-5q6tc succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,231 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rbxwd with k8s id: gxy-rbxwd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bvl6q with k8s id: gxy-bvl6q succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xdpt4 failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-xdpt4.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 57 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:36:53,599 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-xdpt4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-xdpt4": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9ch87 with k8s id: gxy-9ch87 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-f8kn9 with k8s id: gxy-f8kn9 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:53,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:54,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:55,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g67rl with k8s id: gxy-g67rl succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-68z7d with k8s id: gxy-68z7d succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,231 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9rb7l with k8s id: gxy-9rb7l succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2jcfd with k8s id: gxy-2jcfd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,831 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:56,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:57,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:57,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:58,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:58,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:58,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:58,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:36:59,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhrhp with k8s id: gxy-bhrhp succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-glbz5 with k8s id: gxy-glbz5 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,163 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:00,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g8tkq with k8s id: gxy-g8tkq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:01,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:01,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hs578 with k8s id: gxy-hs578 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:01,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:01,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:02,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:02,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-v9pbm with k8s id: gxy-v9pbm succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:03,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:03,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:03,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5mhb7 with k8s id: gxy-5mhb7 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:04,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7kctr with k8s id: gxy-7kctr succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:04,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xr2mh with k8s id: gxy-xr2mh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:04,809 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-npd9d with k8s id: gxy-npd9d succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:04,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-n6tcq with k8s id: gxy-n6tcq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:04,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vkwwn with k8s id: gxy-vkwwn succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 51 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 50 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:09,059 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 102
galaxy.model.metadata DEBUG 2024-11-24 06:37:09,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 101
galaxy.jobs INFO 2024-11-24 06:37:09,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 51 in /galaxy/server/database/jobs_directory/000/51
galaxy.jobs INFO 2024-11-24 06:37:09,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 50 in /galaxy/server/database/jobs_directory/000/50
galaxy.jobs DEBUG 2024-11-24 06:37:09,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 51 executed (200.711 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 52 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:09,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 51 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:37:09,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 50 executed (192.681 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:09,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 50 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:37:09,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 103
galaxy.jobs INFO 2024-11-24 06:37:09,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 52 in /galaxy/server/database/jobs_directory/000/52
galaxy.jobs DEBUG 2024-11-24 06:37:09,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 52 executed (148.882 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:09,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 52 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,476 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 53: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,527 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 54: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:09,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 55: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:10,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 49 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:10,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 100
galaxy.jobs INFO 2024-11-24 06:37:10,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 49 in /galaxy/server/database/jobs_directory/000/49
galaxy.jobs DEBUG 2024-11-24 06:37:10,219 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 49 executed (193.190 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:10,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 49 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:10,550 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 56: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:11,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpqc8 with k8s id: gxy-zpqc8 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:12,702 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hf2nm with k8s id: gxy-hf2nm succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:12,711 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-92mqr with k8s id: gxy-92mqr succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:12,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ntlnp with k8s id: gxy-ntlnp succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:37:24,401 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 53 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:24,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 104
galaxy.jobs.runners DEBUG 2024-11-24 06:37:24,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 54 finished
galaxy.jobs INFO 2024-11-24 06:37:24,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 53 in /galaxy/server/database/jobs_directory/000/53
galaxy.model.metadata DEBUG 2024-11-24 06:37:24,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 105
galaxy.jobs INFO 2024-11-24 06:37:24,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 54 in /galaxy/server/database/jobs_directory/000/54
galaxy.jobs DEBUG 2024-11-24 06:37:24,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 53 executed (189.077 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:24,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 53 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:37:24,656 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 54 executed (143.165 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:24,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 54 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:24,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 55 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:25,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 106
galaxy.jobs.runners DEBUG 2024-11-24 06:37:25,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 58: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:37:25,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 55 in /galaxy/server/database/jobs_directory/000/55
galaxy.jobs.runners DEBUG 2024-11-24 06:37:25,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 59: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:37:25,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 55 executed (129.621 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:25,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 55 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:25,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 56 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:25,363 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 107
galaxy.jobs INFO 2024-11-24 06:37:25,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 56 in /galaxy/server/database/jobs_directory/000/56
galaxy.jobs.runners DEBUG 2024-11-24 06:37:25,460 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 60: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:37:25,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 56 executed (180.542 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:25,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 56 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:25,821 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 61: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:39,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 58 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:40,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 109
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 59 finished
galaxy.jobs INFO 2024-11-24 06:37:40,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 58 in /galaxy/server/database/jobs_directory/000/58
galaxy.model.metadata DEBUG 2024-11-24 06:37:40,113 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 110
galaxy.jobs DEBUG 2024-11-24 06:37:40,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 58 executed (207.366 ms)
galaxy.jobs INFO 2024-11-24 06:37:40,151 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 59 in /galaxy/server/database/jobs_directory/000/59
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:40,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 58 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:37:40,248 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 59 executed (190.674 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:40,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 59 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 60 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:40,364 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 111
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 62: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:37:40,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 60 in /galaxy/server/database/jobs_directory/000/60
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,464 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 61 finished
galaxy.jobs DEBUG 2024-11-24 06:37:40,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 60 executed (179.814 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:40,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 60 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:37:40,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 112
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,562 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 63: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:37:40,591 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 61 in /galaxy/server/database/jobs_directory/000/61
galaxy.jobs DEBUG 2024-11-24 06:37:40,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 61 executed (158.242 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:40,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 61 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 64: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:40,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 71: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 62 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:55,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 113
galaxy.jobs INFO 2024-11-24 06:37:55,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 62 in /galaxy/server/database/jobs_directory/000/62
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 64 finished
galaxy.jobs DEBUG 2024-11-24 06:37:55,516 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 62 executed (188.510 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:55,533 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 62 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:37:55,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 115
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 63 finished
galaxy.jobs INFO 2024-11-24 06:37:55,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 64 in /galaxy/server/database/jobs_directory/000/64
galaxy.model.metadata DEBUG 2024-11-24 06:37:55,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 114
galaxy.jobs INFO 2024-11-24 06:37:55,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 63 in /galaxy/server/database/jobs_directory/000/63
galaxy.jobs DEBUG 2024-11-24 06:37:55,687 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 64 executed (169.551 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:55,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 64 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:37:55,733 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 63 executed (126.011 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,754 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 77: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:55,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 63 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 71 finished
galaxy.model.metadata DEBUG 2024-11-24 06:37:55,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 122
galaxy.jobs INFO 2024-11-24 06:37:55,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 71 in /galaxy/server/database/jobs_directory/000/71
galaxy.jobs.runners DEBUG 2024-11-24 06:37:55,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 72: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:37:56,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 71 executed (147.998 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:37:56,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 76: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:37:56,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 71 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:37:56,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 78: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:10,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 77 finished
galaxy.model.metadata DEBUG 2024-11-24 06:38:10,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 128
galaxy.jobs.runners DEBUG 2024-11-24 06:38:10,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 72 finished
galaxy.jobs INFO 2024-11-24 06:38:10,623 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 77 in /galaxy/server/database/jobs_directory/000/77
galaxy.model.metadata DEBUG 2024-11-24 06:38:10,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 123
galaxy.jobs INFO 2024-11-24 06:38:10,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 72 in /galaxy/server/database/jobs_directory/000/72
galaxy.jobs DEBUG 2024-11-24 06:38:10,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 77 executed (198.479 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:10,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 77 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:38:10,756 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 72 executed (123.554 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:10,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 72 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:38:10,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 76 finished
galaxy.model.metadata DEBUG 2024-11-24 06:38:10,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 127
galaxy.jobs.runners DEBUG 2024-11-24 06:38:10,950 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 78 finished
galaxy.jobs INFO 2024-11-24 06:38:10,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 76 in /galaxy/server/database/jobs_directory/000/76
galaxy.model.metadata DEBUG 2024-11-24 06:38:10,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 129
galaxy.jobs.runners DEBUG 2024-11-24 06:38:11,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 65: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:38:11,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 78 in /galaxy/server/database/jobs_directory/000/78
galaxy.jobs.runners DEBUG 2024-11-24 06:38:11,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 66: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:38:11,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 76 executed (175.741 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:11,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 76 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:38:11,126 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 78 executed (149.531 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:11,147 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 78 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:38:11,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 67: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:11,514 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 68: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:25,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 66 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:38:25,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 65 finished
galaxy.model.metadata DEBUG 2024-11-24 06:38:25,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 116
galaxy.model.metadata DEBUG 2024-11-24 06:38:25,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 117
galaxy.jobs INFO 2024-11-24 06:38:25,929 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 65 in /galaxy/server/database/jobs_directory/000/65
galaxy.jobs INFO 2024-11-24 06:38:25,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 66 in /galaxy/server/database/jobs_directory/000/66
galaxy.jobs DEBUG 2024-11-24 06:38:26,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 65 executed (171.427 ms)
galaxy.jobs DEBUG 2024-11-24 06:38:26,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 66 executed (176.180 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:26,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 65 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:26,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 66 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,251 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 67 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 69: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 74: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-24 06:38:26,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 118
galaxy.jobs INFO 2024-11-24 06:38:26,412 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 67 in /galaxy/server/database/jobs_directory/000/67
galaxy.jobs DEBUG 2024-11-24 06:38:26,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 67 executed (156.509 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,508 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 68 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:26,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 67 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:38:26,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 119
galaxy.jobs INFO 2024-11-24 06:38:26,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 68 in /galaxy/server/database/jobs_directory/000/68
galaxy.jobs DEBUG 2024-11-24 06:38:26,668 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 68 executed (139.590 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:26,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 68 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 70: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:26,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 73: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:40,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 69 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:38:41,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 74 finished
galaxy.model.metadata DEBUG 2024-11-24 06:38:41,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 120
galaxy.model.metadata DEBUG 2024-11-24 06:38:41,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 125
galaxy.jobs INFO 2024-11-24 06:38:41,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 69 in /galaxy/server/database/jobs_directory/000/69
galaxy.jobs INFO 2024-11-24 06:38:41,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 74 in /galaxy/server/database/jobs_directory/000/74
galaxy.jobs DEBUG 2024-11-24 06:38:41,167 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 69 executed (154.131 ms)
galaxy.jobs DEBUG 2024-11-24 06:38:41,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 74 executed (171.740 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:38:41,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] No k8s job found which matches job id 'gxy-vkwwn'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 74 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:38:41,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 70 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:38:41,387 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 75: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-24 06:38:41,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 121
galaxy.jobs.runners DEBUG 2024-11-24 06:38:41,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 73 finished
galaxy.jobs INFO 2024-11-24 06:38:41,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 70 in /galaxy/server/database/jobs_directory/000/70
galaxy.model.metadata DEBUG 2024-11-24 06:38:41,478 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 124
galaxy.jobs INFO 2024-11-24 06:38:41,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 73 in /galaxy/server/database/jobs_directory/000/73
galaxy.jobs DEBUG 2024-11-24 06:38:41,525 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 70 executed (154.564 ms)
galaxy.jobs DEBUG 2024-11-24 06:38:41,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 73 executed (100.460 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:38:41,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] No k8s job found which matches job id 'gxy-hf2nm'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (57/gxy-xdpt4) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (57/gxy-xdpt4) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (57/gxy-xdpt4) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (57/gxy-xdpt4) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-xdpt4.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 57 (gxy-xdpt4)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 73 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Could not find job with id gxy-xdpt4 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (57/gxy-xdpt4) Terminated at user's request
galaxy.jobs.runners ERROR 2024-11-24 06:38:41,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (73) Unhandled exception calling finish_job
Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/__init__.py", line 174, in run_next
    method(arg)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 1128, in finish_job
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 27, in scale
    self.exists(ensure=True)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 124, in exists
    raise ObjectDoesNotExist(f"{self.name} does not exist.")
pykube.exceptions.ObjectDoesNotExist: gxy-92mqr does not exist.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] 73/gxy-92mqr Job output not returned from cluster: [Errno 2] No such file or directory: '/galaxy/server/database/jobs_directory/000/73/galaxy_73.o'
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (73/gxy-92mqr) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (73/gxy-92mqr) tool_stderr: Job output not returned from cluster
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (73/gxy-92mqr) job_stdout: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (73/gxy-92mqr) job_stderr: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Attempting to stop job 73 (gxy-92mqr)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,654 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Could not find job with id gxy-92mqr to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:41,654 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (73/gxy-92mqr) Terminated at user's request
galaxy.jobs ERROR 2024-11-24 06:38:41,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to cleanup job 73
Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/__init__.py", line 2133, in cleanup
    self.object_store.delete(
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 469, in delete
    return self._invoke("delete", obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 451, in _invoke
    return self.__getattribute__(f"_{delegate}")(obj=obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 870, in _delete
    path = self._get_filename(obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 916, in _get_filename
    raise ObjectNotFound
galaxy.exceptions.ObjectNotFound: No such object found.
galaxy.jobs.handler DEBUG 2024-11-24 06:38:42,824 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 80, 79
tpv.core.entities DEBUG 2024-11-24 06:38:42,846 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:38:42,846 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (79) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:38:42,851 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (79) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:38:42,859 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (79) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:38:42,872 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (79) Working directory for job is: /galaxy/server/database/jobs_directory/000/79
galaxy.jobs.runners DEBUG 2024-11-24 06:38:42,879 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [79] queued (27.756 ms)
galaxy.jobs.handler INFO 2024-11-24 06:38:42,881 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (79) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:42,884 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 79
tpv.core.entities DEBUG 2024-11-24 06:38:42,892 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:38:42,893 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (80) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:38:42,896 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (80) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:38:42,907 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (80) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:38:42,928 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (80) Working directory for job is: /galaxy/server/database/jobs_directory/000/80
galaxy.jobs.runners DEBUG 2024-11-24 06:38:42,935 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [80] queued (38.269 ms)
galaxy.jobs.handler INFO 2024-11-24 06:38:42,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (80) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:42,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 80
galaxy.jobs DEBUG 2024-11-24 06:38:42,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [79] prepared (87.722 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:38:43,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/79/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/79/registry.xml' '/galaxy/server/database/jobs_directory/000/79/upload_params.json' '130:/galaxy/server/database/objects/7/f/9/dataset_7f97c7ea-f1d4-4f74-baa2-29e7f3b99188_files:/galaxy/server/database/objects/7/f/9/dataset_7f97c7ea-f1d4-4f74-baa2-29e7f3b99188.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:38:43,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (79) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/79/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/79/galaxy_79.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:38:43,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [80] prepared (75.132 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 79 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 79 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:38:43,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/80/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/80/registry.xml' '/galaxy/server/database/jobs_directory/000/80/upload_params.json' '131:/galaxy/server/database/objects/0/f/c/dataset_0fc71d9a-a061-445b-bcd3-77c4e1b1eb0c_files:/galaxy/server/database/objects/0/f/c/dataset_0fc71d9a-a061-445b-bcd3-77c4e1b1eb0c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:38:43,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (80) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/80/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/80/galaxy_80.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 80 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 80 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,930 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:43,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:38:48,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 75 finished
galaxy.model.metadata DEBUG 2024-11-24 06:38:48,729 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 126
galaxy.jobs INFO 2024-11-24 06:38:48,756 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 75 in /galaxy/server/database/jobs_directory/000/75
galaxy.jobs DEBUG 2024-11-24 06:38:48,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 75 executed (82.973 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:38:48,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] No k8s job found which matches job id 'gxy-ntlnp'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:53,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8hgc6 with k8s id: gxy-8hgc6 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:38:53,181 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4q25q with k8s id: gxy-4q25q succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:38:53,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 80: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:38:53,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 79: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:39:00,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 80 finished
galaxy.model.metadata DEBUG 2024-11-24 06:39:00,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 131
galaxy.jobs INFO 2024-11-24 06:39:00,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 80 in /galaxy/server/database/jobs_directory/000/80
galaxy.jobs DEBUG 2024-11-24 06:39:00,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 80 executed (99.651 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:00,622 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 80 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:39:00,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 79 finished
galaxy.model.metadata DEBUG 2024-11-24 06:39:00,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 130
galaxy.jobs INFO 2024-11-24 06:39:00,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 79 in /galaxy/server/database/jobs_directory/000/79
galaxy.jobs DEBUG 2024-11-24 06:39:00,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 79 executed (88.908 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:00,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 79 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:39:01,306 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 81
tpv.core.entities DEBUG 2024-11-24 06:39:01,332 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:39:01,333 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (81) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:39:01,336 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (81) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:39:01,347 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (81) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:39:01,359 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (81) Working directory for job is: /galaxy/server/database/jobs_directory/000/81
galaxy.jobs.runners DEBUG 2024-11-24 06:39:01,367 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [81] queued (30.947 ms)
galaxy.jobs.handler INFO 2024-11-24 06:39:01,369 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (81) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:01,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 81
galaxy.jobs DEBUG 2024-11-24 06:39:01,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [81] prepared (49.953 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:01,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:39:01,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:01,452 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:39:01,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/81/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/81/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/custom_content_0 &&  ln -s '/galaxy/server/database/objects/7/f/9/dataset_7f97c7ea-f1d4-4f74-baa2-29e7f3b99188.dat' 'multiqc_WDir/custom_content_0/file_0_0' && more /galaxy/server/database/objects/7/f/9/dataset_7f97c7ea-f1d4-4f74-baa2-29e7f3b99188.dat && ln -s '/galaxy/server/database/objects/0/f/c/dataset_0fc71d9a-a061-445b-bcd3-77c4e1b1eb0c.dat' 'multiqc_WDir/custom_content_0/file_0_1' && more /galaxy/server/database/objects/0/f/c/dataset_0fc71d9a-a061-445b-bcd3-77c4e1b1eb0c.dat &&  multiqc multiqc_WDir --filename "report"      --config '/galaxy/server/database/jobs_directory/000/81/configs/tmp7oc03xq0']
galaxy.jobs.runners DEBUG 2024-11-24 06:39:01,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (81) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/81/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/81/galaxy_81.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/81/working/report.html" -a -f "/galaxy/server/database/objects/a/b/0/dataset_ab02cf92-065d-46c6-ac87-8a4ec184a0c4.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/81/working/report.html" "/galaxy/server/database/objects/a/b/0/dataset_ab02cf92-065d-46c6-ac87-8a4ec184a0c4.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:01,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 81 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:01,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:39:01,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:01,524 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:01,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 81 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:02,224 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:09,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-42m5c with k8s id: gxy-42m5c succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:39:09,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 81: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:39:16,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 81 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:39:16,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (81) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/81/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (4.610 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:39:16,678 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (81) Add dynamic collection datasets to history for output [stats] (16.605 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:39:16,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 132
galaxy.jobs INFO 2024-11-24 06:39:16,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 81 in /galaxy/server/database/jobs_directory/000/81
galaxy.jobs DEBUG 2024-11-24 06:39:16,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 81 executed (128.434 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:16,776 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 81 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:39:18,644 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 82
tpv.core.entities DEBUG 2024-11-24 06:39:18,665 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:39:18,665 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (82) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:39:18,669 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (82) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:39:18,679 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (82) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:39:18,694 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (82) Working directory for job is: /galaxy/server/database/jobs_directory/000/82
galaxy.jobs.runners DEBUG 2024-11-24 06:39:18,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [82] queued (31.575 ms)
galaxy.jobs.handler INFO 2024-11-24 06:39:18,704 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (82) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:18,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 82
galaxy.jobs DEBUG 2024-11-24 06:39:18,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [82] prepared (68.090 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:39:18,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/82/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/82/registry.xml' '/galaxy/server/database/jobs_directory/000/82/upload_params.json' '134:/galaxy/server/database/objects/1/6/1/dataset_161f95f1-76f4-4b97-a9c2-21cc65358e8b_files:/galaxy/server/database/objects/1/6/1/dataset_161f95f1-76f4-4b97-a9c2-21cc65358e8b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:39:18,809 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (82) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/82/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/82/galaxy_82.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:18,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 82 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:18,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 82 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:19,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:39:23,771 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 83
tpv.core.entities DEBUG 2024-11-24 06:39:23,792 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:39:23,792 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (83) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:39:23,795 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (83) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:39:23,803 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (83) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:39:23,813 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (83) Working directory for job is: /galaxy/server/database/jobs_directory/000/83
galaxy.jobs.runners DEBUG 2024-11-24 06:39:23,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [83] queued (24.333 ms)
galaxy.jobs.handler INFO 2024-11-24 06:39:23,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (83) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:23,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 83
galaxy.jobs DEBUG 2024-11-24 06:39:23,888 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [83] prepared (58.481 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:39:23,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/83/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/83/registry.xml' '/galaxy/server/database/jobs_directory/000/83/upload_params.json' '135:/galaxy/server/database/objects/2/1/4/dataset_21436270-ac37-4068-a118-270713f0b947_files:/galaxy/server/database/objects/2/1/4/dataset_21436270-ac37-4068-a118-270713f0b947.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:39:23,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (83) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/83/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/83/galaxy_83.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:23,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 83 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:23,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 83 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:24,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:28,698 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-w6qs6 with k8s id: gxy-w6qs6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:39:28,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 82: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:33,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwgfr with k8s id: gxy-vwgfr succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:39:34,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 83: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:39:36,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 82 finished
galaxy.model.metadata DEBUG 2024-11-24 06:39:36,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 134
galaxy.jobs INFO 2024-11-24 06:39:36,129 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 82 in /galaxy/server/database/jobs_directory/000/82
galaxy.jobs DEBUG 2024-11-24 06:39:36,178 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 82 executed (96.112 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:36,191 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 82 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:39:41,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 83 finished
galaxy.model.metadata DEBUG 2024-11-24 06:39:41,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 135
galaxy.jobs INFO 2024-11-24 06:39:41,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 83 in /galaxy/server/database/jobs_directory/000/83
galaxy.jobs DEBUG 2024-11-24 06:39:41,198 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 83 executed (86.270 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:41,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 83 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:39:42,113 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 84
tpv.core.entities DEBUG 2024-11-24 06:39:42,144 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:39:42,145 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (84) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:39:42,149 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (84) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:39:42,157 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (84) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:39:42,171 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (84) Working directory for job is: /galaxy/server/database/jobs_directory/000/84
galaxy.jobs.runners DEBUG 2024-11-24 06:39:42,181 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [84] queued (31.926 ms)
galaxy.jobs.handler INFO 2024-11-24 06:39:42,183 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (84) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:42,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 84
galaxy.jobs DEBUG 2024-11-24 06:39:42,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [84] prepared (61.169 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:42,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:39:42,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:42,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:39:42,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/84/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/84/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/fastqc_0 &&    mkdir 'multiqc_WDir/fastqc_0/data_0' &&  mkdir 'multiqc_WDir/fastqc_0/data_0/file_0' && ln -s '/galaxy/server/database/objects/1/6/1/dataset_161f95f1-76f4-4b97-a9c2-21cc65358e8b.dat' 'multiqc_WDir/fastqc_0/data_0/file_0/fastqc_data.txt' && mkdir 'multiqc_WDir/fastqc_0/data_0/file_1' && ln -s '/galaxy/server/database/objects/2/1/4/dataset_21436270-ac37-4068-a118-270713f0b947.dat' 'multiqc_WDir/fastqc_0/data_0/file_1/fastqc_data.txt' &&  multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"  --flat --export]
galaxy.jobs.runners DEBUG 2024-11-24 06:39:42,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (84) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/84/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/84/galaxy_84.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/84/working/report.html" -a -f "/galaxy/server/database/objects/e/a/9/dataset_ea985de7-7908-462c-8c06-64045ef7a103.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/84/working/report.html" "/galaxy/server/database/objects/e/a/9/dataset_ea985de7-7908-462c-8c06-64045ef7a103.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:42,633 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 84 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:42,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:39:42,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:39:42,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:42,671 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 84 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:42,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-m52n4 failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,126 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-m52n4.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,188 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 84 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:39:56,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-m52n4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-m52n4": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (84/gxy-m52n4) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (84/gxy-m52n4) tool_stderr: [WARNING]         multiqc : MultiQC Version v1.25.2 now available!
[INFO   ]         multiqc : This is MultiQC v1.9
[INFO   ]         multiqc : Template    : default
[INFO   ]         multiqc : Report title: Title of the report
[INFO   ]         multiqc : Searching   : /galaxy/server/database/jobs_directory/000/84/working/multiqc_WDir
[INFO   ]          fastqc : Found 2 reports
[INFO   ]         multiqc : Compressing plot data
[INFO   ]         multiqc : Report      : report.html
[INFO   ]         multiqc : Data        : report_data
[INFO   ]         multiqc : Plots       : report_plots
[INFO   ]         multiqc : MultiQC complete

galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (84/gxy-m52n4) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (84/gxy-m52n4) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-m52n4.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 84 (gxy-m52n4)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-m52n4 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 84 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:56,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (84/gxy-m52n4) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 06:39:58,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 85
tpv.core.entities DEBUG 2024-11-24 06:39:58,453 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:39:58,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (85) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:39:58,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (85) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:39:58,467 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (85) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:39:58,480 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (85) Working directory for job is: /galaxy/server/database/jobs_directory/000/85
galaxy.jobs.runners DEBUG 2024-11-24 06:39:58,486 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [85] queued (28.639 ms)
galaxy.jobs.handler INFO 2024-11-24 06:39:58,488 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (85) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:58,490 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 85
galaxy.jobs DEBUG 2024-11-24 06:39:58,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [85] prepared (66.600 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:39:58,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/85/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/85/registry.xml' '/galaxy/server/database/jobs_directory/000/85/upload_params.json' '137:/galaxy/server/database/objects/b/9/9/dataset_b991f25c-b5c5-4cca-ad4a-0e54ace55390_files:/galaxy/server/database/objects/b/9/9/dataset_b991f25c-b5c5-4cca-ad4a-0e54ace55390.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:39:58,591 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (85) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/85/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/85/galaxy_85.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:58,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 85 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:58,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 85 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:39:59,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:08,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hmc7l with k8s id: gxy-hmc7l succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:40:08,515 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 85: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:40:15,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 85 finished
galaxy.model.metadata DEBUG 2024-11-24 06:40:15,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 137
galaxy.jobs INFO 2024-11-24 06:40:15,748 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 85 in /galaxy/server/database/jobs_directory/000/85
galaxy.jobs DEBUG 2024-11-24 06:40:15,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 85 executed (101.976 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:15,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 85 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:40:16,772 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 86
tpv.core.entities DEBUG 2024-11-24 06:40:16,798 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:16,798 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (86) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:16,802 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (86) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:16,813 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (86) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:16,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (86) Working directory for job is: /galaxy/server/database/jobs_directory/000/86
galaxy.jobs.runners DEBUG 2024-11-24 06:40:16,837 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [86] queued (35.611 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:16,839 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (86) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:16,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 86
galaxy.jobs DEBUG 2024-11-24 06:40:16,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [86] prepared (50.188 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:40:16,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:40:16,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:40:16,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:40:16,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/86/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/86/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/pycoqc_0 &&         grep -q '"pycoqc":' /galaxy/server/database/objects/b/9/9/dataset_b991f25c-b5c5-4cca-ad4a-0e54ace55390.dat || die "Module 'pycoqc: '"pycoqc":' not found in the file 'pycoqc_json'" && ln -s '/galaxy/server/database/objects/b/9/9/dataset_b991f25c-b5c5-4cca-ad4a-0e54ace55390.dat' 'multiqc_WDir/pycoqc_0/pycoqc_json'  &&    multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"]
galaxy.jobs.runners DEBUG 2024-11-24 06:40:16,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (86) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/86/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/86/galaxy_86.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/86/working/report.html" -a -f "/galaxy/server/database/objects/2/d/8/dataset_2d8aa001-c967-41d5-9803-92b011c1de50.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/86/working/report.html" "/galaxy/server/database/objects/2/d/8/dataset_2d8aa001-c967-41d5-9803-92b011c1de50.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:16,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 86 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:40:16,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:40:16,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:40:16,979 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:16,995 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 86 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:17,438 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:24,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8qg2d with k8s id: gxy-8qg2d succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:40:24,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 86: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:40:31,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 86 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:40:31,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (86) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/86/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (3.440 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:40:31,654 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (86) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/86/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.822 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:40:31,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (86) Add dynamic collection datasets to history for output [stats] (23.037 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:40:31,696 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 138
galaxy.jobs INFO 2024-11-24 06:40:31,738 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 86 in /galaxy/server/database/jobs_directory/000/86
galaxy.jobs DEBUG 2024-11-24 06:40:31,768 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 86 executed (145.946 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:31,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 86 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:40:34,092 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 88, 87
tpv.core.entities DEBUG 2024-11-24 06:40:34,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:34,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (87) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:34,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (87) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:34,129 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (87) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:34,143 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (87) Working directory for job is: /galaxy/server/database/jobs_directory/000/87
galaxy.jobs.runners DEBUG 2024-11-24 06:40:34,149 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [87] queued (29.616 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:34,151 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (87) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 87
tpv.core.entities DEBUG 2024-11-24 06:40:34,160 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:34,160 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (88) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:34,164 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (88) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:34,176 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (88) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:34,201 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (88) Working directory for job is: /galaxy/server/database/jobs_directory/000/88
galaxy.jobs.runners DEBUG 2024-11-24 06:40:34,208 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [88] queued (44.158 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:34,213 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (88) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 88
galaxy.jobs DEBUG 2024-11-24 06:40:34,248 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [87] prepared (81.341 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:40:34,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/87/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/87/registry.xml' '/galaxy/server/database/jobs_directory/000/87/upload_params.json' '141:/galaxy/server/database/objects/3/8/c/dataset_38ccab8c-4131-4ced-91ae-e642ce9ae535_files:/galaxy/server/database/objects/3/8/c/dataset_38ccab8c-4131-4ced-91ae-e642ce9ae535.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:34,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (87) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/87/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/87/galaxy_87.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 87 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:34,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [88] prepared (76.197 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 87 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:40:34,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/88/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/88/registry.xml' '/galaxy/server/database/jobs_directory/000/88/upload_params.json' '142:/galaxy/server/database/objects/8/5/c/dataset_85c0bf5b-f1e2-4ffb-8fbd-0596aaed225c_files:/galaxy/server/database/objects/8/5/c/dataset_85c0bf5b-f1e2-4ffb-8fbd-0596aaed225c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:34,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (88) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/88/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/88/galaxy_88.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 88 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 88 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,579 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:34,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:40:35,217 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 90, 89, 91
tpv.core.entities DEBUG 2024-11-24 06:40:35,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:35,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (89) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:35,250 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (89) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:35,263 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (89) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:35,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (89) Working directory for job is: /galaxy/server/database/jobs_directory/000/89
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,282 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [89] queued (32.068 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:35,285 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (89) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,288 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 89
tpv.core.entities DEBUG 2024-11-24 06:40:35,300 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:35,301 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (90) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:35,305 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (90) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:35,314 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (90) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:35,336 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (90) Working directory for job is: /galaxy/server/database/jobs_directory/000/90
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,343 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [90] queued (37.128 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:35,345 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (90) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 90
tpv.core.entities DEBUG 2024-11-24 06:40:35,357 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:35,357 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (91) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:35,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (91) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:35,374 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (91) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:35,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [89] prepared (91.825 ms)
galaxy.jobs DEBUG 2024-11-24 06:40:35,406 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (91) Working directory for job is: /galaxy/server/database/jobs_directory/000/91
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,411 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [91] queued (49.134 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:35,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (91) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 91
galaxy.jobs.command_factory INFO 2024-11-24 06:40:35,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/89/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/89/registry.xml' '/galaxy/server/database/jobs_directory/000/89/upload_params.json' '143:/galaxy/server/database/objects/f/5/c/dataset_f5c72763-fe03-4812-9cb5-55e20a7399a1_files:/galaxy/server/database/objects/f/5/c/dataset_f5c72763-fe03-4812-9cb5-55e20a7399a1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (89) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/89/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/89/galaxy_89.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 89 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:35,465 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [90] prepared (105.131 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 89 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:40:35,489 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/90/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/90/registry.xml' '/galaxy/server/database/jobs_directory/000/90/upload_params.json' '144:/galaxy/server/database/objects/0/e/d/dataset_0edc8ba9-c973-4890-8b4a-ba4fc36bc8b2_files:/galaxy/server/database/objects/0/e/d/dataset_0edc8ba9-c973-4890-8b4a-ba4fc36bc8b2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (90) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/90/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/90/galaxy_90.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:40:35,515 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [91] prepared (85.228 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 90 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 90 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:40:35,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/91/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/91/registry.xml' '/galaxy/server/database/jobs_directory/000/91/upload_params.json' '145:/galaxy/server/database/objects/2/3/e/dataset_23e2dd53-c1ec-4047-b201-a42b22796600_files:/galaxy/server/database/objects/2/3/e/dataset_23e2dd53-c1ec-4047-b201-a42b22796600.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:35,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (91) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/91/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/91/galaxy_91.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 91 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,568 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 91 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:35,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,417 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 92, 93, 96, 94, 95
tpv.core.entities DEBUG 2024-11-24 06:40:36,442 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:36,442 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (92) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,445 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (92) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:36,455 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (92) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:36,465 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (92) Working directory for job is: /galaxy/server/database/jobs_directory/000/92
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,471 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [92] queued (25.595 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:36,473 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (92) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 92
tpv.core.entities DEBUG 2024-11-24 06:40:36,482 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:36,483 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (93) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,487 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (93) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:36,496 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (93) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:36,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (93) Working directory for job is: /galaxy/server/database/jobs_directory/000/93
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,526 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [93] queued (39.809 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:36,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (93) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,533 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 93
tpv.core.entities DEBUG 2024-11-24 06:40:36,544 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:36,544 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (94) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,549 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (94) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:36,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (94) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:36,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [92] prepared (87.729 ms)
galaxy.jobs DEBUG 2024-11-24 06:40:36,594 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (94) Working directory for job is: /galaxy/server/database/jobs_directory/000/94
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,602 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [94] queued (52.831 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:36,605 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (94) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:40:36,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/92/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/92/registry.xml' '/galaxy/server/database/jobs_directory/000/92/upload_params.json' '146:/galaxy/server/database/objects/0/7/d/dataset_07d16157-e3eb-426f-9a51-841a898e7172_files:/galaxy/server/database/objects/0/7/d/dataset_07d16157-e3eb-426f-9a51-841a898e7172.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 94
tpv.core.entities DEBUG 2024-11-24 06:40:36,622 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:36,622 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (95) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (92) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/92/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/92/galaxy_92.ec; sh -c "exit $return_code"
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,629 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (95) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:36,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (95) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:36,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [93] prepared (106.608 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 92 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:36,689 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (95) Working directory for job is: /galaxy/server/database/jobs_directory/000/95
galaxy.jobs.command_factory INFO 2024-11-24 06:40:36,696 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/93/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/93/registry.xml' '/galaxy/server/database/jobs_directory/000/93/upload_params.json' '147:/galaxy/server/database/objects/c/4/1/dataset_c419fcd7-989e-4b0e-80c3-e5e503576714_files:/galaxy/server/database/objects/c/4/1/dataset_c419fcd7-989e-4b0e-80c3-e5e503576714.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,703 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [95] queued (73.513 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:36,707 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (95) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 95
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (93) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/93/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/93/galaxy_93.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 92 is an interactive tool. guest ports: []. interactive entry points: []
tpv.core.entities DEBUG 2024-11-24 06:40:36,736 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:36,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (96) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:36,743 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (96) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,754 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 93 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:36,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (96) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:36,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [94] prepared (169.443 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 93 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:36,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (96) Working directory for job is: /galaxy/server/database/jobs_directory/000/96
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,825 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [96] queued (81.620 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:36,830 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (96) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,835 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 96
galaxy.jobs.command_factory INFO 2024-11-24 06:40:36,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/94/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/94/registry.xml' '/galaxy/server/database/jobs_directory/000/94/upload_params.json' '148:/galaxy/server/database/objects/3/e/1/dataset_3e11c535-a5b7-46ce-be66-d9a8d1714d6b_files:/galaxy/server/database/objects/3/e/1/dataset_3e11c535-a5b7-46ce-be66-d9a8d1714d6b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (94) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/94/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/94/galaxy_94.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:40:36,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [95] prepared (146.115 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 94 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:40:36,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/95/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/95/registry.xml' '/galaxy/server/database/jobs_directory/000/95/upload_params.json' '149:/galaxy/server/database/objects/b/f/f/dataset_bffd94b4-5280-44f5-b3df-b47a33a3164a_files:/galaxy/server/database/objects/b/f/f/dataset_bffd94b4-5280-44f5-b3df-b47a33a3164a.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 94 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:40:36,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (95) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/95/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/95/galaxy_95.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:36,988 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 95 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:36,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [96] prepared (142.220 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:40:37,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/96/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/96/registry.xml' '/galaxy/server/database/jobs_directory/000/96/upload_params.json' '150:/galaxy/server/database/objects/e/3/3/dataset_e338f680-0b4b-44fc-b48a-5281b23fd1a2_files:/galaxy/server/database/objects/e/3/3/dataset_e338f680-0b4b-44fc-b48a-5281b23fd1a2.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:37,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 95 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:40:37,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (96) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/96/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/96/galaxy_96.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:37,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 96 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:37,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 96 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:40:37,836 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 97
tpv.core.entities DEBUG 2024-11-24 06:40:37,859 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:40:37,859 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (97) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:40:37,863 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (97) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:40:37,874 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (97) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:40:37,886 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (97) Working directory for job is: /galaxy/server/database/jobs_directory/000/97
galaxy.jobs.runners DEBUG 2024-11-24 06:40:37,893 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [97] queued (30.092 ms)
galaxy.jobs.handler INFO 2024-11-24 06:40:37,896 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (97) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:37,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 97
galaxy.jobs DEBUG 2024-11-24 06:40:37,979 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [97] prepared (74.194 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:40:38,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/97/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/97/registry.xml' '/galaxy/server/database/jobs_directory/000/97/upload_params.json' '151:/galaxy/server/database/objects/e/f/e/dataset_efe7bb11-4d27-4fa7-b032-9d769ef4d3e1_files:/galaxy/server/database/objects/e/f/e/dataset_efe7bb11-4d27-4fa7-b032-9d769ef4d3e1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:40:38,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (97) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/97/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/97/galaxy_97.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 97 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 97 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,128 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,279 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:38,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:39,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9fv8f failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,241 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-9fv8f.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 88 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,401 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (88/gxy-9fv8f) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (88/gxy-9fv8f) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (88/gxy-9fv8f) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (88/gxy-9fv8f) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-9fv8f.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 88 (gxy-9fv8f)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,431 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Could not find job with id gxy-9fv8f to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:44,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (88/gxy-9fv8f) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:45,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2xlfn with k8s id: gxy-2xlfn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:45,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bz5nm with k8s id: gxy-bz5nm succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:40:45,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 89: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:40:45,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 87: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:46,682 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8hdcn with k8s id: gxy-8hdcn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:46,702 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kg2cr with k8s id: gxy-kg2cr succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:40:46,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 90: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:40:46,913 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 91: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9cmdf with k8s id: gxy-9cmdf succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vpdst with k8s id: gxy-vpdst succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6w4mw with k8s id: gxy-6w4mw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dxn59 failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-dxn59.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:48,407 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 97 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:40:48,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-dxn59

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-dxn59": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:49,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4z6bh with k8s id: gxy-4z6bh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:49,524 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7wz62 with k8s id: gxy-7wz62 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:40:59,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 89 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:40:59,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 87 finished
galaxy.model.metadata DEBUG 2024-11-24 06:40:59,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 143
galaxy.jobs INFO 2024-11-24 06:40:59,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 89 in /galaxy/server/database/jobs_directory/000/89
galaxy.model.metadata DEBUG 2024-11-24 06:40:59,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 141
galaxy.jobs INFO 2024-11-24 06:40:59,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 87 in /galaxy/server/database/jobs_directory/000/87
galaxy.jobs DEBUG 2024-11-24 06:40:59,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 89 executed (207.044 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:59,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 89 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:40:59,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 87 executed (178.164 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:40:59,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 87 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:40:59,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 92: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:40:59,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 93: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-24 06:41:00,623 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 98, 99
tpv.core.entities DEBUG 2024-11-24 06:41:00,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:00,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (98) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:00,706 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (98) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:00,718 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (98) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:00,731 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (98) Working directory for job is: /galaxy/server/database/jobs_directory/000/98
galaxy.jobs.runners DEBUG 2024-11-24 06:41:00,739 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [98] queued (32.935 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:00,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (98) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:00,810 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:00,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (99) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:00,815 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (99) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:00,826 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (99) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:00,843 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (99) Working directory for job is: /galaxy/server/database/jobs_directory/000/99
galaxy.jobs.runners DEBUG 2024-11-24 06:41:00,906 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [99] queued (91.420 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:00,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (99) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:41:01,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 90 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:01,508 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 144
galaxy.jobs INFO 2024-11-24 06:41:01,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 90 in /galaxy/server/database/jobs_directory/000/90
galaxy.jobs.runners DEBUG 2024-11-24 06:41:01,543 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 91 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:01,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 145
galaxy.jobs DEBUG 2024-11-24 06:41:01,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 90 executed (211.712 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:01,662 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 90 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 06:41:01,668 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 91 in /galaxy/server/database/jobs_directory/000/91
galaxy.jobs DEBUG 2024-11-24 06:41:01,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 91 executed (141.034 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:01,767 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 91 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:01,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 96: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-24 06:41:01,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 103, 102, 101, 104, 100
tpv.core.entities DEBUG 2024-11-24 06:41:01,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:01,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (100) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:01,944 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (100) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:02,003 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (100) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:02,019 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (100) Working directory for job is: /galaxy/server/database/jobs_directory/000/100
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,028 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [100] queued (83.119 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:02,031 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (100) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:02,106 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:02,107 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (101) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:02,112 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (101) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:02,123 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (101) Persisting job destination (destination id: k8s)
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 94: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:41:02,214 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (101) Working directory for job is: /galaxy/server/database/jobs_directory/000/101
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,225 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [101] queued (112.696 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:02,228 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (101) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:02,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:02,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (102) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:02,311 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (102) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:02,322 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (102) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:02,404 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (102) Working directory for job is: /galaxy/server/database/jobs_directory/000/102
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,410 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [102] queued (99.045 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:02,412 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (102) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:02,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:02,420 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (103) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:02,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (103) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:02,504 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (103) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:02,516 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (103) Working directory for job is: /galaxy/server/database/jobs_directory/000/103
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [103] queued (99.253 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:02,524 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (103) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:02,531 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:02,599 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (104) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:02,604 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (104) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:02,613 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (104) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:02,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (104) Working directory for job is: /galaxy/server/database/jobs_directory/000/104
galaxy.jobs.runners DEBUG 2024-11-24 06:41:02,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [104] queued (26.711 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:02,701 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (104) Job dispatched
galaxy.jobs.handler DEBUG 2024-11-24 06:41:07,832 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 107, 106, 105
tpv.core.entities DEBUG 2024-11-24 06:41:07,905 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:07,906 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (105) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:07,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (105) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:07,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (105) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:07,933 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (105) Working directory for job is: /galaxy/server/database/jobs_directory/000/105
galaxy.jobs.runners DEBUG 2024-11-24 06:41:07,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [105] queued (29.937 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:07,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (105) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:08,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:08,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (106) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:08,013 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (106) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:08,023 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (106) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:08,037 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (106) Working directory for job is: /galaxy/server/database/jobs_directory/000/106
galaxy.jobs.runners DEBUG 2024-11-24 06:41:08,101 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [106] queued (88.001 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:08,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (106) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:08,111 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:08,112 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (107) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:08,115 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (107) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:08,125 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (107) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:08,137 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (107) Working directory for job is: /galaxy/server/database/jobs_directory/000/107
galaxy.jobs.runners DEBUG 2024-11-24 06:41:08,200 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [107] queued (84.494 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:08,202 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (107) Job dispatched
galaxy.jobs.handler DEBUG 2024-11-24 06:41:09,205 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 109, 108, 111, 110
tpv.core.entities DEBUG 2024-11-24 06:41:09,228 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:09,229 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (108) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:09,233 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (108) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:09,300 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (108) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:09,313 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (108) Working directory for job is: /galaxy/server/database/jobs_directory/000/108
galaxy.jobs.runners DEBUG 2024-11-24 06:41:09,320 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [108] queued (87.169 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:09,322 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (108) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:09,330 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:09,331 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (109) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:09,335 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (109) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:09,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (109) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:09,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (109) Working directory for job is: /galaxy/server/database/jobs_directory/000/109
galaxy.jobs.runners DEBUG 2024-11-24 06:41:09,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [109] queued (86.666 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:09,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (109) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:09,432 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:09,432 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (110) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:09,436 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (110) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:09,506 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (110) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:09,520 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (110) Working directory for job is: /galaxy/server/database/jobs_directory/000/110
galaxy.jobs.runners DEBUG 2024-11-24 06:41:09,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [110] queued (91.081 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:09,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (110) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:41:09,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:41:09,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (111) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:41:09,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (111) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:41:09,611 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (111) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:41:09,624 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (111) Working directory for job is: /galaxy/server/database/jobs_directory/000/111
galaxy.jobs.runners DEBUG 2024-11-24 06:41:09,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [111] queued (31.396 ms)
galaxy.jobs.handler INFO 2024-11-24 06:41:09,633 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (111) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:41:14,851 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 92 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:14,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 146
galaxy.jobs INFO 2024-11-24 06:41:15,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 92 in /galaxy/server/database/jobs_directory/000/92
galaxy.jobs DEBUG 2024-11-24 06:41:15,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 92 executed (141.637 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 92 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:15,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 93 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:15,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 147
galaxy.jobs INFO 2024-11-24 06:41:15,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 93 in /galaxy/server/database/jobs_directory/000/93
galaxy.jobs DEBUG 2024-11-24 06:41:15,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 93 executed (186.604 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 93 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:15,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 95: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 98
galaxy.jobs DEBUG 2024-11-24 06:41:15,553 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [98] prepared (117.900 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:15,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/98/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/98/registry.xml' '/galaxy/server/database/jobs_directory/000/98/upload_params.json' '152:/galaxy/server/database/objects/5/e/6/dataset_5e6294e4-6024-4adf-a119-65c1e9c4fef7_files:/galaxy/server/database/objects/5/e/6/dataset_5e6294e4-6024-4adf-a119-65c1e9c4fef7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:15,626 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (98) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/98/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/98/galaxy_98.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 98 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,699 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 98 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 99
galaxy.jobs DEBUG 2024-11-24 06:41:15,851 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [99] prepared (116.227 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:15,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/99/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/99/registry.xml' '/galaxy/server/database/jobs_directory/000/99/upload_params.json' '153:/galaxy/server/database/objects/3/3/3/dataset_333a579d-03f8-4111-b860-be98013ced2b_files:/galaxy/server/database/objects/3/3/3/dataset_333a579d-03f8-4111-b860-be98013ced2b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:15,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (99) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/99/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/99/galaxy_99.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 99 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:15,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 99 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,007 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (97/gxy-dxn59) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (97/gxy-dxn59) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (97/gxy-dxn59) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (97/gxy-dxn59) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-dxn59.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Attempting to stop job 97 (gxy-dxn59)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Found job with id gxy-dxn59 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 97 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (97/gxy-dxn59) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 100
galaxy.jobs DEBUG 2024-11-24 06:41:16,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [100] prepared (162.440 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:16,433 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/100/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/100/registry.xml' '/galaxy/server/database/jobs_directory/000/100/upload_params.json' '154:/galaxy/server/database/objects/4/7/c/dataset_47cc233a-7e19-4130-a203-dc57df4c35ec_files:/galaxy/server/database/objects/4/7/c/dataset_47cc233a-7e19-4130-a203-dc57df4c35ec.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:16,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (100) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/100/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/100/galaxy_100.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 100 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 100 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 101
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:41:16,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 96 finished
galaxy.jobs DEBUG 2024-11-24 06:41:16,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [101] prepared (183.279 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:41:16,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/101/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/101/registry.xml' '/galaxy/server/database/jobs_directory/000/101/upload_params.json' '155:/galaxy/server/database/objects/f/7/b/dataset_f7ba5295-4736-4043-b09b-a94f56819141_files:/galaxy/server/database/objects/f/7/b/dataset_f7ba5295-4736-4043-b09b-a94f56819141.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:16,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (101) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/101/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/101/galaxy_101.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,835 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.model.metadata DEBUG 2024-11-24 06:41:16,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 150
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 101 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 101 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 06:41:16,946 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 96 in /galaxy/server/database/jobs_directory/000/96
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:16,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 102
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 94 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:17,065 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 148
galaxy.jobs DEBUG 2024-11-24 06:41:17,075 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 96 executed (270.715 ms)
galaxy.jobs DEBUG 2024-11-24 06:41:17,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [102] prepared (99.730 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 96 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 06:41:17,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 94 in /galaxy/server/database/jobs_directory/000/94
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/102/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/102/registry.xml' '/galaxy/server/database/jobs_directory/000/102/upload_params.json' '156:/galaxy/server/database/objects/8/3/d/dataset_83da5da9-55ca-433b-b087-c1134fda3141_files:/galaxy/server/database/objects/8/3/d/dataset_83da5da9-55ca-433b-b087-c1134fda3141.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,144 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (102) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/102/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/102/galaxy_102.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,161 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 102 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,171 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 103
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,175 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 102 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:41:17,212 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 94 executed (175.943 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 104
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,231 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 94 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:41:17,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [103] prepared (98.300 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/103/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/103/registry.xml' '/galaxy/server/database/jobs_directory/000/103/upload_params.json' '157:/galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807_files:/galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,311 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (103) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/103/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/103/galaxy_103.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:41:17,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [104] prepared (81.983 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 103 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 103 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/104/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/104/registry.xml' '/galaxy/server/database/jobs_directory/000/104/upload_params.json' '158:/galaxy/server/database/objects/7/2/f/dataset_72f0a99f-9d57-49df-9648-8f977fa4b5bb_files:/galaxy/server/database/objects/7/2/f/dataset_72f0a99f-9d57-49df-9648-8f977fa4b5bb.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (104) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/104/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/104/galaxy_104.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 104 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 104 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 105
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 106
galaxy.jobs DEBUG 2024-11-24 06:41:17,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [105] prepared (76.899 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,492 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 107
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/105/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/105/registry.xml' '/galaxy/server/database/jobs_directory/000/105/upload_params.json' '159:/galaxy/server/database/objects/5/2/8/dataset_52817386-4bc5-4cd4-94b1-7412cec6e47d_files:/galaxy/server/database/objects/5/2/8/dataset_52817386-4bc5-4cd4-94b1-7412cec6e47d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (105) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/105/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/105/galaxy_105.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:41:17,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [106] prepared (86.941 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 105 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/106/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/106/registry.xml' '/galaxy/server/database/jobs_directory/000/106/upload_params.json' '160:/galaxy/server/database/objects/9/2/a/dataset_92aead4b-7a9e-4503-92f0-85ea7e5cae09_files:/galaxy/server/database/objects/9/2/a/dataset_92aead4b-7a9e-4503-92f0-85ea7e5cae09.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,578 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 105 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (106) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/106/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/106/galaxy_106.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:41:17,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [107] prepared (105.373 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 106 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:41:17,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/107/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/107/registry.xml' '/galaxy/server/database/jobs_directory/000/107/upload_params.json' '161:/galaxy/server/database/objects/f/6/2/dataset_f62bb515-b2b4-47bc-a6fd-b55c913232a3_files:/galaxy/server/database/objects/f/6/2/dataset_f62bb515-b2b4-47bc-a6fd-b55c913232a3.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:17,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (107) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/107/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/107/galaxy_107.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,643 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 106 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 107 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 107 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 108
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 109
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:17,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 110
galaxy.jobs DEBUG 2024-11-24 06:41:18,032 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [108] prepared (316.194 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:18,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/108/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/108/registry.xml' '/galaxy/server/database/jobs_directory/000/108/upload_params.json' '162:/galaxy/server/database/objects/b/f/3/dataset_bf34fbef-44cc-4f34-b4df-2ba546e24bf7_files:/galaxy/server/database/objects/b/f/3/dataset_bf34fbef-44cc-4f34-b4df-2ba546e24bf7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:18,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (108) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/108/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/108/galaxy_108.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:41:18,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [109] prepared (150.901 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,092 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 108 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:41:18,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [110] prepared (153.289 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,112 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 108 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:41:18,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/109/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/109/registry.xml' '/galaxy/server/database/jobs_directory/000/109/upload_params.json' '163:/galaxy/server/database/objects/8/1/4/dataset_81462f6e-6ec8-4de8-8c13-80ce9d526508_files:/galaxy/server/database/objects/8/1/4/dataset_81462f6e-6ec8-4de8-8c13-80ce9d526508.dat']
galaxy.jobs.command_factory INFO 2024-11-24 06:41:18,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/110/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/110/registry.xml' '/galaxy/server/database/jobs_directory/000/110/upload_params.json' '164:/galaxy/server/database/objects/f/9/d/dataset_f9d74b80-222d-48d8-adc0-ec082d0c39d8_files:/galaxy/server/database/objects/f/9/d/dataset_f9d74b80-222d-48d8-adc0-ec082d0c39d8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:18,129 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (109) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/109/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/109/galaxy_109.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-24 06:41:18,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (110) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/110/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/110/galaxy_110.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,149 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 109 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 110 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 109 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,178 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 110 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,223 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 111
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:41:18,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [111] prepared (92.215 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:41:18,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/111/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/111/registry.xml' '/galaxy/server/database/jobs_directory/000/111/upload_params.json' '165:/galaxy/server/database/objects/8/e/9/dataset_8e9a75ac-9e5d-4ebd-8ac5-3ee7a468165e_files:/galaxy/server/database/objects/8/e/9/dataset_8e9a75ac-9e5d-4ebd-8ac5-3ee7a468165e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:41:18,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (111) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/111/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/111/galaxy_111.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,373 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 111 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,392 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 111 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:18,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:19,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:19,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:19,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:20,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:41:24,888 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 95 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:24,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 149
galaxy.jobs INFO 2024-11-24 06:41:24,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 95 in /galaxy/server/database/jobs_directory/000/95
galaxy.jobs DEBUG 2024-11-24 06:41:25,035 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 95 executed (121.385 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:25,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 95 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:25,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8vrjm with k8s id: gxy-8vrjm succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:41:26,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 98: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:27,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lr49j with k8s id: gxy-lr49j succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:27,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6qvz6 with k8s id: gxy-6qvz6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:41:27,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 99: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:27,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 100: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:29,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ngscn with k8s id: gxy-ngscn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:29,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-lx46w with k8s id: gxy-lx46w succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:29,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-klf9q with k8s id: gxy-klf9q succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:29,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-p7779 with k8s id: gxy-p7779 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:29,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gkjrm with k8s id: gxy-gkjrm succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:30,005 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vxh5f with k8s id: gxy-vxh5f succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:30,113 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4z5dx with k8s id: gxy-4z5dx succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:41:30,221 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 101: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:31,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rs9xp with k8s id: gxy-rs9xp succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:31,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vstvs with k8s id: gxy-vstvs succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:31,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ws72p with k8s id: gxy-ws72p succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:31,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-994h6 with k8s id: gxy-994h6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:41:39,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 98 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:39,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 152
galaxy.jobs INFO 2024-11-24 06:41:39,702 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 98 in /galaxy/server/database/jobs_directory/000/98
galaxy.jobs DEBUG 2024-11-24 06:41:39,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 98 executed (205.955 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:39,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 98 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:40,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 102: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:41,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 99 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:41,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 153
galaxy.jobs INFO 2024-11-24 06:41:41,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 99 in /galaxy/server/database/jobs_directory/000/99
galaxy.jobs DEBUG 2024-11-24 06:41:41,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 99 executed (185.966 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:41,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 99 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:41,847 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 100 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:41:41,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 103: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-24 06:41:41,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 154
galaxy.jobs INFO 2024-11-24 06:41:42,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 100 in /galaxy/server/database/jobs_directory/000/100
galaxy.jobs DEBUG 2024-11-24 06:41:42,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 100 executed (256.299 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:42,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 100 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:42,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 104: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:44,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 101 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:44,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 155
galaxy.jobs INFO 2024-11-24 06:41:44,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 101 in /galaxy/server/database/jobs_directory/000/101
galaxy.jobs DEBUG 2024-11-24 06:41:45,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 101 executed (187.977 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:45,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 101 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:45,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 105: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:54,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 102 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:54,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 156
galaxy.jobs INFO 2024-11-24 06:41:55,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 102 in /galaxy/server/database/jobs_directory/000/102
galaxy.jobs DEBUG 2024-11-24 06:41:55,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 102 executed (183.032 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:55,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 102 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:55,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 106: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:56,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 103 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:56,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 157
galaxy.jobs INFO 2024-11-24 06:41:57,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 103 in /galaxy/server/database/jobs_directory/000/103
galaxy.jobs DEBUG 2024-11-24 06:41:57,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 103 executed (136.700 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:57,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 103 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:57,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 104 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:57,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 158
galaxy.jobs.runners DEBUG 2024-11-24 06:41:57,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 109: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:41:57,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 104 in /galaxy/server/database/jobs_directory/000/104
galaxy.jobs DEBUG 2024-11-24 06:41:57,440 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 104 executed (188.825 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:57,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 104 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:41:57,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 107: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:41:59,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 105 finished
galaxy.model.metadata DEBUG 2024-11-24 06:41:59,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 159
galaxy.jobs INFO 2024-11-24 06:41:59,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 105 in /galaxy/server/database/jobs_directory/000/105
galaxy.jobs DEBUG 2024-11-24 06:41:59,899 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 105 executed (177.562 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:41:59,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 105 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:00,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 108: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:42:09,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 106 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:09,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 160
galaxy.jobs INFO 2024-11-24 06:42:09,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 106 in /galaxy/server/database/jobs_directory/000/106
galaxy.jobs DEBUG 2024-11-24 06:42:10,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 106 executed (189.373 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:10,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 106 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:10,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 110: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:42:11,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 109 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:11,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 163
galaxy.jobs INFO 2024-11-24 06:42:11,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 109 in /galaxy/server/database/jobs_directory/000/109
galaxy.jobs DEBUG 2024-11-24 06:42:12,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 109 executed (262.104 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:12,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 109 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:12,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 107 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:12,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 161
galaxy.jobs INFO 2024-11-24 06:42:12,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 107 in /galaxy/server/database/jobs_directory/000/107
galaxy.jobs.runners DEBUG 2024-11-24 06:42:12,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 111: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:42:12,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 107 executed (220.547 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:12,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 107 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:14,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 108 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:14,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 162
galaxy.jobs INFO 2024-11-24 06:42:14,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 108 in /galaxy/server/database/jobs_directory/000/108
galaxy.jobs DEBUG 2024-11-24 06:42:14,656 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 108 executed (108.615 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:14,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 108 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:19,528 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 110 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:19,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 164
galaxy.jobs INFO 2024-11-24 06:42:19,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 110 in /galaxy/server/database/jobs_directory/000/110
galaxy.jobs DEBUG 2024-11-24 06:42:19,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 110 executed (92.639 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:19,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 110 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:20,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 111 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:20,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 165
galaxy.jobs INFO 2024-11-24 06:42:20,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 111 in /galaxy/server/database/jobs_directory/000/111
galaxy.jobs DEBUG 2024-11-24 06:42:20,497 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 111 executed (88.349 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:20,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 111 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:42:21,208 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 112
tpv.core.entities DEBUG 2024-11-24 06:42:21,251 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:21,251 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (112) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:21,255 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (112) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:21,265 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (112) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:21,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (112) Working directory for job is: /galaxy/server/database/jobs_directory/000/112
galaxy.jobs.runners DEBUG 2024-11-24 06:42:21,293 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [112] queued (37.016 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:21,295 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (112) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:21,297 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 112
galaxy.jobs DEBUG 2024-11-24 06:42:21,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [112] prepared (132.565 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:42:21,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:42:21,436 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:42:21,457 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:42:21,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/112/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/112/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/bismark_0 &&    mkdir 'multiqc_WDir/bismark_0/align_0' &&     ln -s '/galaxy/server/database/objects/5/e/6/dataset_5e6294e4-6024-4adf-a119-65c1e9c4fef7.dat' 'multiqc_WDir/bismark_0/align_0/bismark_txt_SE_report.txt' && mkdir multiqc_WDir/bowtie2_1 &&         grep -q '% overall alignment rate' /galaxy/server/database/objects/3/3/3/dataset_333a579d-03f8-4111-b860-be98013ced2b.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_1_txt'" && ln -s '/galaxy/server/database/objects/3/3/3/dataset_333a579d-03f8-4111-b860-be98013ced2b.dat' 'multiqc_WDir/bowtie2_1/bowtie2_1_txt'  &&       grep -q '% overall alignment rate' /galaxy/server/database/objects/4/7/c/dataset_47cc233a-7e19-4130-a203-dc57df4c35ec.dat || die "Module 'bowtie2: '% overall alignment rate' not found in the file 'bowtie2_2_txt'" && ln -s '/galaxy/server/database/objects/4/7/c/dataset_47cc233a-7e19-4130-a203-dc57df4c35ec.dat' 'multiqc_WDir/bowtie2_1/bowtie2_2_txt'  &&   mkdir multiqc_WDir/hisat2_2 &&         grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/f/7/b/dataset_f7ba5295-4736-4043-b09b-a94f56819141.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_1_txt'" && ln -s '/galaxy/server/database/objects/f/7/b/dataset_f7ba5295-4736-4043-b09b-a94f56819141.dat' 'multiqc_WDir/hisat2_2/hisat2_1_txt'  &&       grep -q 'HISAT2 summary stats:' /galaxy/server/database/objects/8/3/d/dataset_83da5da9-55ca-433b-b087-c1134fda3141.dat || die "Module 'hisat2: 'HISAT2 summary stats:' not found in the file 'hisat2_2_txt'" && ln -s '/galaxy/server/database/objects/8/3/d/dataset_83da5da9-55ca-433b-b087-c1134fda3141.dat' 'multiqc_WDir/hisat2_2/hisat2_2_txt'  &&   mkdir multiqc_WDir/hicexplorer_3 &&         grep -q 'Min rest. site distance' /galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer1_log'" && ln -s '/galaxy/server/database/objects/4/0/7/dataset_40722a58-a444-40ef-b79b-042658776807.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer1_log_1'  &&       grep -q 'Min rest. site distance' /galaxy/server/database/objects/7/2/f/dataset_72f0a99f-9d57-49df-9648-8f977fa4b5bb.dat || die "Module 'hicexplorer: 'Min rest. site distance' not found in the file 'hicexplorer2_log'" && ln -s '/galaxy/server/database/objects/7/2/f/dataset_72f0a99f-9d57-49df-9648-8f977fa4b5bb.dat' 'multiqc_WDir/hicexplorer_3/hicexplorer2_log'  &&   mkdir multiqc_WDir/kallisto_4 &&         grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/5/2/8/dataset_52817386-4bc5-4cd4-94b1-7412cec6e47d.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_1_txt'" && ln -s '/galaxy/server/database/objects/5/2/8/dataset_52817386-4bc5-4cd4-94b1-7412cec6e47d.dat' 'multiqc_WDir/kallisto_4/kallisto_1_txt'  &&       grep -q 'finding pseudoalignments for the reads' /galaxy/server/database/objects/9/2/a/dataset_92aead4b-7a9e-4503-92f0-85ea7e5cae09.dat || die "Module 'kallisto: 'finding pseudoalignments for the reads' not found in the file 'kallisto_2_txt'" && ln -s '/galaxy/server/database/objects/9/2/a/dataset_92aead4b-7a9e-4503-92f0-85ea7e5cae09.dat' 'multiqc_WDir/kallisto_4/kallisto_2_txt'  &&   mkdir multiqc_WDir/macs2_5 &&     grep -q "# This file is generated by MACS" /galaxy/server/database/objects/f/6/2/dataset_f62bb515-b2b4-47bc-a6fd-b55c913232a3.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/f/6/2/dataset_f62bb515-b2b4-47bc-a6fd-b55c913232a3.dat' 'multiqc_WDir/macs2_5/macs_1_txt_peaks.xls' &&    grep -q "# This file is generated by MACS" /galaxy/server/database/objects/b/f/3/dataset_bf34fbef-44cc-4f34-b4df-2ba546e24bf7.dat || die "'# This file is generated by MACS' not found in the file" && ln -s '/galaxy/server/database/objects/b/f/3/dataset_bf34fbef-44cc-4f34-b4df-2ba546e24bf7.dat' 'multiqc_WDir/macs2_5/macs_2_txt_peaks.xls' && mkdir multiqc_WDir/star_6 &&    mkdir 'multiqc_WDir/star_6/log_0' &&     ln -s '/galaxy/server/database/objects/8/1/4/dataset_81462f6e-6ec8-4de8-8c13-80ce9d526508.dat' 'multiqc_WDir/star_6/log_0/star_log_txt_Log.final.out' &&   mkdir 'multiqc_WDir/star_6/genecounts_1' &&     ln -s '/galaxy/server/database/objects/f/9/d/dataset_f9d74b80-222d-48d8-adc0-ec082d0c39d8.dat' 'multiqc_WDir/star_6/genecounts_1/star_counts_txt_ReadsPerGene.out.tab' && mkdir multiqc_WDir/tophat_7 &&     ln -s '/galaxy/server/database/objects/8/e/9/dataset_8e9a75ac-9e5d-4ebd-8ac5-3ee7a468165e.dat' 'multiqc_WDir/tophat_7/tophat_txtalign_summary.txt' &&  multiqc multiqc_WDir --filename "report"]
galaxy.jobs.runners DEBUG 2024-11-24 06:42:21,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (112) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/112/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/112/galaxy_112.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/112/working/report.html" -a -f "/galaxy/server/database/objects/e/6/b/dataset_e6b7ff53-1369-4aa6-b91e-4797530e2611.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/112/working/report.html" "/galaxy/server/database/objects/e/6/b/dataset_e6b7ff53-1369-4aa6-b91e-4797530e2611.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:21,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 112 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:42:21,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:42:21,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:42:21,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:21,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 112 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:22,652 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bd7wn failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,850 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-bd7wn.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 112 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:42:29,883 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-bd7wn

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-bd7wn": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (112/gxy-bd7wn) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (112/gxy-bd7wn) tool_stderr: [WARNING]         multiqc : MultiQC Version v1.25.2 now available!
[INFO   ]         multiqc : This is MultiQC v1.9
[INFO   ]         multiqc : Template    : default
[INFO   ]         multiqc : Searching   : /galaxy/server/database/jobs_directory/000/112/working/multiqc_WDir
[INFO   ]           macs2 : Found 2 logs
[INFO   ]         bismark : Found 1 alignment reports
[INFO   ]     hicexplorer : Found 3 reports
[INFO   ]        kallisto : Found 2 reports
[INFO   ]            star : Found 1 reports and 1 gene count files
[INFO   ]          hisat2 : Found 2 reports
[INFO   ]          tophat : Found 1 reports
[INFO   ]         bowtie2 : Found 2 reports
[INFO   ]        cutadapt : Found 4 reports
[INFO   ]         multiqc : Compressing plot data
[INFO   ]         multiqc : Report      : report.html
[INFO   ]         multiqc : Data        : report_data
[INFO   ]         multiqc : MultiQC complete

galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (112/gxy-bd7wn) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (112/gxy-bd7wn) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-bd7wn.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 112 (gxy-bd7wn)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Found job with id gxy-bd7wn to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 112 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:29,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (112/gxy-bd7wn) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 06:42:31,438 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 114, 113
tpv.core.entities DEBUG 2024-11-24 06:42:31,460 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:31,461 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (113) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:31,465 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (113) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:31,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (113) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:31,489 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (113) Working directory for job is: /galaxy/server/database/jobs_directory/000/113
galaxy.jobs.runners DEBUG 2024-11-24 06:42:31,497 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [113] queued (31.693 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:31,499 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (113) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 113
tpv.core.entities DEBUG 2024-11-24 06:42:31,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:31,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (114) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:31,516 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (114) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:31,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (114) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:31,551 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (114) Working directory for job is: /galaxy/server/database/jobs_directory/000/114
galaxy.jobs.runners DEBUG 2024-11-24 06:42:31,558 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [114] queued (42.234 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:31,561 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (114) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 114
galaxy.jobs DEBUG 2024-11-24 06:42:31,597 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [113] prepared (82.279 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:31,619 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/113/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/113/registry.xml' '/galaxy/server/database/jobs_directory/000/113/upload_params.json' '167:/galaxy/server/database/objects/8/c/3/dataset_8c3c4026-8291-43bb-b7d3-d0c1b9ff2c75_files:/galaxy/server/database/objects/8/c/3/dataset_8c3c4026-8291-43bb-b7d3-d0c1b9ff2c75.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:31,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (113) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/113/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/113/galaxy_113.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 113 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:31,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [114] prepared (75.522 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 113 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:31,669 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/114/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/114/registry.xml' '/galaxy/server/database/jobs_directory/000/114/upload_params.json' '168:/galaxy/server/database/objects/c/6/a/dataset_c6aef13e-7018-4a88-a841-62221e95550d_files:/galaxy/server/database/objects/c/6/a/dataset_c6aef13e-7018-4a88-a841-62221e95550d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:31,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (114) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/114/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/114/galaxy_114.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 114 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 114 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,934 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:31,986 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:42:32,565 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 115, 118, 116, 117
tpv.core.entities DEBUG 2024-11-24 06:42:32,589 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:32,589 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (115) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:32,593 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (115) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:32,601 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (115) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:32,615 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (115) Working directory for job is: /galaxy/server/database/jobs_directory/000/115
galaxy.jobs.runners DEBUG 2024-11-24 06:42:32,622 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [115] queued (29.231 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:32,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (115) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:32,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 115
tpv.core.entities DEBUG 2024-11-24 06:42:32,639 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:32,640 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (116) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:32,644 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (116) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:32,657 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (116) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:32,678 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (116) Working directory for job is: /galaxy/server/database/jobs_directory/000/116
galaxy.jobs.runners DEBUG 2024-11-24 06:42:32,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [116] queued (40.483 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:32,688 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (116) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:32,691 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 116
tpv.core.entities DEBUG 2024-11-24 06:42:32,702 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:32,702 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (117) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:32,707 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (117) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:32,720 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (117) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:32,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [115] prepared (89.568 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:33,315 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (117) Working directory for job is: /galaxy/server/database/jobs_directory/000/117
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,324 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [117] queued (617.297 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:33,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/115/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/115/registry.xml' '/galaxy/server/database/jobs_directory/000/115/upload_params.json' '169:/galaxy/server/database/objects/8/e/7/dataset_8e7e4de2-7a87-4506-a2b7-942b8b9952b9_files:/galaxy/server/database/objects/8/e/7/dataset_8e7e4de2-7a87-4506-a2b7-942b8b9952b9.dat']
galaxy.jobs.handler INFO 2024-11-24 06:42:33,333 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (117) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,334 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 117
tpv.core.entities DEBUG 2024-11-24 06:42:33,355 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:33,356 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (118) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:33,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (118) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,363 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (115) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/115/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/115/galaxy_115.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:33,372 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (118) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,396 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 115 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:33,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [116] prepared (696.215 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:33,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (118) Working directory for job is: /galaxy/server/database/jobs_directory/000/118
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [118] queued (69.077 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:33,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (118) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:42:33,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/116/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/116/registry.xml' '/galaxy/server/database/jobs_directory/000/116/upload_params.json' '170:/galaxy/server/database/objects/a/0/6/dataset_a061b4ed-92ab-4f04-aa10-05454a7269e2_files:/galaxy/server/database/objects/a/0/6/dataset_a061b4ed-92ab-4f04-aa10-05454a7269e2.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,440 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 118
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 115 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,446 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (116) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/116/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/116/galaxy_116.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 116 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:33,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [117] prepared (118.270 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 116 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:33,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/117/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/117/registry.xml' '/galaxy/server/database/jobs_directory/000/117/upload_params.json' '171:/galaxy/server/database/objects/6/d/6/dataset_6d6c8552-fc70-4725-a223-ff0b53225d6e_files:/galaxy/server/database/objects/6/d/6/dataset_6d6c8552-fc70-4725-a223-ff0b53225d6e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (117) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/117/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/117/galaxy_117.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 117 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:33,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [118] prepared (87.841 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:33,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/118/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/118/registry.xml' '/galaxy/server/database/jobs_directory/000/118/upload_params.json' '172:/galaxy/server/database/objects/d/7/9/dataset_d794c194-9ea7-406c-9e32-d774e293d53e_files:/galaxy/server/database/objects/d/7/9/dataset_d794c194-9ea7-406c-9e32-d774e293d53e.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,568 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 117 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:33,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (118) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/118/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/118/galaxy_118.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 118 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:33,599 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 118 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,438 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 119, 123, 122, 121, 120, 124
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
tpv.core.entities DEBUG 2024-11-24 06:42:34,473 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,474 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (119) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,477 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (119) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:34,497 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (119) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:42:34,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (119) Working directory for job is: /galaxy/server/database/jobs_directory/000/119
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,525 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [119] queued (47.219 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:34,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (119) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 119
tpv.core.entities DEBUG 2024-11-24 06:42:34,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,541 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (120) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (120) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:34,557 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (120) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:34,583 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (120) Working directory for job is: /galaxy/server/database/jobs_directory/000/120
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,591 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [120] queued (44.963 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:34,594 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (120) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,598 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 120
tpv.core.entities DEBUG 2024-11-24 06:42:34,615 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,616 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (121) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,620 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (121) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:34,638 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (121) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:34,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [119] prepared (118.945 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:34,681 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (121) Working directory for job is: /galaxy/server/database/jobs_directory/000/121
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,689 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [121] queued (68.480 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:34,692 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (121) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:42:34,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/119/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/119/registry.xml' '/galaxy/server/database/jobs_directory/000/119/upload_params.json' '173:/galaxy/server/database/objects/d/c/1/dataset_dc1f45d2-c8c7-4704-8e45-09e370d8b4ee_files:/galaxy/server/database/objects/d/c/1/dataset_dc1f45d2-c8c7-4704-8e45-09e370d8b4ee.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,697 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 121
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (119) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/119/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/119/galaxy_119.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:34,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (122) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,719 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (122) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 119 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:34,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [120] prepared (125.710 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:34,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (122) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 119 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:34,777 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (122) Working directory for job is: /galaxy/server/database/jobs_directory/000/122
galaxy.jobs.command_factory INFO 2024-11-24 06:42:34,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/120/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/120/registry.xml' '/galaxy/server/database/jobs_directory/000/120/upload_params.json' '174:/galaxy/server/database/objects/e/0/6/dataset_e0689946-af5f-42d9-9dca-50cdc5373711_files:/galaxy/server/database/objects/e/0/6/dataset_e0689946-af5f-42d9-9dca-50cdc5373711.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,788 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [122] queued (68.639 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:34,792 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (122) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 122
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (120) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/120/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/120/galaxy_120.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:34,814 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,814 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (123) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,822 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (123) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 120 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:34,842 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (123) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 120 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:34,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [121] prepared (164.118 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:34,882 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (123) Working directory for job is: /galaxy/server/database/jobs_directory/000/123
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,895 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [123] queued (72.751 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:34,900 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (123) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 123
tpv.core.entities DEBUG 2024-11-24 06:42:34,928 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:34,929 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (124) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:34,934 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (124) Dispatching to k8s runner
galaxy.jobs.command_factory INFO 2024-11-24 06:42:34,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/121/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/121/registry.xml' '/galaxy/server/database/jobs_directory/000/121/upload_params.json' '175:/galaxy/server/database/objects/7/e/9/dataset_7e9a849e-a583-4f46-af65-c2720d44a24f_files:/galaxy/server/database/objects/7/e/9/dataset_7e9a849e-a583-4f46-af65-c2720d44a24f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:34,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (121) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/121/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/121/galaxy_121.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:34,949 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (124) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:34,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [122] prepared (151.592 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 121 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:34,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (124) Working directory for job is: /galaxy/server/database/jobs_directory/000/124
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:34,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 121 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:35,006 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [124] queued (72.571 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:35,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (124) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 124
galaxy.jobs.command_factory INFO 2024-11-24 06:42:35,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/122/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/122/registry.xml' '/galaxy/server/database/jobs_directory/000/122/upload_params.json' '176:/galaxy/server/database/objects/6/1/2/dataset_61217ba2-4146-4d99-8e76-666a297ec90e_files:/galaxy/server/database/objects/6/1/2/dataset_61217ba2-4146-4d99-8e76-666a297ec90e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:35,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (122) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/122/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/122/galaxy_122.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:35,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [123] prepared (119.243 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 122 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 122 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:35,083 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/123/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/123/registry.xml' '/galaxy/server/database/jobs_directory/000/123/upload_params.json' '177:/galaxy/server/database/objects/1/f/8/dataset_1f88afbe-9fad-47c7-83ef-e1e53a3a34d7_files:/galaxy/server/database/objects/1/f/8/dataset_1f88afbe-9fad-47c7-83ef-e1e53a3a34d7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:35,097 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (123) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/123/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/123/galaxy_123.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 123 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:35,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [124] prepared (107.765 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 123 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/124/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/124/registry.xml' '/galaxy/server/database/jobs_directory/000/124/upload_params.json' '178:/galaxy/server/database/objects/0/4/f/dataset_04f65cbb-455f-4ee7-84a4-ae13fc3d42a1_files:/galaxy/server/database/objects/0/4/f/dataset_04f65cbb-455f-4ee7-84a4-ae13fc3d42a1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:35,167 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (124) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/124/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/124/galaxy_124.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 124 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,194 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 124 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:35,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,013 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 125, 130, 129, 128, 126, 127
tpv.core.entities DEBUG 2024-11-24 06:42:36,040 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,040 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (125) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,044 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (125) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:36,053 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (125) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:36,067 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (125) Working directory for job is: /galaxy/server/database/jobs_directory/000/125
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,075 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [125] queued (30.590 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:36,077 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (125) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 125
tpv.core.entities DEBUG 2024-11-24 06:42:36,095 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,096 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (126) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,100 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (126) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:36,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (126) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:36,145 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (126) Working directory for job is: /galaxy/server/database/jobs_directory/000/126
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,155 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [126] queued (55.107 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:36,158 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (126) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,163 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 126
tpv.core.entities DEBUG 2024-11-24 06:42:36,174 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,175 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (127) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,179 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (127) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:36,196 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (127) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:36,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [125] prepared (113.994 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:36,226 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (127) Working directory for job is: /galaxy/server/database/jobs_directory/000/127
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,237 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [127] queued (58.108 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,240 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/125/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/125/registry.xml' '/galaxy/server/database/jobs_directory/000/125/upload_params.json' '179:/galaxy/server/database/objects/5/2/8/dataset_528571eb-57cd-4bd2-8aaa-869c031e36ba_files:/galaxy/server/database/objects/5/2/8/dataset_528571eb-57cd-4bd2-8aaa-869c031e36ba.dat']
galaxy.jobs.handler INFO 2024-11-24 06:42:36,242 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (127) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 127
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,258 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (125) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/125/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/125/galaxy_125.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:36,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,277 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (128) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,285 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (128) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:36,298 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (128) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 125 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 125 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:36,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [126] prepared (160.216 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:36,346 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (128) Working directory for job is: /galaxy/server/database/jobs_directory/000/128
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,358 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [128] queued (72.761 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:36,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (128) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 128
tpv.core.entities DEBUG 2024-11-24 06:42:36,379 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,380 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (129) Mapped job to destination id: k8s
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/126/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/126/registry.xml' '/galaxy/server/database/jobs_directory/000/126/upload_params.json' '180:/galaxy/server/database/objects/2/0/e/dataset_20e68a99-35c5-4606-898a-191313638cd3_files:/galaxy/server/database/objects/2/0/e/dataset_20e68a99-35c5-4606-898a-191313638cd3.dat']
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,387 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (129) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,396 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (126) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/126/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/126/galaxy_126.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:36,409 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (129) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:36,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [127] prepared (130.845 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 126 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/127/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/127/registry.xml' '/galaxy/server/database/jobs_directory/000/127/upload_params.json' '181:/galaxy/server/database/objects/8/2/e/dataset_82e3af61-5ad5-4e72-9e22-234c042a7fdc_files:/galaxy/server/database/objects/8/2/e/dataset_82e3af61-5ad5-4e72-9e22-234c042a7fdc.dat']
galaxy.jobs DEBUG 2024-11-24 06:42:36,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (129) Working directory for job is: /galaxy/server/database/jobs_directory/000/129
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,472 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [129] queued (84.542 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,476 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 126 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler INFO 2024-11-24 06:42:36,479 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (129) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,489 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 129
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (127) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/127/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/127/galaxy_127.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:36,506 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:36,506 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (130) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:36,516 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (130) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:36,532 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (130) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 127 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:36,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [128] prepared (167.119 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:36,590 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (130) Working directory for job is: /galaxy/server/database/jobs_directory/000/130
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,594 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/128/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/128/registry.xml' '/galaxy/server/database/jobs_directory/000/128/upload_params.json' '182:/galaxy/server/database/objects/7/3/3/dataset_733c22d2-0f7a-4de4-93b3-6f9a16bbc6f7_files:/galaxy/server/database/objects/7/3/3/dataset_733c22d2-0f7a-4de4-93b3-6f9a16bbc6f7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [130] queued (89.965 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:36,614 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (130) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 130
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 127 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,623 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (128) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/128/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/128/galaxy_128.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,645 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 128 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:36,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [129] prepared (153.394 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,691 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 128 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/129/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/129/registry.xml' '/galaxy/server/database/jobs_directory/000/129/upload_params.json' '183:/galaxy/server/database/objects/0/d/0/dataset_0d083496-c6cc-4260-8fd7-a60720b8e979_files:/galaxy/server/database/objects/0/d/0/dataset_0d083496-c6cc-4260-8fd7-a60720b8e979.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (129) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/129/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/129/galaxy_129.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 129 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:36,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [130] prepared (117.593 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,768 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 129 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:36,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/130/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/130/registry.xml' '/galaxy/server/database/jobs_directory/000/130/upload_params.json' '184:/galaxy/server/database/objects/6/4/3/dataset_643d3274-2bde-47d8-bdb3-329b3c601f28_files:/galaxy/server/database/objects/6/4/3/dataset_643d3274-2bde-47d8-bdb3-329b3c601f28.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:36,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (130) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/130/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/130/galaxy_130.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 130 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:36,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 130 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,483 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:42:37,623 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 137, 136, 135, 134, 133, 132, 131
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
tpv.core.entities DEBUG 2024-11-24 06:42:37,654 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:37,654 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (131) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:37,659 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (131) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:37,672 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (131) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:37,688 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (131) Working directory for job is: /galaxy/server/database/jobs_directory/000/131
galaxy.jobs.runners DEBUG 2024-11-24 06:42:37,700 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [131] queued (40.030 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:37,705 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (131) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 131
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7  pending...
tpv.core.entities DEBUG 2024-11-24 06:42:37,725 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:37,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (132) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:37,731 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (132) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:37,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (132) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:37,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (132) Working directory for job is: /galaxy/server/database/jobs_directory/000/132
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,782 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8m6qg with k8s id: gxy-8m6qg  pending...
galaxy.jobs.runners DEBUG 2024-11-24 06:42:37,783 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [132] queued (51.850 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:37,785 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (132) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,789 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 132
tpv.core.entities DEBUG 2024-11-24 06:42:37,799 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:37,799 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (133) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:37,805 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (133) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:37,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (133) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:37,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [131] prepared (109.432 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:37,855 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (133) Working directory for job is: /galaxy/server/database/jobs_directory/000/133
galaxy.jobs.runners DEBUG 2024-11-24 06:42:37,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [133] queued (63.189 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,876 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 133
galaxy.jobs.handler INFO 2024-11-24 06:42:37,878 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (133) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:42:37,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/131/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/131/registry.xml' '/galaxy/server/database/jobs_directory/000/131/upload_params.json' '185:/galaxy/server/database/objects/2/7/7/dataset_2778f0bb-ee80-4065-8115-02bd44b055b6_files:/galaxy/server/database/objects/2/7/7/dataset_2778f0bb-ee80-4065-8115-02bd44b055b6.dat']
tpv.core.entities DEBUG 2024-11-24 06:42:37,907 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:37,908 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (134) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:37,917 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (134) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:42:37,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (131) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/131/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/131/galaxy_131.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:37,941 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (134) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:37,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [132] prepared (146.676 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:37,967 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 131 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:37,999 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (134) Working directory for job is: /galaxy/server/database/jobs_directory/000/134
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [134] queued (97.424 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/132/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/132/registry.xml' '/galaxy/server/database/jobs_directory/000/132/upload_params.json' '186:/galaxy/server/database/objects/2/5/3/dataset_253f85a5-3513-4cc6-a56e-3a011a80b0b7_files:/galaxy/server/database/objects/2/5/3/dataset_253f85a5-3513-4cc6-a56e-3a011a80b0b7.dat']
galaxy.jobs.handler INFO 2024-11-24 06:42:38,021 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (134) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 131 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 134
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (132) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/132/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/132/galaxy_132.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:38,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:38,047 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (135) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:38,058 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (135) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,073 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 132 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,084 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [133] prepared (195.067 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:38,089 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (135) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 132 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,132 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (135) Working directory for job is: /galaxy/server/database/jobs_directory/000/135
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/133/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/133/registry.xml' '/galaxy/server/database/jobs_directory/000/133/upload_params.json' '187:/galaxy/server/database/objects/4/0/7/dataset_4079e13e-39d6-4077-8840-0afb4862a2ef_files:/galaxy/server/database/objects/4/0/7/dataset_4079e13e-39d6-4077-8840-0afb4862a2ef.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,147 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [135] queued (89.254 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:38,152 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (135) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 135
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,160 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (133) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/133/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/133/galaxy_133.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:42:38,170 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:38,171 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (136) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:38,177 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (136) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:38,196 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (136) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 133 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [134] prepared (153.369 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/134/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/134/registry.xml' '/galaxy/server/database/jobs_directory/000/134/upload_params.json' '188:/galaxy/server/database/objects/9/5/5/dataset_955ce1a8-efbf-4062-8b9e-d2b5eafcb040_files:/galaxy/server/database/objects/9/5/5/dataset_955ce1a8-efbf-4062-8b9e-d2b5eafcb040.dat']
galaxy.jobs DEBUG 2024-11-24 06:42:38,250 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (136) Working directory for job is: /galaxy/server/database/jobs_directory/000/136
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 133 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,261 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [136] queued (84.360 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:38,269 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (136) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,272 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (134) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/134/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/134/galaxy_134.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,273 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 136
tpv.core.entities DEBUG 2024-11-24 06:42:38,290 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:38,290 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (137) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:38,296 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (137) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,305 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 134 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,316 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (137) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 134 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [135] prepared (181.518 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:38,359 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (137) Working directory for job is: /galaxy/server/database/jobs_directory/000/137
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,379 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [137] queued (83.640 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:38,388 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (137) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 137
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/135/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/135/registry.xml' '/galaxy/server/database/jobs_directory/000/135/upload_params.json' '189:/galaxy/server/database/objects/d/8/b/dataset_d8bea80a-39cc-489c-825f-dfcfac81b701_files:/galaxy/server/database/objects/d/8/b/dataset_d8bea80a-39cc-489c-825f-dfcfac81b701.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,415 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/135/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/135/galaxy_135.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 135 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:38,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [136] prepared (177.650 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 135 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/136/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/136/registry.xml' '/galaxy/server/database/jobs_directory/000/136/upload_params.json' '190:/galaxy/server/database/objects/e/2/8/dataset_e28276af-1a65-4f42-bbde-cca85a39b7a7_files:/galaxy/server/database/objects/e/2/8/dataset_e28276af-1a65-4f42-bbde-cca85a39b7a7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,543 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (136) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/136/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/136/galaxy_136.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:38,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [137] prepared (148.778 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 136 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 136 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:38,583 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/137/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/137/registry.xml' '/galaxy/server/database/jobs_directory/000/137/upload_params.json' '191:/galaxy/server/database/objects/5/0/2/dataset_502910d4-ecf5-49dd-8af7-95687cbc37d3_files:/galaxy/server/database/objects/5/0/2/dataset_502910d4-ecf5-49dd-8af7-95687cbc37d3.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:38,595 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (137) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/137/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/137/galaxy_137.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 137 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:38,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 137 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8m6qg with k8s id: gxy-8m6qg  pending...
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,394 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 138, 140, 139, 142, 141
tpv.core.entities DEBUG 2024-11-24 06:42:39,423 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:39,424 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (138) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,427 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (138) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:39,438 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (138) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,441 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79xvr with k8s id: gxy-79xvr  pending...
galaxy.jobs DEBUG 2024-11-24 06:42:39,455 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (138) Working directory for job is: /galaxy/server/database/jobs_directory/000/138
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,461 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [138] queued (33.905 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:39,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (138) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 138
tpv.core.entities DEBUG 2024-11-24 06:42:39,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:39,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (139) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,480 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (139) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:39,494 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (139) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:39,528 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (139) Working directory for job is: /galaxy/server/database/jobs_directory/000/139
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,536 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [139] queued (55.474 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:39,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (139) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 139
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,558 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
tpv.core.entities DEBUG 2024-11-24 06:42:39,566 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:39,567 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (140) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,577 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (140) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:39,592 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (140) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:39,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [138] prepared (145.523 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:39,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (140) Working directory for job is: /galaxy/server/database/jobs_directory/000/140
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,645 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [140] queued (67.668 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:39,649 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (140) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 140
tpv.core.entities DEBUG 2024-11-24 06:42:39,663 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:39,664 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (141) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (141) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:39,684 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (141) Persisting job destination (destination id: k8s)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:39,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/138/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/138/registry.xml' '/galaxy/server/database/jobs_directory/000/138/upload_params.json' '192:/galaxy/server/database/objects/d/3/9/dataset_d3907b1c-086c-4b1f-bcd7-05c0edac50f4_files:/galaxy/server/database/objects/d/3/9/dataset_d3907b1c-086c-4b1f-bcd7-05c0edac50f4.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (138) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/138/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/138/galaxy_138.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:42:39,744 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [139] prepared (168.538 ms)
galaxy.jobs DEBUG 2024-11-24 06:42:39,751 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (141) Working directory for job is: /galaxy/server/database/jobs_directory/000/141
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,764 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [141] queued (96.098 ms)
galaxy.jobs.handler INFO 2024-11-24 06:42:39,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (141) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,778 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 141
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,784 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 138 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:39,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/139/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/139/registry.xml' '/galaxy/server/database/jobs_directory/000/139/upload_params.json' '193:/galaxy/server/database/objects/d/2/d/dataset_d2d768a7-edb8-4603-a65e-2c5599136f4d_files:/galaxy/server/database/objects/d/2/d/dataset_d2d768a7-edb8-4603-a65e-2c5599136f4d.dat']
tpv.core.entities DEBUG 2024-11-24 06:42:39,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:42:39,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (142) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (139) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/139/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/139/galaxy_139.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 138 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:42:39,817 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (142) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:42:39,840 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (142) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:42:39,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [140] prepared (186.058 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-q5gpr with k8s id: gxy-q5gpr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,871 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 139 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:42:39,903 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (142) Working directory for job is: /galaxy/server/database/jobs_directory/000/142
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [142] queued (95.364 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:39,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/140/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/140/registry.xml' '/galaxy/server/database/jobs_directory/000/140/upload_params.json' '194:/galaxy/server/database/objects/0/d/0/dataset_0d038921-fa26-4ff6-b279-f9e9d1c3e86e_files:/galaxy/server/database/objects/0/d/0/dataset_0d038921-fa26-4ff6-b279-f9e9d1c3e86e.dat']
galaxy.jobs.handler INFO 2024-11-24 06:42:39,923 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (142) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 139 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:39,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (140) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/140/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/140/galaxy_140.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,955 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 142
galaxy.jobs DEBUG 2024-11-24 06:42:39,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [141] prepared (164.165 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 140 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:39,981 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mdd2c with k8s id: gxy-mdd2c  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 140 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:42:40,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/141/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/141/registry.xml' '/galaxy/server/database/jobs_directory/000/141/upload_params.json' '195:/galaxy/server/database/objects/f/0/e/dataset_f0eaf711-f11e-4240-8d5f-c0fb789cd165_files:/galaxy/server/database/objects/f/0/e/dataset_f0eaf711-f11e-4240-8d5f-c0fb789cd165.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:40,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (141) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/141/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/141/galaxy_141.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,047 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 141 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 141 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,082 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs DEBUG 2024-11-24 06:42:40,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [142] prepared (108.999 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:42:40,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/142/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/142/registry.xml' '/galaxy/server/database/jobs_directory/000/142/upload_params.json' '196:/galaxy/server/database/objects/a/5/c/dataset_a5cb8e4b-810f-4cf3-b691-ef00603e5d46_files:/galaxy/server/database/objects/a/5/c/dataset_a5cb8e4b-810f-4cf3-b691-ef00603e5d46.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:42:40,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (142) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/142/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/142/galaxy_142.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 142 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,161 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 142 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:40,213 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,593 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79xvr with k8s id: gxy-79xvr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,674 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,738 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-q5gpr with k8s id: gxy-q5gpr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,777 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mdd2c with k8s id: gxy-mdd2c  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,819 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9wwbf with k8s id: gxy-9wwbf  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:41,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rn8mq with k8s id: gxy-rn8mq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:42,032 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wsq82 with k8s id: gxy-wsq82  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:42,066 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-scl4x with k8s id: gxy-scl4x  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:42,149 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bjgj2 with k8s id: gxy-bjgj2  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ddg7l with k8s id: gxy-ddg7l succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,178 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8r6db with k8s id: gxy-8r6db succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:42:43,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 113: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:42:43,379 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 114: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79xvr with k8s id: gxy-79xvr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,784 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:43,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-q5gpr with k8s id: gxy-q5gpr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,174 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mdd2c with k8s id: gxy-mdd2c  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9wwbf with k8s id: gxy-9wwbf  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rn8mq with k8s id: gxy-rn8mq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,699 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wsq82 with k8s id: gxy-wsq82  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-scl4x with k8s id: gxy-scl4x  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:44,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bjgj2 with k8s id: gxy-bjgj2  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:45,784 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kqrjk with k8s id: gxy-kqrjk succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:45,805 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6s4fq with k8s id: gxy-6s4fq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:45,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-csk52 with k8s id: gxy-csk52 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:45,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ztwf2 with k8s id: gxy-ztwf2 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:42:46,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 116: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:42:46,060 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 115: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,129 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-q5gpr with k8s id: gxy-q5gpr  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mdd2c with k8s id: gxy-mdd2c  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,638 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,738 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:46,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:47,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:47,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:47,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:48,446 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ftg52 with k8s id: gxy-ftg52 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:48,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6ggtq with k8s id: gxy-6ggtq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:48,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2n2mz with k8s id: gxy-2n2mz succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:48,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tc5t8 with k8s id: gxy-tc5t8 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:48,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:49,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:50,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rlljb with k8s id: gxy-rlljb succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:50,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-v944t with k8s id: gxy-v944t succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:50,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rkz7m with k8s id: gxy-rkz7m succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4j98w with k8s id: gxy-4j98w succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-m8tkc with k8s id: gxy-m8tkc succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:51,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:52,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8m6qg with k8s id: gxy-8m6qg succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:52,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:52,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:53,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:53,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:53,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:54,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:54,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:55,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:55,304 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:55,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:56,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:56,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:57,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9wwbf with k8s id: gxy-9wwbf succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:57,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rn8mq with k8s id: gxy-rn8mq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:57,102 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-scl4x with k8s id: gxy-scl4x succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:57,113 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bjgj2 with k8s id: gxy-bjgj2 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtfk7 with k8s id: gxy-mtfk7 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79xvr failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-79xvr.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 130 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:42:58,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-79xvr

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-79xvr": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-q5gpr with k8s id: gxy-q5gpr succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mdd2c with k8s id: gxy-mdd2c succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:58,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wsq82 with k8s id: gxy-wsq82 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:42:59,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 113 finished
galaxy.model.metadata DEBUG 2024-11-24 06:42:59,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 167
galaxy.jobs INFO 2024-11-24 06:42:59,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 113 in /galaxy/server/database/jobs_directory/000/113
galaxy.jobs DEBUG 2024-11-24 06:42:59,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 113 executed (195.974 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:42:59,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 113 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:42:59,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 117: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:42:59,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 114 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:00,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 168
galaxy.jobs INFO 2024-11-24 06:43:00,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 114 in /galaxy/server/database/jobs_directory/000/114
galaxy.jobs DEBUG 2024-11-24 06:43:00,153 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 114 executed (206.946 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:00,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 114 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:00,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 118: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:04,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 116 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:04,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 170
galaxy.jobs INFO 2024-11-24 06:43:04,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 116 in /galaxy/server/database/jobs_directory/000/116
galaxy.jobs DEBUG 2024-11-24 06:43:04,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 116 executed (378.612 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:04,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tz9jp with k8s id: gxy-tz9jp succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:43:04,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 115 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:04,547 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 116 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:04,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-d668n with k8s id: gxy-d668n succeeded
galaxy.model.metadata DEBUG 2024-11-24 06:43:04,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 169
galaxy.jobs INFO 2024-11-24 06:43:04,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 115 in /galaxy/server/database/jobs_directory/000/115
galaxy.jobs DEBUG 2024-11-24 06:43:04,758 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 115 executed (157.447 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:04,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 115 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:04,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 119: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:05,160 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 120: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:05,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vwzx6 with k8s id: gxy-vwzx6 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:05,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xckjq with k8s id: gxy-xckjq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:05,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-j4jl8 with k8s id: gxy-j4jl8 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:43:14,710 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 117 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:14,751 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 171
galaxy.jobs INFO 2024-11-24 06:43:14,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 117 in /galaxy/server/database/jobs_directory/000/117
galaxy.jobs DEBUG 2024-11-24 06:43:14,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 117 executed (183.522 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:14,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 117 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:15,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 122: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:15,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 118 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:15,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 172
galaxy.jobs INFO 2024-11-24 06:43:15,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 118 in /galaxy/server/database/jobs_directory/000/118
galaxy.jobs DEBUG 2024-11-24 06:43:15,825 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 118 executed (192.020 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:15,837 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 118 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:16,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 121: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:19,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 119 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:19,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 173
galaxy.jobs INFO 2024-11-24 06:43:19,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 119 in /galaxy/server/database/jobs_directory/000/119
galaxy.jobs DEBUG 2024-11-24 06:43:19,854 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 119 executed (135.150 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:19,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 119 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:19,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 120 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:20,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 174
galaxy.jobs INFO 2024-11-24 06:43:20,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 120 in /galaxy/server/database/jobs_directory/000/120
galaxy.jobs DEBUG 2024-11-24 06:43:20,151 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 120 executed (190.490 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:20,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 120 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:20,171 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 123: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:20,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 124: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:30,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 122 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:30,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 176
galaxy.jobs INFO 2024-11-24 06:43:30,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 122 in /galaxy/server/database/jobs_directory/000/122
galaxy.jobs DEBUG 2024-11-24 06:43:30,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 122 executed (130.065 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:30,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 122 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:30,643 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 125: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:30,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 121 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:31,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 175
galaxy.jobs INFO 2024-11-24 06:43:31,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 121 in /galaxy/server/database/jobs_directory/000/121
galaxy.jobs DEBUG 2024-11-24 06:43:31,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 121 executed (200.407 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:31,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 121 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:31,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 126: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:35,106 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 124 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:43:35,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 123 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:35,223 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 178
galaxy.model.metadata DEBUG 2024-11-24 06:43:35,224 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 177
galaxy.jobs INFO 2024-11-24 06:43:35,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 124 in /galaxy/server/database/jobs_directory/000/124
galaxy.jobs INFO 2024-11-24 06:43:35,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 123 in /galaxy/server/database/jobs_directory/000/123
galaxy.jobs DEBUG 2024-11-24 06:43:35,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 124 executed (226.357 ms)
galaxy.jobs DEBUG 2024-11-24 06:43:35,364 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 123 executed (237.265 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:35,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 124 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:35,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 123 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:35,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 127: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:35,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 129: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:45,441 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 125 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:45,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 179
galaxy.jobs INFO 2024-11-24 06:43:45,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 125 in /galaxy/server/database/jobs_directory/000/125
galaxy.jobs DEBUG 2024-11-24 06:43:45,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 125 executed (195.465 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:45,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 125 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:46,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 138: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:46,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 126 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:46,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 180
galaxy.jobs INFO 2024-11-24 06:43:46,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 126 in /galaxy/server/database/jobs_directory/000/126
galaxy.jobs DEBUG 2024-11-24 06:43:46,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 126 executed (136.200 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:46,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 126 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:46,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 140: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:50,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 127 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:43:50,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 129 finished
galaxy.model.metadata DEBUG 2024-11-24 06:43:50,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 181
galaxy.model.metadata DEBUG 2024-11-24 06:43:50,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 183
galaxy.jobs INFO 2024-11-24 06:43:50,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 127 in /galaxy/server/database/jobs_directory/000/127
galaxy.jobs INFO 2024-11-24 06:43:50,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 129 in /galaxy/server/database/jobs_directory/000/129
galaxy.jobs DEBUG 2024-11-24 06:43:50,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 127 executed (136.536 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:50,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 127 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:43:50,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 129 executed (135.223 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:43:50,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 129 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:43:50,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 141: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:43:50,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 142: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:00,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 138 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:00,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 192
galaxy.jobs INFO 2024-11-24 06:44:00,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 138 in /galaxy/server/database/jobs_directory/000/138
galaxy.jobs DEBUG 2024-11-24 06:44:00,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 138 executed (194.257 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:00,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 138 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:00,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 140 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:01,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 194
galaxy.jobs INFO 2024-11-24 06:44:01,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 140 in /galaxy/server/database/jobs_directory/000/140
galaxy.jobs.runners DEBUG 2024-11-24 06:44:01,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 128: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:44:01,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 140 executed (169.838 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:01,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 140 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:01,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 133: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:05,431 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 141 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:05,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 195
galaxy.jobs INFO 2024-11-24 06:44:05,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 141 in /galaxy/server/database/jobs_directory/000/141
galaxy.jobs DEBUG 2024-11-24 06:44:05,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 141 executed (183.006 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:05,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 141 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:05,734 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 142 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:05,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 196
galaxy.jobs INFO 2024-11-24 06:44:05,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 142 in /galaxy/server/database/jobs_directory/000/142
galaxy.jobs.runners DEBUG 2024-11-24 06:44:05,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 134: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:44:05,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 142 executed (159.225 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:05,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 142 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:06,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 139: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:15,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 128 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:15,733 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 182
galaxy.jobs INFO 2024-11-24 06:44:15,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 128 in /galaxy/server/database/jobs_directory/000/128
galaxy.jobs DEBUG 2024-11-24 06:44:15,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 128 executed (127.396 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:15,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 128 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:16,138 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 133 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:44:16,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 131: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.model.metadata DEBUG 2024-11-24 06:44:16,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 187
galaxy.jobs INFO 2024-11-24 06:44:16,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 133 in /galaxy/server/database/jobs_directory/000/133
galaxy.jobs DEBUG 2024-11-24 06:44:16,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 133 executed (195.994 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:16,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 133 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:16,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 132: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:20,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 134 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:20,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 188
galaxy.jobs INFO 2024-11-24 06:44:20,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 134 in /galaxy/server/database/jobs_directory/000/134
galaxy.jobs DEBUG 2024-11-24 06:44:20,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 134 executed (147.289 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:20,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 134 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:20,821 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 139 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:20,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 193
galaxy.jobs INFO 2024-11-24 06:44:20,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 139 in /galaxy/server/database/jobs_directory/000/139
galaxy.jobs.runners DEBUG 2024-11-24 06:44:20,960 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 135: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:44:21,008 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 139 executed (168.324 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:21,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 139 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:21,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 136: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:30,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 131 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:30,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 185
galaxy.jobs INFO 2024-11-24 06:44:30,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 131 in /galaxy/server/database/jobs_directory/000/131
galaxy.jobs DEBUG 2024-11-24 06:44:30,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 131 executed (186.275 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:30,821 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 131 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:31,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 137: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:31,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 132 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:31,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 186
galaxy.jobs INFO 2024-11-24 06:44:31,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 132 in /galaxy/server/database/jobs_directory/000/132
galaxy.jobs DEBUG 2024-11-24 06:44:31,442 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 132 executed (190.387 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 132 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (130/gxy-79xvr) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (130/gxy-79xvr) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (130/gxy-79xvr) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (130/gxy-79xvr) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-79xvr.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 130 (gxy-79xvr)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Could not find job with id gxy-79xvr to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:31,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (130/gxy-79xvr) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 06:44:32,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 143
tpv.core.entities DEBUG 2024-11-24 06:44:32,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:44:32,647 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (143) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:44:32,650 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (143) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:44:32,707 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (143) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:44:32,717 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (143) Working directory for job is: /galaxy/server/database/jobs_directory/000/143
galaxy.jobs.runners DEBUG 2024-11-24 06:44:32,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [143] queued (73.390 ms)
galaxy.jobs.handler INFO 2024-11-24 06:44:32,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (143) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:32,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 143
galaxy.jobs DEBUG 2024-11-24 06:44:32,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [143] prepared (109.220 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:44:32,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/143/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/143/registry.xml' '/galaxy/server/database/jobs_directory/000/143/upload_params.json' '197:/galaxy/server/database/objects/f/6/4/dataset_f648713c-dc83-4bd9-ac1a-d0387d253eb2_files:/galaxy/server/database/objects/f/6/4/dataset_f648713c-dc83-4bd9-ac1a-d0387d253eb2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:44:32,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (143) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/143/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/143/galaxy_143.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:32,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 143 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:32,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 143 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:44:33,729 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 144
tpv.core.entities DEBUG 2024-11-24 06:44:33,808 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:44:33,808 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (144) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:44:33,902 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (144) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:44:33,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (144) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:34,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:44:34,012 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (144) Working directory for job is: /galaxy/server/database/jobs_directory/000/144
galaxy.jobs.runners DEBUG 2024-11-24 06:44:34,020 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [144] queued (117.446 ms)
galaxy.jobs.handler INFO 2024-11-24 06:44:34,022 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (144) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:34,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 144
galaxy.jobs DEBUG 2024-11-24 06:44:34,152 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [144] prepared (121.370 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:44:34,212 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/144/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/144/registry.xml' '/galaxy/server/database/jobs_directory/000/144/upload_params.json' '198:/galaxy/server/database/objects/9/8/3/dataset_9838f666-66c0-4d87-be9f-21b9358f7cd7_files:/galaxy/server/database/objects/9/8/3/dataset_9838f666-66c0-4d87-be9f-21b9358f7cd7.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:44:34,221 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (144) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/144/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/144/galaxy_144.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:34,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 144 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:34,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 144 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:34,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 135 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:34,917 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 189
galaxy.jobs INFO 2024-11-24 06:44:34,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 135 in /galaxy/server/database/jobs_directory/000/135
galaxy.jobs DEBUG 2024-11-24 06:44:34,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 135 executed (97.861 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:44:35,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 136 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 135 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:44:35,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 190
galaxy.jobs INFO 2024-11-24 06:44:35,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 136 in /galaxy/server/database/jobs_directory/000/136
galaxy.jobs.runners ERROR 2024-11-24 06:44:35,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (135) Unhandled exception calling finish_job
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-vwzx6

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/__init__.py", line 174, in run_next
    method(arg)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 1128, in finish_job
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-vwzx6": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] 135/gxy-vwzx6 Job output not returned from cluster: [Errno 2] No such file or directory: '/galaxy/server/database/jobs_directory/000/135/galaxy_135.o'
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135/gxy-vwzx6) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135/gxy-vwzx6) tool_stderr: Job output not returned from cluster
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135/gxy-vwzx6) job_stdout: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135/gxy-vwzx6) job_stderr: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 135 (gxy-vwzx6)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Found job with id gxy-vwzx6 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,138 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 135 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:44:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 136 executed (114.182 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 136 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners ERROR 2024-11-24 06:44:35,294 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (136) Unhandled exception calling finish_job
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-xckjq

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/__init__.py", line 174, in run_next
    method(arg)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 1128, in finish_job
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: jobs.batch "gxy-xckjq" not found
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,295 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (135/gxy-vwzx6) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] 136/gxy-xckjq Job output not returned from cluster: [Errno 2] No such file or directory: '/galaxy/server/database/jobs_directory/000/136/galaxy_136.o'
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (136/gxy-xckjq) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (136/gxy-xckjq) tool_stderr: Job output not returned from cluster
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (136/gxy-xckjq) job_stdout: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (136/gxy-xckjq) job_stderr: None
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 136 (gxy-xckjq)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Could not find job with id gxy-xckjq to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:35,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (136/gxy-xckjq) Terminated at user's request
galaxy.jobs ERROR 2024-11-24 06:44:35,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to cleanup job 135
Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/__init__.py", line 2133, in cleanup
    self.object_store.delete(
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 469, in delete
    return self._invoke("delete", obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 451, in _invoke
    return self.__getattribute__(f"_{delegate}")(obj=obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 870, in _delete
    path = self._get_filename(obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 916, in _get_filename
    raise ObjectNotFound
galaxy.exceptions.ObjectNotFound: No such object found.
galaxy.jobs ERROR 2024-11-24 06:44:35,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to cleanup job 136
Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/__init__.py", line 2133, in cleanup
    self.object_store.delete(
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 469, in delete
    return self._invoke("delete", obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 451, in _invoke
    return self.__getattribute__(f"_{delegate}")(obj=obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 870, in _delete
    path = self._get_filename(obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/galaxy/server/lib/galaxy/objectstore/__init__.py", line 916, in _get_filename
    raise ObjectNotFound
galaxy.exceptions.ObjectNotFound: No such object found.
galaxy.jobs.runners DEBUG 2024-11-24 06:44:39,759 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 137 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:39,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 191
galaxy.jobs INFO 2024-11-24 06:44:39,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 137 in /galaxy/server/database/jobs_directory/000/137
galaxy.jobs DEBUG 2024-11-24 06:44:39,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 137 executed (86.035 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:44:39,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] No k8s job found which matches job id 'gxy-j4jl8'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:43,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4zx6m with k8s id: gxy-4zx6m succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:44:43,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 143: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:44,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kwr7f with k8s id: gxy-kwr7f succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:44:44,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 144: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:44:50,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 143 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:50,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 197
galaxy.jobs INFO 2024-11-24 06:44:50,758 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 143 in /galaxy/server/database/jobs_directory/000/143
galaxy.jobs DEBUG 2024-11-24 06:44:50,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 143 executed (91.474 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:50,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 143 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:44:51,621 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 144 finished
galaxy.model.metadata DEBUG 2024-11-24 06:44:51,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 198
galaxy.jobs INFO 2024-11-24 06:44:51,687 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 144 in /galaxy/server/database/jobs_directory/000/144
galaxy.jobs DEBUG 2024-11-24 06:44:51,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 144 executed (91.949 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:51,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 144 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:44:52,400 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 145
tpv.core.entities DEBUG 2024-11-24 06:44:52,422 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:44:52,422 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (145) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:44:52,425 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (145) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:44:52,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (145) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:44:52,444 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (145) Working directory for job is: /galaxy/server/database/jobs_directory/000/145
galaxy.jobs.runners DEBUG 2024-11-24 06:44:52,452 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [145] queued (26.096 ms)
galaxy.jobs.handler INFO 2024-11-24 06:44:52,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (145) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:52,456 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 145
galaxy.jobs DEBUG 2024-11-24 06:44:52,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [145] prepared (49.272 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:44:52,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:44:52,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:44:52,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:44:52,778 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/145/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/145/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/custom_content_0 &&  ln -s '/galaxy/server/database/objects/f/6/4/dataset_f648713c-dc83-4bd9-ac1a-d0387d253eb2.dat' 'multiqc_WDir/custom_content_0/file_0_0' && more /galaxy/server/database/objects/f/6/4/dataset_f648713c-dc83-4bd9-ac1a-d0387d253eb2.dat && ln -s '/galaxy/server/database/objects/9/8/3/dataset_9838f666-66c0-4d87-be9f-21b9358f7cd7.dat' 'multiqc_WDir/custom_content_0/file_0_1' && more /galaxy/server/database/objects/9/8/3/dataset_9838f666-66c0-4d87-be9f-21b9358f7cd7.dat &&  multiqc multiqc_WDir --filename "report"      --config '/galaxy/server/database/jobs_directory/000/145/configs/tmp0plhjp8l']
galaxy.jobs.runners DEBUG 2024-11-24 06:44:52,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (145) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/145/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/145/galaxy_145.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/145/working/report.html" -a -f "/galaxy/server/database/objects/8/6/c/dataset_86c0773c-a637-4f0c-a029-2e844db6e64f.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/145/working/report.html" "/galaxy/server/database/objects/8/6/c/dataset_86c0773c-a637-4f0c-a029-2e844db6e64f.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:52,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 145 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:44:52,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:44:52,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:44:52,817 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:52,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 145 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:53,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:44:59,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wzwdt with k8s id: gxy-wzwdt succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:44:59,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 145: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:45:06,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 145 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:45:06,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (145) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/145/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (3.790 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:06,750 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (145) Add dynamic collection datasets to history for output [stats] (14.071 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:45:06,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 199
galaxy.jobs INFO 2024-11-24 06:45:06,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 145 in /galaxy/server/database/jobs_directory/000/145
galaxy.jobs DEBUG 2024-11-24 06:45:06,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 145 executed (115.973 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:06,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 145 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:45:08,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 146, 147
tpv.core.entities DEBUG 2024-11-24 06:45:08,731 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:45:08,732 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (146) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:45:08,735 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (146) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:45:08,743 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (146) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:45:08,754 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (146) Working directory for job is: /galaxy/server/database/jobs_directory/000/146
galaxy.jobs.runners DEBUG 2024-11-24 06:45:08,760 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [146] queued (25.050 ms)
galaxy.jobs.handler INFO 2024-11-24 06:45:08,762 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (146) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 146
tpv.core.entities DEBUG 2024-11-24 06:45:08,771 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:45:08,772 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (147) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:45:08,775 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (147) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:45:08,786 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (147) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:45:08,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (147) Working directory for job is: /galaxy/server/database/jobs_directory/000/147
galaxy.jobs.runners DEBUG 2024-11-24 06:45:08,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [147] queued (43.473 ms)
galaxy.jobs.handler INFO 2024-11-24 06:45:08,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (147) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 147
galaxy.jobs DEBUG 2024-11-24 06:45:08,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [146] prepared (88.726 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:45:08,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/146/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/146/registry.xml' '/galaxy/server/database/jobs_directory/000/146/upload_params.json' '201:/galaxy/server/database/objects/2/d/3/dataset_2d359302-4a59-4dc2-9c9e-e5f8141fe8fc_files:/galaxy/server/database/objects/2/d/3/dataset_2d359302-4a59-4dc2-9c9e-e5f8141fe8fc.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:45:08,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (146) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/146/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/146/galaxy_146.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:45:08,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [147] prepared (71.221 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 146 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 146 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:45:08,928 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/147/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/147/registry.xml' '/galaxy/server/database/jobs_directory/000/147/upload_params.json' '202:/galaxy/server/database/objects/f/c/9/dataset_fc981b9e-8471-4e83-b6ed-be343c5e7050_files:/galaxy/server/database/objects/f/c/9/dataset_fc981b9e-8471-4e83-b6ed-be343c5e7050.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:45:08,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (147) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/147/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/147/galaxy_147.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 147 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:08,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 147 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:09,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:09,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:18,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kz9tx with k8s id: gxy-kz9tx succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:18,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ngxkn with k8s id: gxy-ngxkn succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:45:19,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 146: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:45:19,087 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 147: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:45:26,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 146 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:45:26,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 147 finished
galaxy.model.metadata DEBUG 2024-11-24 06:45:26,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 201
galaxy.model.metadata DEBUG 2024-11-24 06:45:26,581 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 202
galaxy.jobs INFO 2024-11-24 06:45:26,587 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 146 in /galaxy/server/database/jobs_directory/000/146
galaxy.jobs INFO 2024-11-24 06:45:26,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 147 in /galaxy/server/database/jobs_directory/000/147
galaxy.jobs DEBUG 2024-11-24 06:45:26,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 146 executed (99.400 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:26,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 146 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:45:26,656 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 147 executed (101.493 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:26,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 147 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:45:27,108 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 148
tpv.core.entities DEBUG 2024-11-24 06:45:27,132 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:45:27,133 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (148) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:45:27,137 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (148) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:45:27,147 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (148) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:45:27,158 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (148) Working directory for job is: /galaxy/server/database/jobs_directory/000/148
galaxy.jobs.runners DEBUG 2024-11-24 06:45:27,166 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [148] queued (29.361 ms)
galaxy.jobs.handler INFO 2024-11-24 06:45:27,169 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (148) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:27,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 148
galaxy.jobs DEBUG 2024-11-24 06:45:27,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [148] prepared (53.922 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:45:27,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:45:27,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:45:27,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:45:27,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/148/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/148/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/fastqc_0 &&    mkdir 'multiqc_WDir/fastqc_0/data_0' &&  mkdir 'multiqc_WDir/fastqc_0/data_0/file_0' && ln -s '/galaxy/server/database/objects/2/d/3/dataset_2d359302-4a59-4dc2-9c9e-e5f8141fe8fc.dat' 'multiqc_WDir/fastqc_0/data_0/file_0/fastqc_data.txt' && mkdir 'multiqc_WDir/fastqc_0/data_0/file_1' && ln -s '/galaxy/server/database/objects/f/c/9/dataset_fc981b9e-8471-4e83-b6ed-be343c5e7050.dat' 'multiqc_WDir/fastqc_0/data_0/file_1/fastqc_data.txt' &&  multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"  --flat --export]
galaxy.jobs.runners DEBUG 2024-11-24 06:45:27,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/148/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/148/galaxy_148.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/148/working/report.html" -a -f "/galaxy/server/database/objects/e/0/1/dataset_e014631e-ed48-4425-aa5e-3448dddd4b55.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/148/working/report.html" "/galaxy/server/database/objects/e/0/1/dataset_e014631e-ed48-4425-aa5e-3448dddd4b55.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:27,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 148 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:45:27,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:45:27,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:45:27,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:27,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 148 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:27,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:40,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zr8q7 with k8s id: gxy-zr8q7 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:45:40,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 148: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:45:47,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 148 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_per_base_n_content_plot_1.txt] with element identifier [fastqc_per_base_n_content_plot_1] for output [plots] (3.207 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_per_base_sequence_quality_plot_1.txt] with element identifier [fastqc_per_base_sequence_quality_plot_1] for output [plots] (0.436 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,195 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Counts.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Counts] for output [plots] (0.342 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Percentages.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Percentages] for output [plots] (0.346 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_per_sequence_quality_scores_plot_1.txt] with element identifier [fastqc_per_sequence_quality_scores_plot_1] for output [plots] (0.364 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_sequence_counts_plot_1.txt] with element identifier [fastqc_sequence_counts_plot_1] for output [plots] (0.523 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/mqc_fastqc_sequence_duplication_levels_plot_1.txt] with element identifier [fastqc_sequence_duplication_levels_plot_1] for output [plots] (0.404 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,252 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Add dynamic collection datasets to history for output [plots] (54.430 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,295 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/multiqc_fastqc.txt] with element identifier [fastqc] for output [stats] (0.613 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (0.378 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/148/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.357 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:45:47,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (148) Add dynamic collection datasets to history for output [stats] (24.436 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:45:47,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 203
galaxy.jobs INFO 2024-11-24 06:45:47,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 148 in /galaxy/server/database/jobs_directory/000/148
galaxy.jobs DEBUG 2024-11-24 06:45:47,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 148 executed (232.105 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:47,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 148 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:45:49,506 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 149
tpv.core.entities DEBUG 2024-11-24 06:45:49,528 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:45:49,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (149) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:45:49,532 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (149) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:45:49,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (149) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:45:49,553 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (149) Working directory for job is: /galaxy/server/database/jobs_directory/000/149
galaxy.jobs.runners DEBUG 2024-11-24 06:45:49,558 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [149] queued (26.541 ms)
galaxy.jobs.handler INFO 2024-11-24 06:45:49,560 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (149) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:49,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 149
galaxy.jobs DEBUG 2024-11-24 06:45:49,643 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [149] prepared (71.530 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:45:49,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/149/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/149/registry.xml' '/galaxy/server/database/jobs_directory/000/149/upload_params.json' '214:/galaxy/server/database/objects/0/f/6/dataset_0f617e08-aef2-4ff7-b8ff-19e0b2d041ee_files:/galaxy/server/database/objects/0/f/6/dataset_0f617e08-aef2-4ff7-b8ff-19e0b2d041ee.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:45:49,665 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (149) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/149/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/149/galaxy_149.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:49,676 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 149 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:49,686 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 149 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:50,166 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:45:59,288 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rhfkk with k8s id: gxy-rhfkk succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:45:59,392 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 149: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:46:06,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 149 finished
galaxy.model.metadata DEBUG 2024-11-24 06:46:06,514 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 214
galaxy.jobs INFO 2024-11-24 06:46:06,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 149 in /galaxy/server/database/jobs_directory/000/149
galaxy.jobs DEBUG 2024-11-24 06:46:06,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 149 executed (85.106 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:06,594 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 149 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:46:06,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 150
tpv.core.entities DEBUG 2024-11-24 06:46:06,854 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:06,854 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (150) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:06,858 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (150) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:06,868 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (150) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:06,878 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (150) Working directory for job is: /galaxy/server/database/jobs_directory/000/150
galaxy.jobs.runners DEBUG 2024-11-24 06:46:06,885 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [150] queued (27.061 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:06,888 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (150) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:06,889 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 150
galaxy.jobs DEBUG 2024-11-24 06:46:06,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [150] prepared (44.422 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:46:06,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:46:06,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:46:06,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:46:06,980 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/150/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/150/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/pycoqc_0 &&         grep -q '"pycoqc":' /galaxy/server/database/objects/0/f/6/dataset_0f617e08-aef2-4ff7-b8ff-19e0b2d041ee.dat || die "Module 'pycoqc: '"pycoqc":' not found in the file 'pycoqc_json'" && ln -s '/galaxy/server/database/objects/0/f/6/dataset_0f617e08-aef2-4ff7-b8ff-19e0b2d041ee.dat' 'multiqc_WDir/pycoqc_0/pycoqc_json'  &&    multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"]
galaxy.jobs.runners DEBUG 2024-11-24 06:46:06,990 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (150) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/150/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/150/galaxy_150.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/150/working/report.html" -a -f "/galaxy/server/database/objects/4/8/d/dataset_48dde28b-1713-4c07-a7a9-f5147303626f.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/150/working/report.html" "/galaxy/server/database/objects/4/8/d/dataset_48dde28b-1713-4c07-a7a9-f5147303626f.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:07,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 150 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:46:07,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:46:07,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:46:07,021 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:07,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 150 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:07,311 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:14,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qnwdf with k8s id: gxy-qnwdf succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:46:14,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 150: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:46:21,408 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 150 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:46:21,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (150) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/150/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (3.782 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:46:21,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (150) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/150/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.548 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:46:21,474 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (150) Add dynamic collection datasets to history for output [stats] (23.202 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:46:21,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 215
galaxy.jobs INFO 2024-11-24 06:46:21,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 150 in /galaxy/server/database/jobs_directory/000/150
galaxy.jobs DEBUG 2024-11-24 06:46:21,566 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 150 executed (139.465 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:21,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 150 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:46:24,235 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 151, 153, 152
tpv.core.entities DEBUG 2024-11-24 06:46:24,257 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:24,257 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (151) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:24,260 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (151) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:24,268 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (151) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:24,278 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (151) Working directory for job is: /galaxy/server/database/jobs_directory/000/151
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,284 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [151] queued (24.150 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:24,286 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (151) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,289 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 151
tpv.core.entities DEBUG 2024-11-24 06:46:24,297 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:24,297 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (152) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:24,300 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (152) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:24,309 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (152) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:24,330 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (152) Working directory for job is: /galaxy/server/database/jobs_directory/000/152
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,337 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [152] queued (37.013 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:24,340 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (152) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 152
tpv.core.entities DEBUG 2024-11-24 06:46:24,357 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:24,357 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (153) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:24,360 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (153) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:24,372 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (153) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:24,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [151] prepared (99.333 ms)
galaxy.jobs DEBUG 2024-11-24 06:46:24,403 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (153) Working directory for job is: /galaxy/server/database/jobs_directory/000/153
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [153] queued (52.431 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:24,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (153) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 153
galaxy.jobs.command_factory INFO 2024-11-24 06:46:24,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/151/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/151/registry.xml' '/galaxy/server/database/jobs_directory/000/151/upload_params.json' '218:/galaxy/server/database/objects/5/3/0/dataset_530e2faf-98f9-4460-8b85-f0890b601faf_files:/galaxy/server/database/objects/5/3/0/dataset_530e2faf-98f9-4460-8b85-f0890b601faf.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (151) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/151/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/151/galaxy_151.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:46:24,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [152] prepared (92.031 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,454 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 151 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 151 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:46:24,483 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/152/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/152/registry.xml' '/galaxy/server/database/jobs_directory/000/152/upload_params.json' '219:/galaxy/server/database/objects/0/1/8/dataset_0184272d-1682-4233-8ad9-94f034dc385b_files:/galaxy/server/database/objects/0/1/8/dataset_0184272d-1682-4233-8ad9-94f034dc385b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (152) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/152/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/152/galaxy_152.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 152 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,528 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 152 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:24,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [153] prepared (100.620 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:24,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/153/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/153/registry.xml' '/galaxy/server/database/jobs_directory/000/153/upload_params.json' '220:/galaxy/server/database/objects/5/d/2/dataset_5d2bc93a-9c5b-4941-af8f-2c684165de93_files:/galaxy/server/database/objects/5/d/2/dataset_5d2bc93a-9c5b-4941-af8f-2c684165de93.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:24,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (153) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/153/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/153/galaxy_153.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,578 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 153 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:24,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 153 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:46:25,422 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 155, 157, 156, 154
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,447 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
tpv.core.entities DEBUG 2024-11-24 06:46:25,453 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:25,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (154) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:25,460 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (154) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:25,472 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (154) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:25,489 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (154) Working directory for job is: /galaxy/server/database/jobs_directory/000/154
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,497 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,498 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [154] queued (38.450 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:25,504 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (154) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 154
tpv.core.entities DEBUG 2024-11-24 06:46:25,523 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:25,524 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (155) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:25,530 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (155) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:25,550 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (155) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:46:25,590 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (155) Working directory for job is: /galaxy/server/database/jobs_directory/000/155
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,597 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [155] queued (66.535 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:25,600 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (155) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 155
tpv.core.entities DEBUG 2024-11-24 06:46:25,613 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:25,613 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (156) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:25,619 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (156) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:25,639 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (156) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:25,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [154] prepared (116.169 ms)
galaxy.jobs DEBUG 2024-11-24 06:46:25,671 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (156) Working directory for job is: /galaxy/server/database/jobs_directory/000/156
galaxy.jobs.command_factory INFO 2024-11-24 06:46:25,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/154/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/154/registry.xml' '/galaxy/server/database/jobs_directory/000/154/upload_params.json' '221:/galaxy/server/database/objects/d/7/1/dataset_d71ef8d0-b08c-4db9-875d-73f7269e15a6_files:/galaxy/server/database/objects/d/7/1/dataset_d71ef8d0-b08c-4db9-875d-73f7269e15a6.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,678 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [156] queued (58.536 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:25,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (156) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 156
tpv.core.entities DEBUG 2024-11-24 06:46:25,717 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:25,718 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (157) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (154) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/154/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/154/galaxy_154.ec; sh -c "exit $return_code"
galaxy.jobs.handler DEBUG 2024-11-24 06:46:25,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (157) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:25,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (157) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,748 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 154 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:25,767 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [155] prepared (151.566 ms)
galaxy.jobs DEBUG 2024-11-24 06:46:25,787 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (157) Working directory for job is: /galaxy/server/database/jobs_directory/000/157
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,796 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [157] queued (71.818 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:25,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (157) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 154 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 157
galaxy.jobs.command_factory INFO 2024-11-24 06:46:25,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/155/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/155/registry.xml' '/galaxy/server/database/jobs_directory/000/155/upload_params.json' '222:/galaxy/server/database/objects/c/f/c/dataset_cfcd86de-6b3c-4a31-9c10-a1f0513e6a1d_files:/galaxy/server/database/objects/c/f/c/dataset_cfcd86de-6b3c-4a31-9c10-a1f0513e6a1d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (155) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/155/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/155/galaxy_155.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:46:25,850 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [156] prepared (127.215 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 155 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 155 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:46:25,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/156/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/156/registry.xml' '/galaxy/server/database/jobs_directory/000/156/upload_params.json' '223:/galaxy/server/database/objects/1/6/f/dataset_16fd45c6-6f43-43d5-9b18-d7ca986ce510_files:/galaxy/server/database/objects/1/6/f/dataset_16fd45c6-6f43-43d5-9b18-d7ca986ce510.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (156) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/156/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/156/galaxy_156.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 156 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 156 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:25,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [157] prepared (111.772 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:25,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/157/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/157/registry.xml' '/galaxy/server/database/jobs_directory/000/157/upload_params.json' '224:/galaxy/server/database/objects/6/1/4/dataset_6144f216-310a-4f30-ac54-1643dc3f73e8_files:/galaxy/server/database/objects/6/1/4/dataset_6144f216-310a-4f30-ac54-1643dc3f73e8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:25,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (157) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/157/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/157/galaxy_157.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 157 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:25,989 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 157 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,777 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:46:26,808 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 160, 159, 161, 158
tpv.core.entities DEBUG 2024-11-24 06:46:26,833 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:26,833 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (158) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:26,837 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (158) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:26,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (158) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:26,859 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (158) Working directory for job is: /galaxy/server/database/jobs_directory/000/158
galaxy.jobs.runners DEBUG 2024-11-24 06:46:26,866 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [158] queued (29.155 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:26,869 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (158) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,872 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 158
tpv.core.entities DEBUG 2024-11-24 06:46:26,879 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:26,880 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (159) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:26,883 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (159) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:26,894 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (159) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:26,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (159) Working directory for job is: /galaxy/server/database/jobs_directory/000/159
galaxy.jobs.runners DEBUG 2024-11-24 06:46:26,927 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [159] queued (43.861 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:26,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (159) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:26,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 159
tpv.core.entities DEBUG 2024-11-24 06:46:26,949 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:26,949 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (160) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:26,957 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (160) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:26,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (160) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:26,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [158] prepared (113.137 ms)
galaxy.jobs DEBUG 2024-11-24 06:46:27,004 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (160) Working directory for job is: /galaxy/server/database/jobs_directory/000/160
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [160] queued (57.739 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:27,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (160) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 160
galaxy.jobs.command_factory INFO 2024-11-24 06:46:27,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/158/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/158/registry.xml' '/galaxy/server/database/jobs_directory/000/158/upload_params.json' '225:/galaxy/server/database/objects/f/3/5/dataset_f35ad565-1401-429f-8e33-5f3e0e9d6532_files:/galaxy/server/database/objects/f/3/5/dataset_f35ad565-1401-429f-8e33-5f3e0e9d6532.dat']
tpv.core.entities DEBUG 2024-11-24 06:46:27,035 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:27,036 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (161) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:27,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (161) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (158) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/158/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/158/galaxy_158.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:46:27,061 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (161) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:27,072 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [159] prepared (118.162 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 158 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:27,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (161) Working directory for job is: /galaxy/server/database/jobs_directory/000/161
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 158 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:46:27,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/159/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/159/registry.xml' '/galaxy/server/database/jobs_directory/000/159/upload_params.json' '226:/galaxy/server/database/objects/a/f/4/dataset_af4dd882-dc76-46fc-86b6-d4d32337f679_files:/galaxy/server/database/objects/a/f/4/dataset_af4dd882-dc76-46fc-86b6-d4d32337f679.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,118 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [161] queued (72.963 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:27,122 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (161) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 161
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/159/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/159/galaxy_159.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,153 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 159 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:27,166 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [160] prepared (129.300 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,177 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 159 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:46:27,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/160/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/160/registry.xml' '/galaxy/server/database/jobs_directory/000/160/upload_params.json' '227:/galaxy/server/database/objects/f/6/c/dataset_f6cdc3f7-ba70-4ab0-93dd-3567fbc31452_files:/galaxy/server/database/objects/f/6/c/dataset_f6cdc3f7-ba70-4ab0-93dd-3567fbc31452.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (160) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/160/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/160/galaxy_160.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 160 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,256 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 160 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:27,258 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [161] prepared (112.936 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:27,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/161/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/161/registry.xml' '/galaxy/server/database/jobs_directory/000/161/upload_params.json' '228:/galaxy/server/database/objects/4/1/6/dataset_4163de0d-56ec-4f21-9bdb-32ddaba18f7e_files:/galaxy/server/database/objects/4/1/6/dataset_4163de0d-56ec-4f21-9bdb-32ddaba18f7e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:27,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (161) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/161/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/161/galaxy_161.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 161 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 161 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:27,997 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:28,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:28,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:28,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:34,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-s5fxp failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:34,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:34,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-s5fxp.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:34,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 151 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:46:35,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-s5fxp

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-s5fxp": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bz7dn with k8s id: gxy-bz7dn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (151/gxy-s5fxp) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (151/gxy-s5fxp) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (151/gxy-s5fxp) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (151/gxy-s5fxp) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-s5fxp.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 151 (gxy-s5fxp)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b5mqw with k8s id: gxy-b5mqw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,175 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Found job with id gxy-s5fxp to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 151 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:35,255 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (151/gxy-s5fxp) Terminated at user's request
galaxy.jobs.runners DEBUG 2024-11-24 06:46:35,334 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 152: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:46:35,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 153: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-24 06:46:36,298 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 164, 163, 162
tpv.core.entities DEBUG 2024-11-24 06:46:36,328 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:36,329 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (162) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:36,334 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (162) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:36,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b8bm6 with k8s id: gxy-b8bm6 succeeded
galaxy.jobs DEBUG 2024-11-24 06:46:36,355 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (162) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:36,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7867p with k8s id: gxy-7867p succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:36,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-dfm8j with k8s id: gxy-dfm8j succeeded
galaxy.jobs DEBUG 2024-11-24 06:46:36,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (162) Working directory for job is: /galaxy/server/database/jobs_directory/000/162
galaxy.jobs.runners DEBUG 2024-11-24 06:46:36,428 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [162] queued (94.308 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:36,436 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (162) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:36,503 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:36,503 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (163) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:36,508 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (163) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:36,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (163) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:36,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (163) Working directory for job is: /galaxy/server/database/jobs_directory/000/163
galaxy.jobs.runners DEBUG 2024-11-24 06:46:36,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [163] queued (36.783 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:36,547 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (163) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:36,560 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:36,560 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (164) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:36,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (164) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:36,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (164) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:36,627 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (164) Working directory for job is: /galaxy/server/database/jobs_directory/000/164
galaxy.jobs.runners DEBUG 2024-11-24 06:46:36,633 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [164] queued (68.290 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:36,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (164) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:46:36,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 154: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:46:36,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 155: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:37,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-27bxr with k8s id: gxy-27bxr succeeded
galaxy.jobs.handler DEBUG 2024-11-24 06:46:37,703 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 167, 165, 169, 166, 168
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:37,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4grz7 with k8s id: gxy-4grz7 succeeded
tpv.core.entities DEBUG 2024-11-24 06:46:37,910 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:37,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (165) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:37,999 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (165) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,001 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-62gg5 failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs DEBUG 2024-11-24 06:46:38,012 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (165) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:38,028 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (165) Working directory for job is: /galaxy/server/database/jobs_directory/000/165
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,032 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-62gg5.
galaxy.jobs.runners DEBUG 2024-11-24 06:46:38,036 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [165] queued (36.358 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:38,038 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (165) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 159 is an interactive tool. guest ports: []. interactive entry points: []
tpv.core.entities DEBUG 2024-11-24 06:46:38,108 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:38,109 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (166) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:38,113 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (166) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:38,122 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (166) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:46:38,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-62gg5

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-62gg5": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qvdxh with k8s id: gxy-qvdxh succeeded
galaxy.jobs DEBUG 2024-11-24 06:46:38,201 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (166) Working directory for job is: /galaxy/server/database/jobs_directory/000/166
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:38,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-xkw48 with k8s id: gxy-xkw48 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:46:38,209 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [166] queued (96.402 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:38,211 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (166) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:38,218 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:38,219 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (167) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:38,222 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (167) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:38,230 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (167) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:38,300 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (167) Working directory for job is: /galaxy/server/database/jobs_directory/000/167
galaxy.jobs.runners DEBUG 2024-11-24 06:46:38,306 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [167] queued (83.667 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:38,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (167) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:38,313 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:38,314 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (168) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:38,317 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (168) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:38,324 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (168) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:38,335 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (168) Working directory for job is: /galaxy/server/database/jobs_directory/000/168
galaxy.jobs.runners DEBUG 2024-11-24 06:46:38,341 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [168] queued (24.248 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:38,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (168) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:38,408 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:38,408 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (169) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:38,411 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (169) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:38,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (169) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:38,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (169) Working directory for job is: /galaxy/server/database/jobs_directory/000/169
galaxy.jobs.runners DEBUG 2024-11-24 06:46:38,436 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [169] queued (24.602 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:38,438 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (169) Job dispatched
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,440 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 171, 175, 174, 172, 170, 173
tpv.core.entities DEBUG 2024-11-24 06:46:39,510 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:39,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (170) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,514 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (170) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:39,523 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (170) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:39,534 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (170) Working directory for job is: /galaxy/server/database/jobs_directory/000/170
galaxy.jobs.runners DEBUG 2024-11-24 06:46:39,541 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [170] queued (26.663 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:39,601 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (170) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:39,609 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:39,609 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (171) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (171) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:39,621 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (171) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:39,633 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (171) Working directory for job is: /galaxy/server/database/jobs_directory/000/171
galaxy.jobs.runners DEBUG 2024-11-24 06:46:39,638 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [171] queued (25.663 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:39,640 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (171) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:39,705 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:39,706 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (172) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,709 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (172) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:39,718 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (172) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:39,728 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (172) Working directory for job is: /galaxy/server/database/jobs_directory/000/172
galaxy.jobs.runners DEBUG 2024-11-24 06:46:39,735 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [172] queued (26.174 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:39,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (172) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:39,802 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:39,802 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,807 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:39,818 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:39,829 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Working directory for job is: /galaxy/server/database/jobs_directory/000/173
galaxy.jobs.runners DEBUG 2024-11-24 06:46:39,835 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [173] queued (28.270 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:39,837 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (173) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:39,905 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:39,906 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:39,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:39,918 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:39,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Working directory for job is: /galaxy/server/database/jobs_directory/000/174
galaxy.jobs.runners DEBUG 2024-11-24 06:46:39,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [174] queued (26.545 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:39,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (174) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:46:40,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:46:40,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:46:40,011 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:46:40,021 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:46:40,032 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Working directory for job is: /galaxy/server/database/jobs_directory/000/175
galaxy.jobs.runners DEBUG 2024-11-24 06:46:40,040 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [175] queued (28.204 ms)
galaxy.jobs.handler INFO 2024-11-24 06:46:40,100 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (175) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:46:49,401 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 153 finished
galaxy.model.metadata DEBUG 2024-11-24 06:46:49,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 220
galaxy.jobs.runners DEBUG 2024-11-24 06:46:49,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 152 finished
galaxy.jobs INFO 2024-11-24 06:46:49,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 153 in /galaxy/server/database/jobs_directory/000/153
galaxy.model.metadata DEBUG 2024-11-24 06:46:49,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 219
galaxy.jobs INFO 2024-11-24 06:46:49,560 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 152 in /galaxy/server/database/jobs_directory/000/152
galaxy.jobs DEBUG 2024-11-24 06:46:49,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 153 executed (182.532 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:49,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 153 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:46:49,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 152 executed (125.913 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:49,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 152 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:49,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 162
galaxy.jobs.runners DEBUG 2024-11-24 06:46:49,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 157: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:46:49,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [162] prepared (112.822 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:49,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/162/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/162/registry.xml' '/galaxy/server/database/jobs_directory/000/162/upload_params.json' '229:/galaxy/server/database/objects/9/e/e/dataset_9ee4b629-bec9-46fb-9793-1c3ca501905b_files:/galaxy/server/database/objects/9/e/e/dataset_9ee4b629-bec9-46fb-9793-1c3ca501905b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:49,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (162) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/162/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/162/galaxy_162.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 162 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 162 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 163
galaxy.jobs DEBUG 2024-11-24 06:46:50,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [163] prepared (112.732 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:50,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/163/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/163/registry.xml' '/galaxy/server/database/jobs_directory/000/163/upload_params.json' '230:/galaxy/server/database/objects/b/9/3/dataset_b939239f-4291-4ab3-874a-625cd5f7cc51_files:/galaxy/server/database/objects/b/9/3/dataset_b939239f-4291-4ab3-874a-625cd5f7cc51.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:46:50,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (163) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/163/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/163/galaxy_163.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 163 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,316 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 163 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 164
galaxy.jobs DEBUG 2024-11-24 06:46:50,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [164] prepared (158.614 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:50,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/164/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/164/registry.xml' '/galaxy/server/database/jobs_directory/000/164/upload_params.json' '231:/galaxy/server/database/objects/6/c/e/dataset_6ce20ac8-b99f-46c6-8022-970aaa58472f_files:/galaxy/server/database/objects/6/c/e/dataset_6ce20ac8-b99f-46c6-8022-970aaa58472f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:50,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (164) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/164/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/164/galaxy_164.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 164 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:50,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 164 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:46:50,817 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 156: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:51,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:51,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:46:51,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 155 finished
galaxy.model.metadata DEBUG 2024-11-24 06:46:51,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 222
galaxy.jobs INFO 2024-11-24 06:46:51,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 155 in /galaxy/server/database/jobs_directory/000/155
galaxy.jobs.runners DEBUG 2024-11-24 06:46:51,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 154 finished
galaxy.jobs DEBUG 2024-11-24 06:46:51,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 155 executed (214.621 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:51,758 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 155 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:46:51,761 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 221
galaxy.jobs INFO 2024-11-24 06:46:51,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 154 in /galaxy/server/database/jobs_directory/000/154
galaxy.jobs DEBUG 2024-11-24 06:46:51,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 154 executed (184.414 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:46:51,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 158: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:52,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 154 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:52,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 165
galaxy.jobs DEBUG 2024-11-24 06:46:52,436 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [165] prepared (208.182 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:46:52,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/165/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/165/registry.xml' '/galaxy/server/database/jobs_directory/000/165/upload_params.json' '232:/galaxy/server/database/objects/a/1/5/dataset_a1573b99-b063-404f-ba08-a072c69a421e_files:/galaxy/server/database/objects/a/1/5/dataset_a1573b99-b063-404f-ba08-a072c69a421e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:46:52,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (165) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/165/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/165/galaxy_165.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:52,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 165 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:52,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 165 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:46:53,001 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 160: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:53,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:46:59,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tkl6c with k8s id: gxy-tkl6c succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:00,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2nqgt with k8s id: gxy-2nqgt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:00,408 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vt75m with k8s id: gxy-vt75m succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:02,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hr5sz with k8s id: gxy-hr5sz succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:47:05,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 157 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:05,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 224
galaxy.jobs INFO 2024-11-24 06:47:05,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 157 in /galaxy/server/database/jobs_directory/000/157
galaxy.jobs DEBUG 2024-11-24 06:47:05,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 157 executed (142.794 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:05,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 157 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:05,841 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 161: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:06,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 156 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:06,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 223
galaxy.jobs INFO 2024-11-24 06:47:06,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 156 in /galaxy/server/database/jobs_directory/000/156
galaxy.jobs DEBUG 2024-11-24 06:47:06,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 156 executed (137.869 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:06,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 156 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:06,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 166
galaxy.jobs DEBUG 2024-11-24 06:47:06,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [166] prepared (118.850 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:06,751 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/166/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/166/registry.xml' '/galaxy/server/database/jobs_directory/000/166/upload_params.json' '233:/galaxy/server/database/objects/a/2/a/dataset_a2a25f03-6fb2-449a-a45a-1ec13b6c35aa_files:/galaxy/server/database/objects/a/2/a/dataset_a2a25f03-6fb2-449a-a45a-1ec13b6c35aa.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:06,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (166) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/166/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/166/galaxy_166.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:06,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 166 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:06,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 166 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:06,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 167
galaxy.jobs DEBUG 2024-11-24 06:47:07,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [167] prepared (117.462 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:07,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/167/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/167/registry.xml' '/galaxy/server/database/jobs_directory/000/167/upload_params.json' '234:/galaxy/server/database/objects/4/a/3/dataset_4a339f9b-5025-4ff8-bef9-0ad9be89f727_files:/galaxy/server/database/objects/4/a/3/dataset_4a339f9b-5025-4ff8-bef9-0ad9be89f727.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:07,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (167) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/167/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/167/galaxy_167.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 167 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 167 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 168
galaxy.jobs DEBUG 2024-11-24 06:47:07,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [168] prepared (127.430 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:07,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/168/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/168/registry.xml' '/galaxy/server/database/jobs_directory/000/168/upload_params.json' '235:/galaxy/server/database/objects/1/4/e/dataset_14e86bf1-54f6-421c-96bb-598476331abf_files:/galaxy/server/database/objects/1/4/e/dataset_14e86bf1-54f6-421c-96bb-598476331abf.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:07,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (168) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/168/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/168/galaxy_168.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,415 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 168 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 168 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:07,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 158 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,508 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 169
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.model.metadata DEBUG 2024-11-24 06:47:07,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 225
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs INFO 2024-11-24 06:47:07,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 158 in /galaxy/server/database/jobs_directory/000/158
galaxy.jobs DEBUG 2024-11-24 06:47:07,710 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [169] prepared (190.361 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:07,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/169/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/169/registry.xml' '/galaxy/server/database/jobs_directory/000/169/upload_params.json' '236:/galaxy/server/database/objects/2/e/a/dataset_2ea8e81a-d70b-44c6-b556-30787316e1a9_files:/galaxy/server/database/objects/2/e/a/dataset_2ea8e81a-d70b-44c6-b556-30787316e1a9.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:47:07,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (169) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/169/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/169/galaxy_169.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 169 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 169 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:07,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 158 executed (296.594 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 158 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 170
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:07,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 171
galaxy.jobs DEBUG 2024-11-24 06:47:07,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [170] prepared (104.858 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/170/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/170/registry.xml' '/galaxy/server/database/jobs_directory/000/170/upload_params.json' '237:/galaxy/server/database/objects/5/d/6/dataset_5d69ad5a-d85c-4c96-964c-868a812e2b5e_files:/galaxy/server/database/objects/5/d/6/dataset_5d69ad5a-d85c-4c96-964c-868a812e2b5e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (170) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/170/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/170/galaxy_170.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,051 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 170 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:08,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [171] prepared (119.541 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 170 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/171/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/171/registry.xml' '/galaxy/server/database/jobs_directory/000/171/upload_params.json' '238:/galaxy/server/database/objects/1/c/2/dataset_1c2f1cc4-a617-4897-b2a8-b6530e2467ab_files:/galaxy/server/database/objects/1/c/2/dataset_1c2f1cc4-a617-4897-b2a8-b6530e2467ab.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (171) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/171/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/171/galaxy_171.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 171 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 172
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 171 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 160 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 173
galaxy.model.metadata DEBUG 2024-11-24 06:47:08,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 227
galaxy.jobs DEBUG 2024-11-24 06:47:08,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [172] prepared (124.827 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/172/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/172/registry.xml' '/galaxy/server/database/jobs_directory/000/172/upload_params.json' '239:/galaxy/server/database/objects/8/8/4/dataset_884071a2-eadf-4f7e-8db6-1c50ed63ef5c_files:/galaxy/server/database/objects/8/8/4/dataset_884071a2-eadf-4f7e-8db6-1c50ed63ef5c.dat']
galaxy.jobs INFO 2024-11-24 06:47:08,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 160 in /galaxy/server/database/jobs_directory/000/160
galaxy.jobs DEBUG 2024-11-24 06:47:08,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [173] prepared (106.148 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (172) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/172/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/172/galaxy_172.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,351 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 172 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/173/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/173/registry.xml' '/galaxy/server/database/jobs_directory/000/173/upload_params.json' '240:/galaxy/server/database/objects/1/4/8/dataset_14852fef-1bef-4564-91b1-b81c0c25fd4a_files:/galaxy/server/database/objects/1/4/8/dataset_14852fef-1bef-4564-91b1-b81c0c25fd4a.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (173) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/173/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/173/galaxy_173.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 172 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:08,408 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 160 executed (181.635 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 174
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 160 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 175
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159/gxy-62gg5) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159/gxy-62gg5) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159/gxy-62gg5) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159/gxy-62gg5) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-62gg5.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 159 (gxy-62gg5)
galaxy.jobs DEBUG 2024-11-24 06:47:08,747 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [174] prepared (239.366 ms)
galaxy.jobs DEBUG 2024-11-24 06:47:08,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [175] prepared (146.396 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,767 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Found job with id gxy-62gg5 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 159 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/174/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/174/registry.xml' '/galaxy/server/database/jobs_directory/000/174/upload_params.json' '241:/galaxy/server/database/objects/7/0/3/dataset_70396777-08f5-43d3-baca-f85f4eed8261_files:/galaxy/server/database/objects/7/0/3/dataset_70396777-08f5-43d3-baca-f85f4eed8261.dat']
galaxy.jobs.command_factory INFO 2024-11-24 06:47:08,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/175/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/175/registry.xml' '/galaxy/server/database/jobs_directory/000/175/upload_params.json' '242:/galaxy/server/database/objects/2/8/f/dataset_28f66151-6a96-478f-8fb8-49db62c19db1_files:/galaxy/server/database/objects/2/8/f/dataset_28f66151-6a96-478f-8fb8-49db62c19db1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (174) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/174/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/174/galaxy_174.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-24 06:47:08,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (175) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/175/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/175/galaxy_175.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,834 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,854 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,860 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (159/gxy-62gg5) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:08,899 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:09,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:09,092 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:47:09,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 162: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:09,187 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:47:09,191 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 163: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:09,210 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 164: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:09,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:10,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:10,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:17,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kws5r failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:17,239 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:17,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-kws5r.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:17,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 166 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:47:17,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-kws5r

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-kws5r": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:17,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-m4cck with k8s id: gxy-m4cck succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:18,633 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rnpjd with k8s id: gxy-rnpjd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:18,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zpxw7 with k8s id: gxy-zpxw7 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:18,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qk4lt with k8s id: gxy-qk4lt succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:19,812 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hlrnk with k8s id: gxy-hlrnk succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:19,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5b88g with k8s id: gxy-5b88g succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:19,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b5vcq with k8s id: gxy-b5vcq succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:20,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hh2xs with k8s id: gxy-hh2xs succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:20,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-k9lft with k8s id: gxy-k9lft succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:47:21,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 161 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:21,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 228
galaxy.jobs INFO 2024-11-24 06:47:21,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 161 in /galaxy/server/database/jobs_directory/000/161
galaxy.jobs DEBUG 2024-11-24 06:47:22,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 161 executed (188.969 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:22,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 161 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:22,506 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 165: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:25,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 162 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:25,946 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 229
galaxy.jobs INFO 2024-11-24 06:47:26,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 162 in /galaxy/server/database/jobs_directory/000/162
galaxy.jobs DEBUG 2024-11-24 06:47:26,113 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 162 executed (183.718 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:26,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 162 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:26,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 163 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:26,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 230
galaxy.jobs INFO 2024-11-24 06:47:26,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 163 in /galaxy/server/database/jobs_directory/000/163
galaxy.jobs.runners DEBUG 2024-11-24 06:47:26,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 167: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:47:26,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 163 executed (145.590 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:47:26,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 164 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:26,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 163 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:47:26,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 231
galaxy.jobs INFO 2024-11-24 06:47:26,507 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 164 in /galaxy/server/database/jobs_directory/000/164
galaxy.jobs DEBUG 2024-11-24 06:47:26,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 164 executed (136.824 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:26,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 164 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:26,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 168: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:26,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 169: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:37,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 165 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:37,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 232
galaxy.jobs INFO 2024-11-24 06:47:37,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 165 in /galaxy/server/database/jobs_directory/000/165
galaxy.jobs DEBUG 2024-11-24 06:47:37,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 165 executed (134.391 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:37,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 165 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:37,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 170: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:40,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 167 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:40,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 234
galaxy.jobs INFO 2024-11-24 06:47:40,809 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 167 in /galaxy/server/database/jobs_directory/000/167
galaxy.jobs DEBUG 2024-11-24 06:47:41,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 167 executed (376.502 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:41,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 167 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:41,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 171: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:41,313 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 168 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:41,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 235
galaxy.jobs.runners DEBUG 2024-11-24 06:47:41,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 169 finished
galaxy.jobs INFO 2024-11-24 06:47:41,437 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 168 in /galaxy/server/database/jobs_directory/000/168
galaxy.model.metadata DEBUG 2024-11-24 06:47:41,508 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 236
galaxy.jobs DEBUG 2024-11-24 06:47:41,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 168 executed (198.641 ms)
galaxy.jobs INFO 2024-11-24 06:47:41,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 169 in /galaxy/server/database/jobs_directory/000/169
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:41,553 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 168 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:41,619 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 169 executed (169.150 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:41,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 169 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:41,801 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 173: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:41,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 174: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:52,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 170 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:52,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 237
galaxy.jobs INFO 2024-11-24 06:47:52,706 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 170 in /galaxy/server/database/jobs_directory/000/170
galaxy.jobs DEBUG 2024-11-24 06:47:52,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 170 executed (296.839 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:52,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 170 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:53,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 172: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:56,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 171 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:56,118 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 238
galaxy.jobs INFO 2024-11-24 06:47:56,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 171 in /galaxy/server/database/jobs_directory/000/171
galaxy.jobs DEBUG 2024-11-24 06:47:56,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 171 executed (375.452 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:56,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 171 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:47:56,700 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 175: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:47:56,744 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 173 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:47:56,804 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 174 finished
galaxy.model.metadata DEBUG 2024-11-24 06:47:56,849 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 240
galaxy.model.metadata DEBUG 2024-11-24 06:47:56,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 241
galaxy.jobs INFO 2024-11-24 06:47:56,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 173 in /galaxy/server/database/jobs_directory/000/173
galaxy.jobs INFO 2024-11-24 06:47:56,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 174 in /galaxy/server/database/jobs_directory/000/174
galaxy.jobs DEBUG 2024-11-24 06:47:56,972 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 173 executed (152.608 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 173 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:57,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 174 executed (185.394 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 174 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (166/gxy-kws5r) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (166/gxy-kws5r) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (166/gxy-kws5r) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (166/gxy-kws5r) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-kws5r.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 166 (gxy-kws5r)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Found job with id gxy-kws5r to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 166 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:57,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (166/gxy-kws5r) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 06:47:58,340 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 178, 177, 176
tpv.core.entities DEBUG 2024-11-24 06:47:58,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:58,363 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:58,366 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:58,374 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:47:58,385 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Working directory for job is: /galaxy/server/database/jobs_directory/000/176
galaxy.jobs.runners DEBUG 2024-11-24 06:47:58,404 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [176] queued (38.637 ms)
galaxy.jobs.handler INFO 2024-11-24 06:47:58,406 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (176) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 176
tpv.core.entities DEBUG 2024-11-24 06:47:58,414 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:58,415 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:58,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:58,429 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:47:58,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Working directory for job is: /galaxy/server/database/jobs_directory/000/177
galaxy.jobs.runners DEBUG 2024-11-24 06:47:58,615 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [177] queued (196.366 ms)
galaxy.jobs.handler INFO 2024-11-24 06:47:58,618 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (177) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,623 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 177
tpv.core.entities DEBUG 2024-11-24 06:47:58,634 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:58,634 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:58,639 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:58,699 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:47:58,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [176] prepared (295.017 ms)
galaxy.jobs DEBUG 2024-11-24 06:47:58,734 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Working directory for job is: /galaxy/server/database/jobs_directory/000/178
galaxy.jobs.command_factory INFO 2024-11-24 06:47:58,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/176/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/176/registry.xml' '/galaxy/server/database/jobs_directory/000/176/upload_params.json' '243:/galaxy/server/database/objects/5/0/f/dataset_50fc88fc-5c6f-4360-9f50-6cec86de33f0_files:/galaxy/server/database/objects/5/0/f/dataset_50fc88fc-5c6f-4360-9f50-6cec86de33f0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:58,743 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [178] queued (103.924 ms)
galaxy.jobs.handler INFO 2024-11-24 06:47:58,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (178) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:47:58,754 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (176) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/176/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/176/galaxy_176.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:47:58,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [177] prepared (177.376 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:47:58,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/177/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/177/registry.xml' '/galaxy/server/database/jobs_directory/000/177/upload_params.json' '244:/galaxy/server/database/objects/4/2/8/dataset_4285bb18-aca7-4275-8605-3b9738fc43a6_files:/galaxy/server/database/objects/4/2/8/dataset_4285bb18-aca7-4275-8605-3b9738fc43a6.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:58,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (177) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/177/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/177/galaxy_177.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:58,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 178
galaxy.jobs DEBUG 2024-11-24 06:47:59,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [178] prepared (86.598 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:47:59,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/178/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/178/registry.xml' '/galaxy/server/database/jobs_directory/000/178/upload_params.json' '245:/galaxy/server/database/objects/e/0/2/dataset_e02ef297-78e8-44b6-ae3c-166cb5401f0f_files:/galaxy/server/database/objects/e/0/2/dataset_e02ef297-78e8-44b6-ae3c-166cb5401f0f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:47:59,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (178) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/178/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/178/galaxy_178.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:47:59,751 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 181, 180, 179, 182
tpv.core.entities DEBUG 2024-11-24 06:47:59,776 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:59,776 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:59,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:59,805 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:47:59,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Working directory for job is: /galaxy/server/database/jobs_directory/000/179
galaxy.jobs.runners DEBUG 2024-11-24 06:47:59,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [179] queued (46.283 ms)
galaxy.jobs.handler INFO 2024-11-24 06:47:59,831 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (179) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 179
tpv.core.entities DEBUG 2024-11-24 06:47:59,842 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:59,842 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:59,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:59,860 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:47:59,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Working directory for job is: /galaxy/server/database/jobs_directory/000/180
galaxy.jobs.runners DEBUG 2024-11-24 06:47:59,921 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [180] queued (73.944 ms)
galaxy.jobs.handler INFO 2024-11-24 06:47:59,924 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (180) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:47:59,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 180
tpv.core.entities DEBUG 2024-11-24 06:47:59,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:47:59,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:47:59,945 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:47:59,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:00,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [179] prepared (184.801 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:00,033 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Working directory for job is: /galaxy/server/database/jobs_directory/000/181
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,042 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [181] queued (96.655 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:00,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (181) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:48:00,060 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:00,061 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Mapped job to destination id: k8s
galaxy.jobs.command_factory INFO 2024-11-24 06:48:00,101 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/179/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/179/registry.xml' '/galaxy/server/database/jobs_directory/000/179/upload_params.json' '246:/galaxy/server/database/objects/6/4/6/dataset_6462eb6d-41e9-43c8-9654-3b69100c0cd5_files:/galaxy/server/database/objects/6/4/6/dataset_6462eb6d-41e9-43c8-9654-3b69100c0cd5.dat']
galaxy.jobs.handler DEBUG 2024-11-24 06:48:00,104 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,111 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (179) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/179/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/179/galaxy_179.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:00,117 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:00,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [180] prepared (185.624 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:00,145 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Working directory for job is: /galaxy/server/database/jobs_directory/000/182
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,153 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [182] queued (48.649 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:00,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/180/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/180/registry.xml' '/galaxy/server/database/jobs_directory/000/180/upload_params.json' '247:/galaxy/server/database/objects/7/1/e/dataset_71e4613b-c754-4a8c-b931-0ce580407439_files:/galaxy/server/database/objects/7/1/e/dataset_71e4613b-c754-4a8c-b931-0ce580407439.dat']
galaxy.jobs.handler INFO 2024-11-24 06:48:00,156 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (182) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,163 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (180) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/180/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/180/galaxy_180.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 181
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 182
galaxy.jobs DEBUG 2024-11-24 06:48:00,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [181] prepared (116.862 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,347 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:48:00,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/181/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/181/registry.xml' '/galaxy/server/database/jobs_directory/000/181/upload_params.json' '248:/galaxy/server/database/objects/a/a/6/dataset_aa6b7189-0df0-4f88-889d-aee4540408d8_files:/galaxy/server/database/objects/a/a/6/dataset_aa6b7189-0df0-4f88-889d-aee4540408d8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (181) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/181/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/181/galaxy_181.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,436 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:48:00,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [182] prepared (160.663 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:00,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/182/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/182/registry.xml' '/galaxy/server/database/jobs_directory/000/182/upload_params.json' '249:/galaxy/server/database/objects/4/7/0/dataset_470d6695-8f68-425d-a75b-5551fca5adfa_files:/galaxy/server/database/objects/4/7/0/dataset_470d6695-8f68-425d-a75b-5551fca5adfa.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:00,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (182) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/182/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/182/galaxy_182.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,564 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:00,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:48:01,159 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 184, 183, 186, 185
tpv.core.entities DEBUG 2024-11-24 06:48:01,184 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:01,185 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:01,188 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:01,208 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:01,222 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Working directory for job is: /galaxy/server/database/jobs_directory/000/183
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,229 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [183] queued (40.711 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:01,231 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (183) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 183
tpv.core.entities DEBUG 2024-11-24 06:48:01,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:01,247 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:01,252 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:01,266 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:01,324 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Working directory for job is: /galaxy/server/database/jobs_directory/000/184
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,332 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [184] queued (79.496 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:01,334 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (184) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 184
tpv.core.entities DEBUG 2024-11-24 06:48:01,345 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:01,346 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:01,351 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:01,406 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:01,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [183] prepared (163.975 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:01,430 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Working directory for job is: /galaxy/server/database/jobs_directory/000/185
galaxy.jobs.command_factory INFO 2024-11-24 06:48:01,438 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/183/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/183/registry.xml' '/galaxy/server/database/jobs_directory/000/183/upload_params.json' '250:/galaxy/server/database/objects/b/2/f/dataset_b2f4ed49-1a20-43ca-8c59-539d1409cefe_files:/galaxy/server/database/objects/b/2/f/dataset_b2f4ed49-1a20-43ca-8c59-539d1409cefe.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,439 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [185] queued (87.833 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:01,442 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (185) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (183) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/183/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/183/galaxy_183.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:48:01,460 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:01,460 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:01,500 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:01,518 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:01,540 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [184] prepared (187.735 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:01,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Working directory for job is: /galaxy/server/database/jobs_directory/000/186
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,564 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [186] queued (63.836 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:01,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/184/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/184/registry.xml' '/galaxy/server/database/jobs_directory/000/184/upload_params.json' '251:/galaxy/server/database/objects/c/f/2/dataset_cf22241b-aabf-4689-a00d-6db2684beedf_files:/galaxy/server/database/objects/c/f/2/dataset_cf22241b-aabf-4689-a00d-6db2684beedf.dat']
galaxy.jobs.handler INFO 2024-11-24 06:48:01,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (186) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 185
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,626 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (184) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/184/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/184/galaxy_184.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,806 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 186
galaxy.jobs DEBUG 2024-11-24 06:48:01,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [185] prepared (194.658 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:01,854 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/185/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/185/registry.xml' '/galaxy/server/database/jobs_directory/000/185/upload_params.json' '252:/galaxy/server/database/objects/2/b/0/dataset_2b0b1334-41d0-483e-bb87-fa8b8dcf8b51_files:/galaxy/server/database/objects/2/b/0/dataset_2b0b1334-41d0-483e-bb87-fa8b8dcf8b51.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,858 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:48:01,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (185) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/185/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/185/galaxy_185.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:01,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:01,958 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [186] prepared (140.947 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:02,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:48:02,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/186/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/186/registry.xml' '/galaxy/server/database/jobs_directory/000/186/upload_params.json' '253:/galaxy/server/database/objects/5/a/a/dataset_5aa38c55-467b-4eab-b98c-d4ca471a3434_files:/galaxy/server/database/objects/5/a/a/dataset_5aa38c55-467b-4eab-b98c-d4ca471a3434.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:02,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (186) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/186/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/186/galaxy_186.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:02,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:02,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:48:02,611 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 190, 192, 191, 188, 189, 187
tpv.core.entities DEBUG 2024-11-24 06:48:02,640 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:02,641 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:02,644 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:02,711 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:02,727 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Working directory for job is: /galaxy/server/database/jobs_directory/000/187
galaxy.jobs.runners DEBUG 2024-11-24 06:48:02,735 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [187] queued (90.210 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:02,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (187) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:02,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 187
tpv.core.entities DEBUG 2024-11-24 06:48:02,800 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:02,801 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:02,805 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:02,824 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:02,853 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Working directory for job is: /galaxy/server/database/jobs_directory/000/188
galaxy.jobs.runners DEBUG 2024-11-24 06:48:02,862 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [188] queued (57.009 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:02,865 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (188) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:02,869 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 188
tpv.core.entities DEBUG 2024-11-24 06:48:02,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:02,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:02,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:02,935 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:02,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [187] prepared (187.174 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:03,001 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Working directory for job is: /galaxy/server/database/jobs_directory/000/189
galaxy.jobs.command_factory INFO 2024-11-24 06:48:03,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/187/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/187/registry.xml' '/galaxy/server/database/jobs_directory/000/187/upload_params.json' '254:/galaxy/server/database/objects/9/1/b/dataset_91b43f98-3cdf-4a15-953a-758b1331dfaf_files:/galaxy/server/database/objects/9/1/b/dataset_91b43f98-3cdf-4a15-953a-758b1331dfaf.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,013 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [189] queued (93.429 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:03,015 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (189) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,021 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (187) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/187/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/187/galaxy_187.ec; sh -c "exit $return_code"
tpv.core.entities DEBUG 2024-11-24 06:48:03,036 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:03,036 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:03,042 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,047 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:03,111 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:03,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [188] prepared (213.071 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:03,141 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Working directory for job is: /galaxy/server/database/jobs_directory/000/190
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,148 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [190] queued (106.047 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:03,152 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (190) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 06:48:03,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/188/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/188/registry.xml' '/galaxy/server/database/jobs_directory/000/188/upload_params.json' '255:/galaxy/server/database/objects/a/c/4/dataset_ac463183-076a-4448-9d30-30f97fc4ed59_files:/galaxy/server/database/objects/a/c/4/dataset_ac463183-076a-4448-9d30-30f97fc4ed59.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 189
tpv.core.entities DEBUG 2024-11-24 06:48:03,204 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:03,204 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:03,217 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (188) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/188/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/188/galaxy_188.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:03,237 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:03,341 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Working directory for job is: /galaxy/server/database/jobs_directory/000/191
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,358 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [191] queued (140.465 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:03,367 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (191) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
tpv.core.entities DEBUG 2024-11-24 06:48:03,426 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:03,426 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:03,431 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:03,453 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:03,462 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [189] prepared (231.268 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 190
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:48:03,520 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Working directory for job is: /galaxy/server/database/jobs_directory/000/192
galaxy.jobs.command_factory INFO 2024-11-24 06:48:03,524 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/189/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/189/registry.xml' '/galaxy/server/database/jobs_directory/000/189/upload_params.json' '256:/galaxy/server/database/objects/d/8/b/dataset_d8b2b941-83e0-47b2-a7cc-8f3d7728eb8b_files:/galaxy/server/database/objects/d/8/b/dataset_d8b2b941-83e0-47b2-a7cc-8f3d7728eb8b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,536 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [192] queued (105.056 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:03,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (192) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,541 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (189) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/189/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/189/galaxy_189.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:48:03,733 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [190] prepared (214.645 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 191
galaxy.jobs.command_factory INFO 2024-11-24 06:48:03,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/190/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/190/registry.xml' '/galaxy/server/database/jobs_directory/000/190/upload_params.json' '257:/galaxy/server/database/objects/0/0/b/dataset_00bd6352-60da-4481-9d65-9bf23c7e06f2_files:/galaxy/server/database/objects/0/0/b/dataset_00bd6352-60da-4481-9d65-9bf23c7e06f2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,807 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (190) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/190/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/190/galaxy_190.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,835 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,850 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:03,865 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [191] prepared (115.110 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,910 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 192
galaxy.jobs.command_factory INFO 2024-11-24 06:48:03,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/191/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/191/registry.xml' '/galaxy/server/database/jobs_directory/000/191/upload_params.json' '258:/galaxy/server/database/objects/a/9/8/dataset_a98fa846-c3f0-4237-b8ea-1f4e7153a689_files:/galaxy/server/database/objects/a/9/8/dataset_a98fa846-c3f0-4237-b8ea-1f4e7153a689.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:03,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (191) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/191/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/191/galaxy_191.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:03,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:04,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [192] prepared (143.301 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:04,112 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/192/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/192/registry.xml' '/galaxy/server/database/jobs_directory/000/192/upload_params.json' '259:/galaxy/server/database/objects/5/d/1/dataset_5d14d24f-26ce-41c7-a866-1b6e713a3e24_files:/galaxy/server/database/objects/5/d/1/dataset_5d14d24f-26ce-41c7-a866-1b6e713a3e24.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,125 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (192) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/192/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/192/galaxy_192.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,138 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 172 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:04,289 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 239
galaxy.jobs INFO 2024-11-24 06:48:04,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 172 in /galaxy/server/database/jobs_directory/000/172
galaxy.jobs DEBUG 2024-11-24 06:48:04,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 172 executed (110.209 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,396 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 172 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:48:04,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 197, 199, 193, 198, 196, 195, 194
tpv.core.entities DEBUG 2024-11-24 06:48:04,579 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:04,580 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:04,584 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:04,595 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:04,616 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Working directory for job is: /galaxy/server/database/jobs_directory/000/193
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,624 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [193] queued (39.254 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,626 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 193
galaxy.jobs.handler INFO 2024-11-24 06:48:04,627 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (193) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:48:04,644 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:04,644 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:04,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:04,667 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:04,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Working directory for job is: /galaxy/server/database/jobs_directory/000/194
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,694 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [194] queued (46.649 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:04,697 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (194) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,698 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 194
tpv.core.entities DEBUG 2024-11-24 06:48:04,712 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:04,714 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:04,721 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:04,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [193] prepared (99.080 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:04,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:04,789 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Working directory for job is: /galaxy/server/database/jobs_directory/000/195
galaxy.jobs.command_factory INFO 2024-11-24 06:48:04,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/193/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/193/registry.xml' '/galaxy/server/database/jobs_directory/000/193/upload_params.json' '260:/galaxy/server/database/objects/5/5/8/dataset_558717eb-3fd1-472a-951a-69f30065e4bf_files:/galaxy/server/database/objects/5/5/8/dataset_558717eb-3fd1-472a-951a-69f30065e4bf.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,807 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [195] queued (86.530 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:04,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (195) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 195
tpv.core.entities DEBUG 2024-11-24 06:48:04,839 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:04,843 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Mapped job to destination id: k8s
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (193) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/193/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/193/galaxy_193.ec; sh -c "exit $return_code"
galaxy.jobs.handler DEBUG 2024-11-24 06:48:04,851 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:04,873 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:04,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [194] prepared (181.298 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:04,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:48:04,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/194/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/194/registry.xml' '/galaxy/server/database/jobs_directory/000/194/upload_params.json' '261:/galaxy/server/database/objects/f/3/b/dataset_f3b5c1c8-adf5-4760-b94d-3bf2eb66f6ea_files:/galaxy/server/database/objects/f/3/b/dataset_f3b5c1c8-adf5-4760-b94d-3bf2eb66f6ea.dat']
galaxy.jobs DEBUG 2024-11-24 06:48:04,960 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Working directory for job is: /galaxy/server/database/jobs_directory/000/196
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,972 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (194) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/194/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/194/galaxy_194.ec; sh -c "exit $return_code"
galaxy.jobs.runners DEBUG 2024-11-24 06:48:04,977 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [196] queued (124.324 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:04,979 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (196) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
tpv.core.entities DEBUG 2024-11-24 06:48:05,017 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:05,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Mapped job to destination id: k8s
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:48:05,032 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Dispatching to k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:05,071 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 196
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,095 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs DEBUG 2024-11-24 06:48:05,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [195] prepared (264.990 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:05,136 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Working directory for job is: /galaxy/server/database/jobs_directory/000/197
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,144 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [197] queued (111.675 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:05,148 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (197) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 197
galaxy.jobs.command_factory INFO 2024-11-24 06:48:05,167 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/195/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/195/registry.xml' '/galaxy/server/database/jobs_directory/000/195/upload_params.json' '262:/galaxy/server/database/objects/b/f/7/dataset_bf71c584-4e24-493c-813f-4ee29e006dbf_files:/galaxy/server/database/objects/b/f/7/dataset_bf71c584-4e24-493c-813f-4ee29e006dbf.dat']
tpv.core.entities DEBUG 2024-11-24 06:48:05,185 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:05,186 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:05,197 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (195) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/195/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/195/galaxy_195.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:05,226 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 195 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,262 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 195 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:05,303 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Working directory for job is: /galaxy/server/database/jobs_directory/000/198
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,315 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [198] queued (115.127 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:05,318 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (198) Job dispatched
galaxy.jobs DEBUG 2024-11-24 06:48:05,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [196] prepared (209.887 ms)
tpv.core.entities DEBUG 2024-11-24 06:48:05,344 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:05,344 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:05,349 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:05,361 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.command_factory INFO 2024-11-24 06:48:05,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/196/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/196/registry.xml' '/galaxy/server/database/jobs_directory/000/196/upload_params.json' '263:/galaxy/server/database/objects/0/a/2/dataset_0a2c9f03-7122-4ea1-9957-96b1772dda2b_files:/galaxy/server/database/objects/0/a/2/dataset_0a2c9f03-7122-4ea1-9957-96b1772dda2b.dat']
galaxy.jobs DEBUG 2024-11-24 06:48:05,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [197] prepared (216.906 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (196) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/196/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/196/galaxy_196.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:05,420 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Working directory for job is: /galaxy/server/database/jobs_directory/000/199
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 196 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:48:05,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/197/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/197/registry.xml' '/galaxy/server/database/jobs_directory/000/197/upload_params.json' '264:/galaxy/server/database/objects/e/a/3/dataset_ea32be99-9d55-4c1e-a837-4c7346513815_files:/galaxy/server/database/objects/e/a/3/dataset_ea32be99-9d55-4c1e-a837-4c7346513815.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,432 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [199] queued (83.235 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:05,441 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (199) Job dispatched
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (197) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/197/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/197/galaxy_197.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,457 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 196 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 198
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 197 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 197 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,505 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 199
galaxy.jobs DEBUG 2024-11-24 06:48:05,577 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [198] prepared (106.036 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:05,597 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/198/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/198/registry.xml' '/galaxy/server/database/jobs_directory/000/198/upload_params.json' '265:/galaxy/server/database/objects/5/c/b/dataset_5cb50d6a-226d-4440-a965-37e246bba12d_files:/galaxy/server/database/objects/5/c/b/dataset_5cb50d6a-226d-4440-a965-37e246bba12d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,618 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (198) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/198/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/198/galaxy_198.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,637 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sqjcj with k8s id: gxy-sqjcj  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sc2p6 with k8s id: gxy-sc2p6  pending...
galaxy.jobs DEBUG 2024-11-24 06:48:05,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [199] prepared (121.364 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:05,731 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/199/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/199/registry.xml' '/galaxy/server/database/jobs_directory/000/199/upload_params.json' '266:/galaxy/server/database/objects/b/3/5/dataset_b35100b9-7a6c-4570-91fe-e5d26a461c28_files:/galaxy/server/database/objects/b/3/5/dataset_b35100b9-7a6c-4570-91fe-e5d26a461c28.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:05,742 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (199) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/199/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/199/galaxy_199.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:05,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,451 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 202, 205, 204, 203, 201, 200
tpv.core.entities DEBUG 2024-11-24 06:48:06,479 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:06,480 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,483 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:06,497 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:06,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Working directory for job is: /galaxy/server/database/jobs_directory/000/200
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,519 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [200] queued (35.820 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 200
galaxy.jobs.handler INFO 2024-11-24 06:48:06,524 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (200) Job dispatched
tpv.core.entities DEBUG 2024-11-24 06:48:06,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:06,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:06,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:06,579 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Working directory for job is: /galaxy/server/database/jobs_directory/000/201
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,586 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [201] queued (44.220 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:06,589 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (201) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,594 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 201
tpv.core.entities DEBUG 2024-11-24 06:48:06,609 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:06,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,617 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:06,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:48:06,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [200] prepared (141.306 ms)
galaxy.jobs DEBUG 2024-11-24 06:48:06,678 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Working directory for job is: /galaxy/server/database/jobs_directory/000/202
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,685 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [202] queued (66.763 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:06,690 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (202) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,691 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 202
tpv.core.entities DEBUG 2024-11-24 06:48:06,717 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:06,718 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Mapped job to destination id: k8s
galaxy.jobs.command_factory INFO 2024-11-24 06:48:06,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/200/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/200/registry.xml' '/galaxy/server/database/jobs_directory/000/200/upload_params.json' '267:/galaxy/server/database/objects/5/e/d/dataset_5edd9ff8-2a77-4795-ad89-5fb4ffa83b6b_files:/galaxy/server/database/objects/5/e/d/dataset_5edd9ff8-2a77-4795-ad89-5fb4ffa83b6b.dat']
galaxy.jobs DEBUG 2024-11-24 06:48:06,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [201] prepared (106.672 ms)
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,730 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (200) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/200/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/200/galaxy_200.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:06,772 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Persisting job destination (destination id: k8s)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:06,794 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/201/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/201/registry.xml' '/galaxy/server/database/jobs_directory/000/201/upload_params.json' '268:/galaxy/server/database/objects/7/f/9/dataset_7f9af3fc-aec0-4f68-9f7b-f20a50783118_files:/galaxy/server/database/objects/7/f/9/dataset_7f9af3fc-aec0-4f68-9f7b-f20a50783118.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (201) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/201/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/201/galaxy_201.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:06,835 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Working directory for job is: /galaxy/server/database/jobs_directory/000/203
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 200 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,843 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [203] queued (112.541 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:06,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (203) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 201 is an interactive tool. guest ports: []. interactive entry points: []
tpv.core.entities DEBUG 2024-11-24 06:48:06,889 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:06,890 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:48:06,911 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Dispatching to k8s runner
galaxy.jobs.runners DEBUG 2024-11-24 06:48:06,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 175 finished
galaxy.jobs DEBUG 2024-11-24 06:48:06,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [202] prepared (225.717 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,952 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 200 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:06,966 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Persisting job destination (destination id: k8s)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:06,997 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/202/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/202/registry.xml' '/galaxy/server/database/jobs_directory/000/202/upload_params.json' '269:/galaxy/server/database/objects/e/3/7/dataset_e371e7d8-48d9-4bef-83a2-c10b104d6442_files:/galaxy/server/database/objects/e/3/7/dataset_e371e7d8-48d9-4bef-83a2-c10b104d6442.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:06,998 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 201 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (202) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/202/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/202/galaxy_202.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:07,028 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Working directory for job is: /galaxy/server/database/jobs_directory/000/204
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,040 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 203
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,041 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [204] queued (130.291 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:07,049 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (204) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:48:07,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 242
tpv.core.entities DEBUG 2024-11-24 06:48:07,080 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:48:07,081 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Mapped job to destination id: k8s
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,084 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 204
galaxy.jobs.handler DEBUG 2024-11-24 06:48:07,092 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:48:07,139 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Persisting job destination (destination id: k8s)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,181 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 06:48:07,224 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 175 in /galaxy/server/database/jobs_directory/000/175
galaxy.jobs DEBUG 2024-11-24 06:48:07,232 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Working directory for job is: /galaxy/server/database/jobs_directory/000/205
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [205] queued (160.125 ms)
galaxy.jobs.handler INFO 2024-11-24 06:48:07,264 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (205) Job dispatched
galaxy.jobs DEBUG 2024-11-24 06:48:07,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [203] prepared (228.328 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,336 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sqjcj with k8s id: gxy-sqjcj  pending...
galaxy.jobs DEBUG 2024-11-24 06:48:07,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [204] prepared (181.093 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 205
galaxy.jobs.command_factory INFO 2024-11-24 06:48:07,370 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/203/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/203/registry.xml' '/galaxy/server/database/jobs_directory/000/203/upload_params.json' '270:/galaxy/server/database/objects/3/6/7/dataset_36735766-9144-4799-b1be-6a5d2817482c_files:/galaxy/server/database/objects/3/6/7/dataset_36735766-9144-4799-b1be-6a5d2817482c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (203) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/203/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/203/galaxy_203.ec; sh -c "exit $return_code"
galaxy.jobs.command_factory INFO 2024-11-24 06:48:07,383 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/204/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/204/registry.xml' '/galaxy/server/database/jobs_directory/000/204/upload_params.json' '271:/galaxy/server/database/objects/7/b/5/dataset_7b51e090-7d5e-4786-b8f4-2a7f3080c677_files:/galaxy/server/database/objects/7/b/5/dataset_7b51e090-7d5e-4786-b8f4-2a7f3080c677.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (204) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/204/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/204/galaxy_204.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:48:07,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 175 executed (408.045 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,433 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,441 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:07,472 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [205] prepared (96.291 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:48:07,490 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/205/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/205/registry.xml' '/galaxy/server/database/jobs_directory/000/205/upload_params.json' '272:/galaxy/server/database/objects/5/b/d/dataset_5bde70b3-853d-4090-aef6-8b19153d0861_files:/galaxy/server/database/objects/5/b/d/dataset_5bde70b3-853d-4090-aef6-8b19153d0861.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:48:07,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (205) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/205/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/205/galaxy_205.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,510 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sc2p6 with k8s id: gxy-sc2p6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,515 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 175 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79bs9 with k8s id: gxy-79bs9  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,673 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kn6df with k8s id: gxy-kn6df  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,711 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,889 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhd4z with k8s id: gxy-bhd4z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:07,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wb5vq with k8s id: gxy-wb5vq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sc2p6 with k8s id: gxy-sc2p6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79bs9 with k8s id: gxy-79bs9  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,790 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,897 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhd4z with k8s id: gxy-bhd4z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:09,928 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wb5vq with k8s id: gxy-wb5vq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,144 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cwrk4 with k8s id: gxy-cwrk4  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g8vtf with k8s id: gxy-g8vtf  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,273 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kj5td with k8s id: gxy-kj5td  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:10,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kqwdw with k8s id: gxy-kqwdw  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cgvcl with k8s id: gxy-cgvcl succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9r26b with k8s id: gxy-9r26b succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-z7v24 with k8s id: gxy-z7v24 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:48:11,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 176: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:11,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 177: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:11,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 178: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sc2p6 with k8s id: gxy-sc2p6  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79bs9 with k8s id: gxy-79bs9  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:11,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wb5vq with k8s id: gxy-wb5vq  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cwrk4 with k8s id: gxy-cwrk4  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g8vtf with k8s id: gxy-g8vtf  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:12,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:13,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kpddd with k8s id: gxy-kpddd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:13,842 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ph5gl with k8s id: gxy-ph5gl succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:13,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9hbpd with k8s id: gxy-9hbpd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:13,929 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kngpx with k8s id: gxy-kngpx succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:13,944 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b6srn with k8s id: gxy-b6srn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,006 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9qpfh with k8s id: gxy-9qpfh succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:48:14,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 179: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,401 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:14,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:15,022 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:15,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:15,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:15,430 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:15,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mzlrh with k8s id: gxy-mzlrh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,143 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qzb62 with k8s id: gxy-qzb62 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5hlmw with k8s id: gxy-5hlmw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wcn4k failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,400 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-wcn4k.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 189 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:48:17,495 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-wcn4k

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-wcn4k": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-v72k4 with k8s id: gxy-v72k4 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,700 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:17,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-p5zxn with k8s id: gxy-p5zxn succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:19,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:20,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sqjcj with k8s id: gxy-sqjcj succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:20,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kn6df with k8s id: gxy-kn6df succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:20,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:21,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:21,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:21,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:21,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:22,502 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:22,626 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:22,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:22,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bhd4z with k8s id: gxy-bhd4z succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:23,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:23,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv  pending...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:24,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:24,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:24,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cwrk4 with k8s id: gxy-cwrk4 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:25,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g8vtf with k8s id: gxy-g8vtf succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:25,109 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kj5td with k8s id: gxy-kj5td succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:25,204 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kqwdw with k8s id: gxy-kqwdw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:26,217 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sc2p6 with k8s id: gxy-sc2p6 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:26,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-79bs9 with k8s id: gxy-79bs9 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:26,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wb5vq with k8s id: gxy-wb5vq succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:48:29,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 177 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:29,651 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 244
galaxy.jobs INFO 2024-11-24 06:48:29,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 177 in /galaxy/server/database/jobs_directory/000/177
galaxy.jobs DEBUG 2024-11-24 06:48:29,812 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 177 executed (181.869 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:29,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 177 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:29,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 176 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:29,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 243
galaxy.jobs.runners DEBUG 2024-11-24 06:48:30,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 178 finished
galaxy.jobs INFO 2024-11-24 06:48:30,051 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 176 in /galaxy/server/database/jobs_directory/000/176
galaxy.model.metadata DEBUG 2024-11-24 06:48:30,070 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 245
galaxy.jobs INFO 2024-11-24 06:48:30,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 178 in /galaxy/server/database/jobs_directory/000/178
galaxy.jobs.runners DEBUG 2024-11-24 06:48:30,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 180: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:48:30,139 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 176 executed (211.020 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:30,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 176 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:30,174 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 178 executed (136.422 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:30,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 178 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:30,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 181: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:30,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 182: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:31,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t5kct with k8s id: gxy-t5kct succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:48:32,021 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 179 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:32,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 246
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:32,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mmcxc with k8s id: gxy-mmcxc succeeded
galaxy.jobs INFO 2024-11-24 06:48:32,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 179 in /galaxy/server/database/jobs_directory/000/179
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:32,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vrpll with k8s id: gxy-vrpll succeeded
galaxy.jobs DEBUG 2024-11-24 06:48:32,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 179 executed (304.711 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:32,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 179 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:32,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 183: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:33,332 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zk28z with k8s id: gxy-zk28z succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:33,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88fwv with k8s id: gxy-88fwv succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:48:45,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 180 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:45,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 247
galaxy.jobs INFO 2024-11-24 06:48:45,350 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 180 in /galaxy/server/database/jobs_directory/000/180
galaxy.jobs DEBUG 2024-11-24 06:48:45,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 180 executed (188.658 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:45,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 180 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:45,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 181 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:45,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 248
galaxy.jobs.runners DEBUG 2024-11-24 06:48:45,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 184: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:45,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 182 finished
galaxy.jobs INFO 2024-11-24 06:48:45,813 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 181 in /galaxy/server/database/jobs_directory/000/181
galaxy.model.metadata DEBUG 2024-11-24 06:48:45,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 249
galaxy.jobs INFO 2024-11-24 06:48:45,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 182 in /galaxy/server/database/jobs_directory/000/182
galaxy.jobs DEBUG 2024-11-24 06:48:45,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 181 executed (198.966 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:45,921 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 181 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:48:45,967 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 182 executed (143.867 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:46,005 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 182 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:46,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 185: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:46,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 187: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:48:47,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 183 finished
galaxy.model.metadata DEBUG 2024-11-24 06:48:47,605 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 250
galaxy.jobs INFO 2024-11-24 06:48:47,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 183 in /galaxy/server/database/jobs_directory/000/183
galaxy.jobs DEBUG 2024-11-24 06:48:47,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 183 executed (176.147 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:48:47,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 183 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:48:48,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 188: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:00,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 184 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:00,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 251
galaxy.jobs INFO 2024-11-24 06:49:00,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 184 in /galaxy/server/database/jobs_directory/000/184
galaxy.jobs DEBUG 2024-11-24 06:49:00,624 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 184 executed (199.045 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:00,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 184 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:00,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 185 finished
galaxy.jobs.runners DEBUG 2024-11-24 06:49:00,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 187 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:00,876 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 252
galaxy.model.metadata DEBUG 2024-11-24 06:49:00,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 254
galaxy.jobs.runners DEBUG 2024-11-24 06:49:00,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 190: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs INFO 2024-11-24 06:49:00,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 185 in /galaxy/server/database/jobs_directory/000/185
galaxy.jobs INFO 2024-11-24 06:49:00,972 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 187 in /galaxy/server/database/jobs_directory/000/187
galaxy.jobs DEBUG 2024-11-24 06:49:01,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 185 executed (179.632 ms)
galaxy.jobs DEBUG 2024-11-24 06:49:01,041 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 187 executed (179.694 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:01,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 185 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:01,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 187 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:01,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 191: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:01,313 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 186: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:02,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 188 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:02,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 255
galaxy.jobs INFO 2024-11-24 06:49:02,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 188 in /galaxy/server/database/jobs_directory/000/188
galaxy.jobs DEBUG 2024-11-24 06:49:02,916 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 188 executed (207.563 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:02,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 188 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:03,201 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 194: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:15,525 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 190 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:15,601 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 257
galaxy.jobs INFO 2024-11-24 06:49:15,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 190 in /galaxy/server/database/jobs_directory/000/190
galaxy.jobs DEBUG 2024-11-24 06:49:15,717 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 190 executed (176.326 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:15,730 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 190 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:16,000 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 198: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:16,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 191 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:16,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 258
galaxy.jobs INFO 2024-11-24 06:49:16,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 191 in /galaxy/server/database/jobs_directory/000/191
galaxy.jobs.runners DEBUG 2024-11-24 06:49:16,240 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 186 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:16,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 253
galaxy.jobs DEBUG 2024-11-24 06:49:16,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 191 executed (211.123 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:16,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 191 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 06:49:16,355 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 186 in /galaxy/server/database/jobs_directory/000/186
galaxy.jobs DEBUG 2024-11-24 06:49:16,438 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 186 executed (179.364 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:16,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 186 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:16,571 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 202: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:16,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 203: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:17,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 194 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:17,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 261
galaxy.jobs INFO 2024-11-24 06:49:17,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 194 in /galaxy/server/database/jobs_directory/000/194
galaxy.jobs DEBUG 2024-11-24 06:49:18,017 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 194 executed (182.078 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:18,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 194 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:18,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 204: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:30,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 198 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:30,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 265
galaxy.jobs INFO 2024-11-24 06:49:30,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 198 in /galaxy/server/database/jobs_directory/000/198
galaxy.jobs DEBUG 2024-11-24 06:49:30,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 198 executed (134.817 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:30,704 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 198 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:30,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 205: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:31,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 202 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:31,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 269
galaxy.jobs INFO 2024-11-24 06:49:31,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 202 in /galaxy/server/database/jobs_directory/000/202
galaxy.jobs DEBUG 2024-11-24 06:49:31,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 202 executed (177.440 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:31,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 202 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:31,515 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 203 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:31,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 270
galaxy.jobs INFO 2024-11-24 06:49:31,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 203 in /galaxy/server/database/jobs_directory/000/203
galaxy.jobs.runners DEBUG 2024-11-24 06:49:31,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 192: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs DEBUG 2024-11-24 06:49:31,711 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 203 executed (176.417 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:31,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 203 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:32,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 193: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:33,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 204 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:33,311 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 271
galaxy.jobs INFO 2024-11-24 06:49:33,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 204 in /galaxy/server/database/jobs_directory/000/204
galaxy.jobs DEBUG 2024-11-24 06:49:33,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 204 executed (184.441 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:33,441 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 204 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:33,710 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 199: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:46,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 205 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:46,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 272
galaxy.jobs INFO 2024-11-24 06:49:46,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 205 in /galaxy/server/database/jobs_directory/000/205
galaxy.jobs DEBUG 2024-11-24 06:49:46,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 205 executed (195.235 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:46,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 205 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:46,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 196: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:46,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 192 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:46,833 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 259
galaxy.jobs INFO 2024-11-24 06:49:46,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 192 in /galaxy/server/database/jobs_directory/000/192
galaxy.jobs DEBUG 2024-11-24 06:49:46,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 192 executed (143.897 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:47,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 192 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:47,314 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 195: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:47,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 193 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:47,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 260
galaxy.jobs INFO 2024-11-24 06:49:47,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 193 in /galaxy/server/database/jobs_directory/000/193
galaxy.jobs DEBUG 2024-11-24 06:49:47,639 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 193 executed (139.606 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:47,650 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 193 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:47,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 197: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:49:48,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 199 finished
galaxy.model.metadata DEBUG 2024-11-24 06:49:48,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 266
galaxy.jobs INFO 2024-11-24 06:49:48,715 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 199 in /galaxy/server/database/jobs_directory/000/199
galaxy.jobs DEBUG 2024-11-24 06:49:48,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 199 executed (178.140 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:49:48,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 199 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:49:49,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 200: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:00,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 196 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:00,845 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 263
galaxy.jobs INFO 2024-11-24 06:50:00,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 196 in /galaxy/server/database/jobs_directory/000/196
galaxy.jobs DEBUG 2024-11-24 06:50:01,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 196 executed (184.112 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:50:01,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] No k8s job found which matches job id 'gxy-t5kct'. Ignoring...
galaxy.jobs.runners DEBUG 2024-11-24 06:50:01,209 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 201: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:01,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 195 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:01,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 262
galaxy.jobs INFO 2024-11-24 06:50:01,725 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 195 in /galaxy/server/database/jobs_directory/000/195
galaxy.jobs DEBUG 2024-11-24 06:50:01,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 195 executed (187.127 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:50:01,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] No k8s job found which matches job id 'gxy-mmcxc'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,820 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189/gxy-wcn4k) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189/gxy-wcn4k) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189/gxy-wcn4k) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189/gxy-wcn4k) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-wcn4k.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 189 (gxy-wcn4k)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Could not find job with id gxy-wcn4k to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:01,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (189/gxy-wcn4k) Terminated at user's request
galaxy.jobs.runners DEBUG 2024-11-24 06:50:02,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 197 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:02,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 264
galaxy.jobs INFO 2024-11-24 06:50:02,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 197 in /galaxy/server/database/jobs_directory/000/197
galaxy.jobs DEBUG 2024-11-24 06:50:02,775 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 197 executed (135.373 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:50:02,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] No k8s job found which matches job id 'gxy-vrpll'. Ignoring...
galaxy.jobs.handler DEBUG 2024-11-24 06:50:03,026 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 207, 206
tpv.core.entities DEBUG 2024-11-24 06:50:03,054 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:03,054 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:03,058 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:03,068 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:03,081 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Working directory for job is: /galaxy/server/database/jobs_directory/000/206
galaxy.jobs.runners DEBUG 2024-11-24 06:50:03,103 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [206] queued (44.613 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:03,105 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (206) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,108 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 206
tpv.core.entities DEBUG 2024-11-24 06:50:03,114 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:03,115 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:03,118 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:03,127 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:03,150 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Working directory for job is: /galaxy/server/database/jobs_directory/000/207
galaxy.jobs.runners DEBUG 2024-11-24 06:50:03,155 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [207] queued (37.572 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:03,158 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (207) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,162 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 207
galaxy.jobs DEBUG 2024-11-24 06:50:03,232 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [206] prepared (113.340 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:50:03,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/206/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/206/registry.xml' '/galaxy/server/database/jobs_directory/000/206/upload_params.json' '273:/galaxy/server/database/objects/2/b/c/dataset_2bcf958f-8481-4aa8-8f04-1cf78379d9c0_files:/galaxy/server/database/objects/2/b/c/dataset_2bcf958f-8481-4aa8-8f04-1cf78379d9c0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:50:03,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (206) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/206/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/206/galaxy_206.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:50:03,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [207] prepared (66.095 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,315 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:50:03,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/207/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/207/registry.xml' '/galaxy/server/database/jobs_directory/000/207/upload_params.json' '274:/galaxy/server/database/objects/7/b/2/dataset_7b29158c-7bde-494d-bdab-4917ed5e977f_files:/galaxy/server/database/objects/7/b/2/dataset_7b29158c-7bde-494d-bdab-4917ed5e977f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:50:03,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (207) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/207/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/207/galaxy_207.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:50:03,350 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 200 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:50:03,402 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 267
galaxy.jobs INFO 2024-11-24 06:50:03,427 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 200 in /galaxy/server/database/jobs_directory/000/200
galaxy.jobs DEBUG 2024-11-24 06:50:03,464 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 200 executed (96.200 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:50:03,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] No k8s job found which matches job id 'gxy-zk28z'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:03,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 06:50:09,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 201 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:09,292 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 268
galaxy.jobs INFO 2024-11-24 06:50:09,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 201 in /galaxy/server/database/jobs_directory/000/201
galaxy.jobs DEBUG 2024-11-24 06:50:09,362 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 201 executed (88.900 ms)
galaxy.jobs.runners.kubernetes WARNING 2024-11-24 06:50:09,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] No k8s job found which matches job id 'gxy-88fwv'. Ignoring...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:13,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-865xh with k8s id: gxy-865xh succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:13,858 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bvmfh with k8s id: gxy-bvmfh succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:50:13,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 206: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:13,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 207: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:21,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 206 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:21,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 273
galaxy.jobs INFO 2024-11-24 06:50:21,274 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 206 in /galaxy/server/database/jobs_directory/000/206
galaxy.jobs DEBUG 2024-11-24 06:50:21,307 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 206 executed (75.057 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:21,317 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 206 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:50:21,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 207 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:21,372 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 274
galaxy.jobs INFO 2024-11-24 06:50:21,395 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 207 in /galaxy/server/database/jobs_directory/000/207
galaxy.jobs DEBUG 2024-11-24 06:50:21,434 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 207 executed (78.181 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:21,447 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 207 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:50:22,469 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 208
tpv.core.entities DEBUG 2024-11-24 06:50:22,494 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:22,494 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:22,498 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:22,508 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:22,520 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Working directory for job is: /galaxy/server/database/jobs_directory/000/208
galaxy.jobs.runners DEBUG 2024-11-24 06:50:22,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [208] queued (29.615 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:22,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (208) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:22,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 208
galaxy.jobs DEBUG 2024-11-24 06:50:22,582 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [208] prepared (45.749 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:22,583 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:50:22,583 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:22,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:50:22,827 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/208/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/208/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/custom_content_0 &&  ln -s '/galaxy/server/database/objects/2/b/c/dataset_2bcf958f-8481-4aa8-8f04-1cf78379d9c0.dat' 'multiqc_WDir/custom_content_0/file_0_0' && more /galaxy/server/database/objects/2/b/c/dataset_2bcf958f-8481-4aa8-8f04-1cf78379d9c0.dat && ln -s '/galaxy/server/database/objects/7/b/2/dataset_7b29158c-7bde-494d-bdab-4917ed5e977f.dat' 'multiqc_WDir/custom_content_0/file_0_1' && more /galaxy/server/database/objects/7/b/2/dataset_7b29158c-7bde-494d-bdab-4917ed5e977f.dat &&  multiqc multiqc_WDir --filename "report"      --config '/galaxy/server/database/jobs_directory/000/208/configs/tmpd_4_alms']
galaxy.jobs.runners DEBUG 2024-11-24 06:50:22,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (208) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/208/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/208/galaxy_208.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/208/working/report.html" -a -f "/galaxy/server/database/objects/a/6/f/dataset_a6faa3f1-e993-4a5e-b078-99a5e79023e8.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/208/working/report.html" "/galaxy/server/database/objects/a/6/f/dataset_a6faa3f1-e993-4a5e-b078-99a5e79023e8.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:22,847 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:22,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:50:22,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:22,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:22,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:23,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:31,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l2677 with k8s id: gxy-l2677 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:50:31,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 208: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:38,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 208 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:50:38,314 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (208) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/208/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (4.328 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:50:38,329 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (208) Add dynamic collection datasets to history for output [stats] (14.757 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:50:38,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 275
galaxy.jobs INFO 2024-11-24 06:50:38,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 208 in /galaxy/server/database/jobs_directory/000/208
galaxy.jobs DEBUG 2024-11-24 06:50:38,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 208 executed (108.817 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:38,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 208 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:50:39,789 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 209
tpv.core.entities DEBUG 2024-11-24 06:50:39,814 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:39,815 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:39,819 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:39,827 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:39,838 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Working directory for job is: /galaxy/server/database/jobs_directory/000/209
galaxy.jobs.runners DEBUG 2024-11-24 06:50:39,845 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [209] queued (25.972 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:39,847 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (209) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:39,849 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 209
galaxy.jobs DEBUG 2024-11-24 06:50:39,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [209] prepared (66.836 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:50:39,940 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/209/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/209/registry.xml' '/galaxy/server/database/jobs_directory/000/209/upload_params.json' '277:/galaxy/server/database/objects/2/b/8/dataset_2b83e376-61db-4049-8167-14c580d8775b_files:/galaxy/server/database/objects/2/b/8/dataset_2b83e376-61db-4049-8167-14c580d8775b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:50:39,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (209) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/209/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/209/galaxy_209.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:39,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:39,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:40,090 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 06:50:40,851 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 210
tpv.core.entities DEBUG 2024-11-24 06:50:40,872 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:40,873 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:40,876 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:40,885 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:40,897 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Working directory for job is: /galaxy/server/database/jobs_directory/000/210
galaxy.jobs.runners DEBUG 2024-11-24 06:50:40,904 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [210] queued (27.879 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:40,906 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (210) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:40,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 210
galaxy.jobs DEBUG 2024-11-24 06:50:40,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [210] prepared (63.893 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:50:40,994 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/210/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/210/registry.xml' '/galaxy/server/database/jobs_directory/000/210/upload_params.json' '278:/galaxy/server/database/objects/4/a/8/dataset_4a886dd6-758c-4ce7-baaa-2e8f09dadf29_files:/galaxy/server/database/objects/4/a/8/dataset_4a886dd6-758c-4ce7-baaa-2e8f09dadf29.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:50:41,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (210) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/210/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/210/galaxy_210.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:41,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:41,027 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:41,151 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:49,345 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-hdx8w with k8s id: gxy-hdx8w succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:50:49,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 209: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:50,368 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zj944 with k8s id: gxy-zj944 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:50:50,466 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 210: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:50:56,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 209 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:56,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 277
galaxy.jobs INFO 2024-11-24 06:50:57,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 209 in /galaxy/server/database/jobs_directory/000/209
galaxy.jobs DEBUG 2024-11-24 06:50:57,068 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 209 executed (93.464 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:57,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 209 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:50:57,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 210 finished
galaxy.model.metadata DEBUG 2024-11-24 06:50:57,805 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 278
galaxy.jobs INFO 2024-11-24 06:50:57,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 210 in /galaxy/server/database/jobs_directory/000/210
galaxy.jobs DEBUG 2024-11-24 06:50:57,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 210 executed (73.277 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:57,871 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 210 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:50:58,221 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 211
tpv.core.entities DEBUG 2024-11-24 06:50:58,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:50:58,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:50:58,248 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:50:58,258 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:50:58,270 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Working directory for job is: /galaxy/server/database/jobs_directory/000/211
galaxy.jobs.runners DEBUG 2024-11-24 06:50:58,279 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [211] queued (30.802 ms)
galaxy.jobs.handler INFO 2024-11-24 06:50:58,281 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (211) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:58,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 211
galaxy.jobs DEBUG 2024-11-24 06:50:58,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [211] prepared (48.360 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:58,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:50:58,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:58,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:50:58,374 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/211/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/211/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/fastqc_0 &&    mkdir 'multiqc_WDir/fastqc_0/data_0' &&  mkdir 'multiqc_WDir/fastqc_0/data_0/file_0' && ln -s '/galaxy/server/database/objects/2/b/8/dataset_2b83e376-61db-4049-8167-14c580d8775b.dat' 'multiqc_WDir/fastqc_0/data_0/file_0/fastqc_data.txt' && mkdir 'multiqc_WDir/fastqc_0/data_0/file_1' && ln -s '/galaxy/server/database/objects/4/a/8/dataset_4a886dd6-758c-4ce7-baaa-2e8f09dadf29.dat' 'multiqc_WDir/fastqc_0/data_0/file_1/fastqc_data.txt' &&  multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"  --flat --export]
galaxy.jobs.runners DEBUG 2024-11-24 06:50:58,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (211) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/211/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/211/galaxy_211.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/211/working/report.html" -a -f "/galaxy/server/database/objects/a/1/1/dataset_a112a287-571c-448e-adc6-fd80d56c5d50.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/211/working/report.html" "/galaxy/server/database/objects/a/1/1/dataset_a112a287-571c-448e-adc6-fd80d56c5d50.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:58,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:58,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:50:58,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:50:58,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:58,433 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:50:59,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:11,607 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-s825v with k8s id: gxy-s825v succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:51:11,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 211: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:51:18,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 211 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_per_base_n_content_plot_1.txt] with element identifier [fastqc_per_base_n_content_plot_1] for output [plots] (3.397 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_per_base_sequence_quality_plot_1.txt] with element identifier [fastqc_per_base_sequence_quality_plot_1] for output [plots] (0.435 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Counts.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Counts] for output [plots] (0.364 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_per_sequence_gc_content_plot_Percentages.txt] with element identifier [fastqc_per_sequence_gc_content_plot_Percentages] for output [plots] (0.388 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_per_sequence_quality_scores_plot_1.txt] with element identifier [fastqc_per_sequence_quality_scores_plot_1] for output [plots] (0.350 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,830 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_sequence_counts_plot_1.txt] with element identifier [fastqc_sequence_counts_plot_1] for output [plots] (0.351 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/mqc_fastqc_sequence_duplication_levels_plot_1.txt] with element identifier [fastqc_sequence_duplication_levels_plot_1] for output [plots] (1.921 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,887 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Add dynamic collection datasets to history for output [plots] (54.050 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/multiqc_fastqc.txt] with element identifier [fastqc] for output [stats] (0.588 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (0.372 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/211/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.391 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:18,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (211) Add dynamic collection datasets to history for output [stats] (24.093 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:51:18,981 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 279
galaxy.jobs INFO 2024-11-24 06:51:19,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 211 in /galaxy/server/database/jobs_directory/000/211
galaxy.jobs DEBUG 2024-11-24 06:51:19,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 211 executed (251.633 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:19,068 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 211 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:51:20,633 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 212
tpv.core.entities DEBUG 2024-11-24 06:51:20,656 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:51:20,656 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:51:20,659 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:51:20,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:51:20,679 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Working directory for job is: /galaxy/server/database/jobs_directory/000/212
galaxy.jobs.runners DEBUG 2024-11-24 06:51:20,684 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [212] queued (25.126 ms)
galaxy.jobs.handler INFO 2024-11-24 06:51:20,686 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (212) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:20,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 212
galaxy.jobs DEBUG 2024-11-24 06:51:20,756 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [212] prepared (60.539 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:51:20,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/212/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/212/registry.xml' '/galaxy/server/database/jobs_directory/000/212/upload_params.json' '290:/galaxy/server/database/objects/9/0/4/dataset_90441085-5f5c-4616-ad97-01d65611aa44_files:/galaxy/server/database/objects/9/0/4/dataset_90441085-5f5c-4616-ad97-01d65611aa44.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:51:20,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (212) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/212/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/212/galaxy_212.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:20,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:20,805 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:21,633 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:29,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-h4dk2 with k8s id: gxy-h4dk2 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:51:29,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 212: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:51:36,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 212 finished
galaxy.model.metadata DEBUG 2024-11-24 06:51:36,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 290
galaxy.jobs INFO 2024-11-24 06:51:37,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 212 in /galaxy/server/database/jobs_directory/000/212
galaxy.jobs DEBUG 2024-11-24 06:51:37,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 212 executed (81.701 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:37,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 212 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:51:37,956 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 213
tpv.core.entities DEBUG 2024-11-24 06:51:37,979 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:51:37,979 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:51:37,982 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:51:37,991 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:51:38,003 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Working directory for job is: /galaxy/server/database/jobs_directory/000/213
galaxy.jobs.runners DEBUG 2024-11-24 06:51:38,012 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [213] queued (29.816 ms)
galaxy.jobs.handler INFO 2024-11-24 06:51:38,014 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (213) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:38,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 213
galaxy.jobs DEBUG 2024-11-24 06:51:38,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [213] prepared (50.591 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:51:38,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:51:38,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:51:38,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:51:38,110 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/213/tool_script.sh] for tool command [multiqc --version > /galaxy/server/database/jobs_directory/000/213/outputs/COMMAND_VERSION 2>&1;
die() { echo "$@" 1>&2 ; exit 1; } &&  mkdir multiqc_WDir &&   mkdir multiqc_WDir/pycoqc_0 &&         grep -q '"pycoqc":' /galaxy/server/database/objects/9/0/4/dataset_90441085-5f5c-4616-ad97-01d65611aa44.dat || die "Module 'pycoqc: '"pycoqc":' not found in the file 'pycoqc_json'" && ln -s '/galaxy/server/database/objects/9/0/4/dataset_90441085-5f5c-4616-ad97-01d65611aa44.dat' 'multiqc_WDir/pycoqc_0/pycoqc_json'  &&    multiqc multiqc_WDir --filename "report"  --title "Title of the report" --comment "Commment for the report"]
galaxy.jobs.runners DEBUG 2024-11-24 06:51:38,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (213) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/213/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/213/galaxy_213.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/213/working/report.html" -a -f "/galaxy/server/database/objects/5/8/0/dataset_58077362-b3cf-4d6b-b778-f5e0f264899f.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/213/working/report.html" "/galaxy/server/database/objects/5/8/0/dataset_58077362-b3cf-4d6b-b778-f5e0f264899f.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:38,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:51:38,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:51:38,130 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.9+galaxy1: multiqc:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:51:38,148 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/multiqc:1.9--py_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:38,160 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:38,858 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:45,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tqcx9 with k8s id: gxy-tqcx9 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:51:46,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 213: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:51:53,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 213 finished
galaxy.model.store.discover DEBUG 2024-11-24 06:51:53,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (213) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/213/working/report_data/multiqc_general_stats.txt] with element identifier [general_stats] for output [stats] (3.028 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:53,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (213) Created dynamic collection dataset for path [/galaxy/server/database/jobs_directory/000/213/working/report_data/multiqc_sources.txt] with element identifier [sources] for output [stats] (0.454 ms)
galaxy.model.store.discover DEBUG 2024-11-24 06:51:53,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (213) Add dynamic collection datasets to history for output [stats] (20.562 ms)
galaxy.model.metadata DEBUG 2024-11-24 06:51:53,272 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 291
galaxy.jobs INFO 2024-11-24 06:51:53,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 213 in /galaxy/server/database/jobs_directory/000/213
galaxy.jobs DEBUG 2024-11-24 06:51:53,336 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 213 executed (131.609 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:53,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 213 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:51:57,308 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 214
tpv.core.entities DEBUG 2024-11-24 06:51:57,329 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:51:57,329 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:51:57,333 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:51:57,342 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:51:57,353 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Working directory for job is: /galaxy/server/database/jobs_directory/000/214
galaxy.jobs.runners DEBUG 2024-11-24 06:51:57,360 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [214] queued (27.654 ms)
galaxy.jobs.handler INFO 2024-11-24 06:51:57,363 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (214) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:57,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 214
galaxy.jobs DEBUG 2024-11-24 06:51:57,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [214] prepared (57.974 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:51:57,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/214/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/214/registry.xml' '/galaxy/server/database/jobs_directory/000/214/upload_params.json' '294:/galaxy/server/database/objects/6/8/d/dataset_68dab62b-ffeb-463a-a5d5-df775c2bcfef_files:/galaxy/server/database/objects/6/8/d/dataset_68dab62b-ffeb-463a-a5d5-df775c2bcfef.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:51:57,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (214) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/214/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/214/galaxy_214.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:57,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:57,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:51:57,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:07,122 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-b69kn with k8s id: gxy-b69kn succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:52:07,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 214: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:52:14,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 214 finished
galaxy.model.metadata DEBUG 2024-11-24 06:52:14,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 294
galaxy.jobs INFO 2024-11-24 06:52:14,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 214 in /galaxy/server/database/jobs_directory/000/214
galaxy.jobs DEBUG 2024-11-24 06:52:14,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 214 executed (78.147 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:14,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 214 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:52:15,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 215
tpv.core.entities DEBUG 2024-11-24 06:52:15,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:52:15,649 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:52:15,653 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:52:15,662 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:52:15,680 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Working directory for job is: /galaxy/server/database/jobs_directory/000/215
galaxy.jobs.runners DEBUG 2024-11-24 06:52:15,688 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [215] queued (35.094 ms)
galaxy.jobs.handler INFO 2024-11-24 06:52:15,692 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (215) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:15,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 215
galaxy.jobs DEBUG 2024-11-24 06:52:15,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [215] prepared (47.545 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:52:15,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:52:15,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:52:16,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:52:16,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/215/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/215/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/6/8/d/dataset_68dab62b-ffeb-463a-a5d5-df775c2bcfef.dat' './read_0.fastq.gz' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --fastq_rich read_0.fastq.gz --downsample 800 --plots kde        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-24 06:52:16,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (215) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/215/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/215/galaxy_215.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/215/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/e/d/5/dataset_ed58f929-0e2c-42e5-a734-10883c22fcf4.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/215/working/NanoPlot-report.html" "/galaxy/server/database/objects/e/d/5/dataset_ed58f929-0e2c-42e5-a734-10883c22fcf4.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/215/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/4/0/8/dataset_40857cfa-3b99-4b0e-9bb8-ca20114ac220.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/215/working/NanoStats.txt" "/galaxy/server/database/objects/4/0/8/dataset_40857cfa-3b99-4b0e-9bb8-ca20114ac220.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/215/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/e/2/2/dataset_e22e3685-a9d4-41b4-ac55-de13c42b4a11.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/215/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/e/2/2/dataset_e22e3685-a9d4-41b4-ac55-de13c42b4a11.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:16,318 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:52:16,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:52:16,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:52:16,338 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:16,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:17,148 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:52:57,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6cq8v with k8s id: gxy-6cq8v succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:52:57,880 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 215: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:53:05,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 215 finished
galaxy.model.metadata DEBUG 2024-11-24 06:53:05,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 295
galaxy.model.metadata DEBUG 2024-11-24 06:53:05,105 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 296
galaxy.model.metadata DEBUG 2024-11-24 06:53:05,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 297
galaxy.util WARNING 2024-11-24 06:53:05,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/e/d/5/dataset_ed58f929-0e2c-42e5-a734-10883c22fcf4.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/e/d/5/dataset_ed58f929-0e2c-42e5-a734-10883c22fcf4.dat'
galaxy.util WARNING 2024-11-24 06:53:05,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/4/0/8/dataset_40857cfa-3b99-4b0e-9bb8-ca20114ac220.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/4/0/8/dataset_40857cfa-3b99-4b0e-9bb8-ca20114ac220.dat'
galaxy.util WARNING 2024-11-24 06:53:05,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/e/2/2/dataset_e22e3685-a9d4-41b4-ac55-de13c42b4a11.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/e/2/2/dataset_e22e3685-a9d4-41b4-ac55-de13c42b4a11.dat'
galaxy.jobs INFO 2024-11-24 06:53:05,153 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 215 in /galaxy/server/database/jobs_directory/000/215
galaxy.jobs DEBUG 2024-11-24 06:53:05,202 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 215 executed (123.770 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:05,216 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 215 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:53:08,505 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 216
tpv.core.entities DEBUG 2024-11-24 06:53:08,524 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:53:08,525 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:53:08,527 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:53:08,535 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:53:08,546 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Working directory for job is: /galaxy/server/database/jobs_directory/000/216
galaxy.jobs.runners DEBUG 2024-11-24 06:53:08,553 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [216] queued (25.320 ms)
galaxy.jobs.handler INFO 2024-11-24 06:53:08,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (216) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:08,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 216
galaxy.jobs DEBUG 2024-11-24 06:53:08,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [216] prepared (61.150 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:53:08,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/216/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/216/registry.xml' '/galaxy/server/database/jobs_directory/000/216/upload_params.json' '298:/galaxy/server/database/objects/e/6/d/dataset_e6da06c3-bdd7-4d02-b102-52dbed7d0010_files:/galaxy/server/database/objects/e/6/d/dataset_e6da06c3-bdd7-4d02-b102-52dbed7d0010.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:53:08,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (216) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/216/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/216/galaxy_216.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:08,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:08,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:08,790 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:18,931 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t7l2x with k8s id: gxy-t7l2x succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:53:19,021 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 216: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:53:26,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 216 finished
galaxy.model.metadata DEBUG 2024-11-24 06:53:26,194 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 298
galaxy.jobs INFO 2024-11-24 06:53:26,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 216 in /galaxy/server/database/jobs_directory/000/216
galaxy.jobs DEBUG 2024-11-24 06:53:26,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 216 executed (94.944 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:26,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 216 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:53:26,829 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 217
tpv.core.entities DEBUG 2024-11-24 06:53:26,850 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:53:26,851 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:53:26,853 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:53:26,861 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:53:26,875 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Working directory for job is: /galaxy/server/database/jobs_directory/000/217
galaxy.jobs.runners DEBUG 2024-11-24 06:53:26,882 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [217] queued (28.459 ms)
galaxy.jobs.handler INFO 2024-11-24 06:53:26,884 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (217) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:26,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 217
galaxy.jobs DEBUG 2024-11-24 06:53:26,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [217] prepared (40.487 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:53:26,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:53:26,933 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:53:26,956 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:53:26,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/217/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/217/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/e/6/d/dataset_e6da06c3-bdd7-4d02-b102-52dbed7d0010.dat' './read_0.bam' && ln -s '/galaxy/server/database/objects/_metadata_files/f/9/3/metadata_f932376b-4575-48e4-91fd-a928325b792f.dat' './read_0.bam.bai' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --bam read_0.bam --maxlength 2000 --color yellow        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-24 06:53:26,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (217) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/217/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/217/galaxy_217.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/217/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/0/f/7/dataset_0f7122df-fba9-4ea3-8a79-d250919a2392.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/217/working/NanoPlot-report.html" "/galaxy/server/database/objects/0/f/7/dataset_0f7122df-fba9-4ea3-8a79-d250919a2392.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/217/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/b/a/d/dataset_bad9e425-1572-48a5-b81b-7616b2172abb.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/217/working/NanoStats.txt" "/galaxy/server/database/objects/b/a/d/dataset_bad9e425-1572-48a5-b81b-7616b2172abb.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/217/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/f/4/c/dataset_f4c2680c-4997-489b-9517-82422e3fea0f.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/217/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/f/4/c/dataset_f4c2680c-4997-489b-9517-82422e3fea0f.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:27,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:53:27,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:53:27,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:53:27,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:27,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:27,958 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:38,092 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cqzhm with k8s id: gxy-cqzhm succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:53:38,230 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 217: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:53:45,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 217 finished
galaxy.model.metadata DEBUG 2024-11-24 06:53:45,275 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 299
galaxy.model.metadata DEBUG 2024-11-24 06:53:45,280 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 300
galaxy.model.metadata DEBUG 2024-11-24 06:53:45,310 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 301
galaxy.util WARNING 2024-11-24 06:53:45,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/0/f/7/dataset_0f7122df-fba9-4ea3-8a79-d250919a2392.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/0/f/7/dataset_0f7122df-fba9-4ea3-8a79-d250919a2392.dat'
galaxy.util WARNING 2024-11-24 06:53:45,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/b/a/d/dataset_bad9e425-1572-48a5-b81b-7616b2172abb.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/b/a/d/dataset_bad9e425-1572-48a5-b81b-7616b2172abb.dat'
galaxy.jobs INFO 2024-11-24 06:53:45,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 217 in /galaxy/server/database/jobs_directory/000/217
galaxy.jobs DEBUG 2024-11-24 06:53:45,421 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 217 executed (165.378 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:45,432 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 217 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:53:47,189 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 219, 218
tpv.core.entities DEBUG 2024-11-24 06:53:47,211 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:53:47,211 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:53:47,214 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:53:47,225 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:53:47,238 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Working directory for job is: /galaxy/server/database/jobs_directory/000/218
galaxy.jobs.runners DEBUG 2024-11-24 06:53:47,245 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [218] queued (30.585 ms)
galaxy.jobs.handler INFO 2024-11-24 06:53:47,248 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (218) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,249 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 218
tpv.core.entities DEBUG 2024-11-24 06:53:47,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:53:47,260 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:53:47,264 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:53:47,275 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:53:47,299 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Working directory for job is: /galaxy/server/database/jobs_directory/000/219
galaxy.jobs.runners DEBUG 2024-11-24 06:53:47,307 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [219] queued (42.414 ms)
galaxy.jobs.handler INFO 2024-11-24 06:53:47,311 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (219) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,312 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 219
galaxy.jobs DEBUG 2024-11-24 06:53:47,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [218] prepared (85.714 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:53:47,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/218/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/218/registry.xml' '/galaxy/server/database/jobs_directory/000/218/upload_params.json' '302:/galaxy/server/database/objects/2/d/a/dataset_2dac9127-776e-4502-8626-b4bcfa538986_files:/galaxy/server/database/objects/2/d/a/dataset_2dac9127-776e-4502-8626-b4bcfa538986.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:53:47,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (218) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/218/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/218/galaxy_218.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:53:47,396 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [219] prepared (77.296 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:53:47,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/219/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/219/registry.xml' '/galaxy/server/database/jobs_directory/000/219/upload_params.json' '303:/galaxy/server/database/objects/8/b/4/dataset_8b40cbb0-6d93-4120-a737-7aa146e76825_files:/galaxy/server/database/objects/8/b/4/dataset_8b40cbb0-6d93-4120-a737-7aa146e76825.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:53:47,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (219) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/219/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/219/galaxy_219.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,438 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:47,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:48,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:48,157 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:57,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9x7bw with k8s id: gxy-9x7bw succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:53:57,387 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rjt52 with k8s id: gxy-rjt52 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:53:57,496 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 219: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:53:57,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 218: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:54:04,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 219 finished
galaxy.model.metadata DEBUG 2024-11-24 06:54:04,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 303
galaxy.jobs INFO 2024-11-24 06:54:04,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 219 in /galaxy/server/database/jobs_directory/000/219
galaxy.jobs DEBUG 2024-11-24 06:54:05,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 219 executed (87.351 ms)
galaxy.jobs.runners DEBUG 2024-11-24 06:54:05,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 218 finished
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:05,024 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 219 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.model.metadata DEBUG 2024-11-24 06:54:05,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 302
galaxy.jobs INFO 2024-11-24 06:54:05,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 218 in /galaxy/server/database/jobs_directory/000/218
galaxy.jobs DEBUG 2024-11-24 06:54:05,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 218 executed (88.960 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:05,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 218 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:54:05,603 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 220
tpv.core.entities DEBUG 2024-11-24 06:54:05,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/.*, abstract=False, cores=2, mem=12, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:54:05,632 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:54:05,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:54:05,643 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:54:05,659 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Working directory for job is: /galaxy/server/database/jobs_directory/000/220
galaxy.jobs.runners DEBUG 2024-11-24 06:54:05,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [220] queued (32.878 ms)
galaxy.jobs.handler INFO 2024-11-24 06:54:05,670 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (220) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:05,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 220
galaxy.jobs DEBUG 2024-11-24 06:54:05,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [220] prepared (41.931 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:05,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:54:05,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:05,743 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:54:05,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/220/tool_script.sh] for tool command [NanoPlot --version > /galaxy/server/database/jobs_directory/000/220/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/2/d/a/dataset_2dac9127-776e-4502-8626-b4bcfa538986.dat' './read_0.fasta' &&  ln -s '/galaxy/server/database/objects/8/b/4/dataset_8b40cbb0-6d93-4120-a737-7aa146e76825.dat' './read_1.fasta' &&   NanoPlot --threads ${GALAXY_SLOTS:-4} --tsv_stats --no_static --fasta read_0.fasta read_1.fasta        -o '.' && >&2 cat *log]
galaxy.jobs.runners DEBUG 2024-11-24 06:54:05,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (220) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/220/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/220/galaxy_220.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/220/working/NanoPlot-report.html" -a -f "/galaxy/server/database/objects/3/8/3/dataset_3836f3c1-d47e-49b9-9d13-6c422b23e530.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/220/working/NanoPlot-report.html" "/galaxy/server/database/objects/3/8/3/dataset_3836f3c1-d47e-49b9-9d13-6c422b23e530.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/220/working/NanoStats.txt" -a -f "/galaxy/server/database/objects/6/a/e/dataset_6aed5655-cf69-43ad-a969-1fc051e91501.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/220/working/NanoStats.txt" "/galaxy/server/database/objects/6/a/e/dataset_6aed5655-cf69-43ad-a969-1fc051e91501.dat" ; fi; 
if [ -f "/galaxy/server/database/jobs_directory/000/220/working/NanoStats_post_filtering.txt" -a -f "/galaxy/server/database/objects/0/9/d/dataset_09d6e555-07e4-4942-8a93-c33023be60cf.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/220/working/NanoStats_post_filtering.txt" "/galaxy/server/database/objects/0/9/d/dataset_09d6e555-07e4-4942-8a93-c33023be60cf.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:05,792 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:05,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:54:05,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0: nanoplot:1.43.0
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:05,814 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/nanoplot:1.43.0--pyhdfd78af_1,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:05,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:06,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:15,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-grk9h with k8s id: gxy-grk9h succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:54:15,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 220: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:54:22,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 220 finished
galaxy.model.metadata DEBUG 2024-11-24 06:54:22,714 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 304
galaxy.model.metadata DEBUG 2024-11-24 06:54:22,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 305
galaxy.model.metadata DEBUG 2024-11-24 06:54:22,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 306
galaxy.util WARNING 2024-11-24 06:54:22,777 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/3/8/3/dataset_3836f3c1-d47e-49b9-9d13-6c422b23e530.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/3/8/3/dataset_3836f3c1-d47e-49b9-9d13-6c422b23e530.dat'
galaxy.util WARNING 2024-11-24 06:54:22,778 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/6/a/e/dataset_6aed5655-cf69-43ad-a969-1fc051e91501.dat, group remains grp.struct_group(gr_name='root', gr_passwd='x', gr_gid=0, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/6/a/e/dataset_6aed5655-cf69-43ad-a969-1fc051e91501.dat'
galaxy.jobs INFO 2024-11-24 06:54:22,803 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 220 in /galaxy/server/database/jobs_directory/000/220
galaxy.jobs DEBUG 2024-11-24 06:54:22,849 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 220 executed (155.999 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:22,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 220 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:54:24,971 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 221
tpv.core.entities DEBUG 2024-11-24 06:54:24,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:54:24,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:54:24,997 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:54:25,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:54:25,022 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Working directory for job is: /galaxy/server/database/jobs_directory/000/221
galaxy.jobs.runners DEBUG 2024-11-24 06:54:25,029 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [221] queued (31.546 ms)
galaxy.jobs.handler INFO 2024-11-24 06:54:25,031 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (221) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:25,033 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 221
galaxy.jobs DEBUG 2024-11-24 06:54:25,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [221] prepared (62.994 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:54:25,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/221/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/221/registry.xml' '/galaxy/server/database/jobs_directory/000/221/upload_params.json' '307:/galaxy/server/database/objects/6/5/d/dataset_65d98cc4-60d2-44b8-a8da-a9cbfa39f465_files:/galaxy/server/database/objects/6/5/d/dataset_65d98cc4-60d2-44b8-a8da-a9cbfa39f465.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:54:25,126 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (221) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/221/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/221/galaxy_221.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:25,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:25,147 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:25,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:34,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mpvf8 with k8s id: gxy-mpvf8 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:54:34,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 221: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:54:41,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 221 finished
galaxy.model.metadata DEBUG 2024-11-24 06:54:41,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 307
galaxy.jobs INFO 2024-11-24 06:54:41,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 221 in /galaxy/server/database/jobs_directory/000/221
galaxy.jobs DEBUG 2024-11-24 06:54:41,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 221 executed (92.808 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:41,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 221 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:54:43,312 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 222
tpv.core.entities DEBUG 2024-11-24 06:54:43,338 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:54:43,339 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:54:43,343 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:54:43,353 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:54:43,365 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Working directory for job is: /galaxy/server/database/jobs_directory/000/222
galaxy.jobs.runners DEBUG 2024-11-24 06:54:43,371 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [222] queued (28.274 ms)
galaxy.jobs.handler INFO 2024-11-24 06:54:43,373 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (222) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:43,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 222
galaxy.jobs DEBUG 2024-11-24 06:54:43,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [222] prepared (42.847 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:43,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:54:43,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:43,638 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:54:43,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/222/tool_script.sh] for tool command [poretools fastq --type all --min-length 0 --max-length 1000000000  '/galaxy/server/database/objects/6/5/d/dataset_65d98cc4-60d2-44b8-a8da-a9cbfa39f465.dat' > '/galaxy/server/database/objects/3/7/a/dataset_37a8e8d4-08a2-4f4e-9a71-76a9aa7ea6b2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:54:43,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (222) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/222/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/222/galaxy_222.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:43,686 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:43,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:54:43,690 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:54:43,709 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:43,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:54:44,831 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:10,152 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5pl8d with k8s id: gxy-5pl8d succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:55:10,261 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 222: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:55:17,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 222 finished
galaxy.model.metadata DEBUG 2024-11-24 06:55:17,327 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 308
galaxy.jobs INFO 2024-11-24 06:55:17,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 222 in /galaxy/server/database/jobs_directory/000/222
galaxy.jobs DEBUG 2024-11-24 06:55:17,393 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 222 executed (88.302 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:17,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 222 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:55:19,017 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 223
tpv.core.entities DEBUG 2024-11-24 06:55:19,040 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:55:19,041 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:55:19,044 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:55:19,053 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:55:19,065 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Working directory for job is: /galaxy/server/database/jobs_directory/000/223
galaxy.jobs.runners DEBUG 2024-11-24 06:55:19,072 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [223] queued (28.548 ms)
galaxy.jobs.handler INFO 2024-11-24 06:55:19,074 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (223) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:19,076 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 223
galaxy.jobs DEBUG 2024-11-24 06:55:19,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [223] prepared (67.101 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:55:19,166 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/223/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/223/registry.xml' '/galaxy/server/database/jobs_directory/000/223/upload_params.json' '309:/galaxy/server/database/objects/b/4/f/dataset_b4f485a0-224d-4879-a371-239231321f16_files:/galaxy/server/database/objects/b/4/f/dataset_b4f485a0-224d-4879-a371-239231321f16.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:55:19,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (223) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/223/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/223/galaxy_223.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:19,185 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:19,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:20,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:28,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wpmt6 with k8s id: gxy-wpmt6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:55:28,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 223: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:55:35,682 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 223 finished
galaxy.model.metadata DEBUG 2024-11-24 06:55:35,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 309
galaxy.jobs INFO 2024-11-24 06:55:35,747 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 223 in /galaxy/server/database/jobs_directory/000/223
galaxy.jobs DEBUG 2024-11-24 06:55:35,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 223 executed (86.852 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:35,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 223 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:55:36,359 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 224
tpv.core.entities DEBUG 2024-11-24 06:55:36,386 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/.*, abstract=False, cores=1, mem=11.4, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:55:36,386 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:55:36,390 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:55:36,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:55:36,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Working directory for job is: /galaxy/server/database/jobs_directory/000/224
galaxy.jobs.runners DEBUG 2024-11-24 06:55:36,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [224] queued (29.129 ms)
galaxy.jobs.handler INFO 2024-11-24 06:55:36,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (224) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:36,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 224
galaxy.jobs DEBUG 2024-11-24 06:55:36,458 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [224] prepared (29.372 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:55:36,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:55:36,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:55:36,645 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:55:36,662 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/224/tool_script.sh] for tool command [poretools fasta --type all --min-length 0 --max-length 1000000000  '/galaxy/server/database/objects/b/4/f/dataset_b4f485a0-224d-4879-a371-239231321f16.dat' > '/galaxy/server/database/objects/c/b/5/dataset_cb5796bc-636d-4920-9be6-0bed92e9ec98.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:55:36,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (224) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/224/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/224/galaxy_224.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:36,685 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:55:36,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:55:36,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/poretools_extract/poretools_extract/0.6.1a1.0: poretools:0.6.1a1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:55:36,713 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/poretools:0.6.1a1--py_8,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:36,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:37,328 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:41,469 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vxqpk with k8s id: gxy-vxqpk succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:55:41,571 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 224: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:55:48,604 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 224 finished
galaxy.model.metadata DEBUG 2024-11-24 06:55:48,643 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 310
galaxy.jobs INFO 2024-11-24 06:55:48,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 224 in /galaxy/server/database/jobs_directory/000/224
galaxy.jobs DEBUG 2024-11-24 06:55:48,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 224 executed (83.922 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:48,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 224 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:55:51,645 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 225
tpv.core.entities DEBUG 2024-11-24 06:55:51,666 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:55:51,667 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:55:51,669 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:55:51,678 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:55:51,691 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Working directory for job is: /galaxy/server/database/jobs_directory/000/225
galaxy.jobs.runners DEBUG 2024-11-24 06:55:51,698 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [225] queued (28.845 ms)
galaxy.jobs.handler INFO 2024-11-24 06:55:51,700 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (225) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:51,702 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 225
galaxy.jobs DEBUG 2024-11-24 06:55:51,772 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [225] prepared (62.309 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:55:51,787 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/225/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/225/registry.xml' '/galaxy/server/database/jobs_directory/000/225/upload_params.json' '311:/galaxy/server/database/objects/c/d/0/dataset_cd0efd4e-7842-4c87-917c-d95ddcc77c77_files:/galaxy/server/database/objects/c/d/0/dataset_cd0efd4e-7842-4c87-917c-d95ddcc77c77.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:55:51,794 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (225) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/225/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/225/galaxy_225.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:51,805 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:51,816 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:55:52,494 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:01,729 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7mrt6 with k8s id: gxy-7mrt6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:56:01,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 225: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:56:08,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 225 finished
galaxy.model.metadata DEBUG 2024-11-24 06:56:08,834 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 311
galaxy.jobs INFO 2024-11-24 06:56:08,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 225 in /galaxy/server/database/jobs_directory/000/225
galaxy.jobs DEBUG 2024-11-24 06:56:08,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 225 executed (79.634 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:08,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 225 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:56:09,969 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 226
tpv.core.entities DEBUG 2024-11-24 06:56:09,993 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:56:09,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:56:09,997 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:56:10,007 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:56:10,019 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Working directory for job is: /galaxy/server/database/jobs_directory/000/226
galaxy.jobs.runners DEBUG 2024-11-24 06:56:10,026 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [226] queued (28.430 ms)
galaxy.jobs.handler INFO 2024-11-24 06:56:10,027 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (226) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:10,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 226
galaxy.jobs DEBUG 2024-11-24 06:56:10,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [226] prepared (43.661 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:10,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:10,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-24 06:56:10,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/226/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/c/d/0/dataset_cd0efd4e-7842-4c87-917c-d95ddcc77c77.dat --output=/galaxy/server/database/objects/6/1/1/dataset_611902a2-945a-4ec5-a119-43b7c29f0297.dat --coverage=3 --format=six --base="None" --seq_column="None" --loc_column="None" --base_column="None" --cvrg_column="None"]
galaxy.jobs.runners DEBUG 2024-11-24 06:56:10,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (226) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/226/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/226/galaxy_226.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:10,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:10,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:10,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:10,155 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:10,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:14,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8kj84 with k8s id: gxy-8kj84 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:56:14,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 226: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:56:21,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 226 finished
galaxy.model.metadata DEBUG 2024-11-24 06:56:21,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 312
galaxy.jobs INFO 2024-11-24 06:56:21,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 226 in /galaxy/server/database/jobs_directory/000/226
galaxy.jobs DEBUG 2024-11-24 06:56:21,988 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 226 executed (82.742 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:22,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 226 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:56:23,218 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 227
tpv.core.entities DEBUG 2024-11-24 06:56:23,238 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:56:23,239 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:56:23,242 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:56:23,250 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:56:23,260 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Working directory for job is: /galaxy/server/database/jobs_directory/000/227
galaxy.jobs.runners DEBUG 2024-11-24 06:56:23,266 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [227] queued (24.351 ms)
galaxy.jobs.handler INFO 2024-11-24 06:56:23,268 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (227) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:23,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 227
galaxy.jobs DEBUG 2024-11-24 06:56:23,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [227] prepared (63.102 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:56:23,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/227/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/227/registry.xml' '/galaxy/server/database/jobs_directory/000/227/upload_params.json' '313:/galaxy/server/database/objects/5/d/b/dataset_5db944b9-08b8-4595-9a63-cd96a1580c84_files:/galaxy/server/database/objects/5/d/b/dataset_5db944b9-08b8-4595-9a63-cd96a1580c84.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:56:23,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (227) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/227/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/227/galaxy_227.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:23,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:23,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:23,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:32,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pq2l7 with k8s id: gxy-pq2l7 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:56:33,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 227: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:56:39,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 227 finished
galaxy.model.metadata DEBUG 2024-11-24 06:56:39,984 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 313
galaxy.jobs INFO 2024-11-24 06:56:40,010 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 227 in /galaxy/server/database/jobs_directory/000/227
galaxy.jobs DEBUG 2024-11-24 06:56:40,048 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 227 executed (83.475 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:40,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 227 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:56:40,515 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 228
tpv.core.entities DEBUG 2024-11-24 06:56:40,535 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:56:40,536 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:56:40,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:56:40,546 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:56:40,557 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Working directory for job is: /galaxy/server/database/jobs_directory/000/228
galaxy.jobs.runners DEBUG 2024-11-24 06:56:40,563 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [228] queued (24.630 ms)
galaxy.jobs.handler INFO 2024-11-24 06:56:40,565 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (228) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:40,567 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 228
galaxy.jobs DEBUG 2024-11-24 06:56:40,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [228] prepared (41.949 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:40,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:40,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-24 06:56:40,631 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/228/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/5/d/b/dataset_5db944b9-08b8-4595-9a63-cd96a1580c84.dat --output=/galaxy/server/database/objects/3/2/a/dataset_32abcbc2-b48d-4f44-b409-325ca9ff4aec.dat --coverage=3 --format=ten --base=first --seq_column="None" --loc_column="None" --base_column="None" --cvrg_column="None"]
galaxy.jobs.runners DEBUG 2024-11-24 06:56:40,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (228) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/228/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/228/galaxy_228.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:40,653 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:40,659 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:56:40,659 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:40,676 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:40,975 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:45,037 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rq7jz with k8s id: gxy-rq7jz succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:56:45,138 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 228: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:56:51,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 228 finished
galaxy.model.metadata DEBUG 2024-11-24 06:56:51,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 314
galaxy.jobs INFO 2024-11-24 06:56:52,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 228 in /galaxy/server/database/jobs_directory/000/228
galaxy.jobs DEBUG 2024-11-24 06:56:52,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 228 executed (91.462 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:52,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 228 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:56:52,888 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 229
tpv.core.entities DEBUG 2024-11-24 06:56:52,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:56:52,909 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:56:52,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:56:52,921 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:56:52,931 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Working directory for job is: /galaxy/server/database/jobs_directory/000/229
galaxy.jobs.runners DEBUG 2024-11-24 06:56:52,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [229] queued (24.078 ms)
galaxy.jobs.handler INFO 2024-11-24 06:56:52,938 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (229) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:52,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 229
galaxy.jobs DEBUG 2024-11-24 06:56:53,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [229] prepared (63.288 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:56:53,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/229/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/229/registry.xml' '/galaxy/server/database/jobs_directory/000/229/upload_params.json' '315:/galaxy/server/database/objects/a/3/7/dataset_a3747c09-9c06-418b-8409-35467fdd103c_files:/galaxy/server/database/objects/a/3/7/dataset_a3747c09-9c06-418b-8409-35467fdd103c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:56:53,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (229) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/229/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/229/galaxy_229.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:53,045 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:53,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:56:54,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:03,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2glqx with k8s id: gxy-2glqx succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:57:03,261 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 229: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:57:10,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 229 finished
galaxy.model.metadata DEBUG 2024-11-24 06:57:10,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 315
galaxy.jobs INFO 2024-11-24 06:57:10,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 229 in /galaxy/server/database/jobs_directory/000/229
galaxy.jobs DEBUG 2024-11-24 06:57:10,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 229 executed (89.488 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:10,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 229 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:57:11,197 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 230
tpv.core.entities DEBUG 2024-11-24 06:57:11,220 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:57:11,220 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:57:11,224 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:57:11,233 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:57:11,244 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Working directory for job is: /galaxy/server/database/jobs_directory/000/230
galaxy.jobs.runners DEBUG 2024-11-24 06:57:11,251 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [230] queued (26.289 ms)
galaxy.jobs.handler INFO 2024-11-24 06:57:11,252 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (230) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:11,255 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 230
galaxy.jobs DEBUG 2024-11-24 06:57:11,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [230] prepared (45.830 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:11,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:11,308 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.command_factory INFO 2024-11-24 06:57:11,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/230/tool_script.sh] for tool command [python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/9c1c0b947e46/pileup_interval/pileup_interval.py' --input=/galaxy/server/database/objects/a/3/7/dataset_a3747c09-9c06-418b-8409-35467fdd103c.dat --output=/galaxy/server/database/objects/1/4/b/dataset_14b8ae08-6557-449b-9717-ab83c5980629.dat --coverage=3 --format=manual --base="None" --seq_column=1 --loc_column=2 --base_column=3 --cvrg_column=8]
galaxy.jobs.runners DEBUG 2024-11-24 06:57:11,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (230) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/230/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/230/galaxy_230.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:11,353 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:11,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:11,361 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [None]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:11,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:12,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:16,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qdl9d with k8s id: gxy-qdl9d succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:57:16,376 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 230: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:57:23,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 230 finished
galaxy.model.metadata DEBUG 2024-11-24 06:57:23,572 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 316
galaxy.jobs INFO 2024-11-24 06:57:23,598 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 230 in /galaxy/server/database/jobs_directory/000/230
galaxy.jobs DEBUG 2024-11-24 06:57:23,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 230 executed (79.428 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:23,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 230 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:57:26,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 232, 231
tpv.core.entities DEBUG 2024-11-24 06:57:26,497 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:57:26,498 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:57:26,501 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:57:26,511 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:57:26,523 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Working directory for job is: /galaxy/server/database/jobs_directory/000/231
galaxy.jobs.runners DEBUG 2024-11-24 06:57:26,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [231] queued (27.795 ms)
galaxy.jobs.handler INFO 2024-11-24 06:57:26,530 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (231) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,533 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 231
tpv.core.entities DEBUG 2024-11-24 06:57:26,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:57:26,542 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:57:26,547 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:57:26,559 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:57:26,584 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Working directory for job is: /galaxy/server/database/jobs_directory/000/232
galaxy.jobs.runners DEBUG 2024-11-24 06:57:26,593 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [232] queued (45.835 ms)
galaxy.jobs.handler INFO 2024-11-24 06:57:26,595 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (232) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,597 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 232
galaxy.jobs DEBUG 2024-11-24 06:57:26,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [231] prepared (93.584 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:57:26,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/231/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/231/registry.xml' '/galaxy/server/database/jobs_directory/000/231/upload_params.json' '317:/galaxy/server/database/objects/3/0/b/dataset_30b75404-a156-491e-a600-a070417098ec_files:/galaxy/server/database/objects/3/0/b/dataset_30b75404-a156-491e-a600-a070417098ec.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:57:26,670 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (231) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/231/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/231/galaxy_231.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 06:57:26,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [232] prepared (71.255 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,682 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,698 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:57:26,700 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/232/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/232/registry.xml' '/galaxy/server/database/jobs_directory/000/232/upload_params.json' '318:/galaxy/server/database/objects/e/1/5/dataset_e15664f6-8375-4453-9766-aa0f1b6a443f_files:/galaxy/server/database/objects/e/1/5/dataset_e15664f6-8375-4453-9766-aa0f1b6a443f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:57:26,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (232) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/232/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/232/galaxy_232.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:26,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:27,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:27,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:35,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jj9ff with k8s id: gxy-jj9ff succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:57:35,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 232: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:36,567 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cdnm2 with k8s id: gxy-cdnm2 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:57:36,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 231: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:57:43,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 232 finished
galaxy.model.metadata DEBUG 2024-11-24 06:57:43,097 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 318
galaxy.jobs INFO 2024-11-24 06:57:43,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 232 in /galaxy/server/database/jobs_directory/000/232
galaxy.jobs DEBUG 2024-11-24 06:57:43,156 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 232 executed (77.585 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:43,170 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 232 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:57:44,054 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 231 finished
galaxy.model.metadata DEBUG 2024-11-24 06:57:44,086 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 317
galaxy.jobs INFO 2024-11-24 06:57:44,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 231 in /galaxy/server/database/jobs_directory/000/231
galaxy.jobs DEBUG 2024-11-24 06:57:44,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 231 executed (88.637 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:44,169 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 231 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:57:44,878 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 233
tpv.core.entities DEBUG 2024-11-24 06:57:44,902 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:57:44,903 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:57:44,905 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:57:44,914 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:57:44,923 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Working directory for job is: /galaxy/server/database/jobs_directory/000/233
galaxy.jobs.runners DEBUG 2024-11-24 06:57:44,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [233] queued (24.348 ms)
galaxy.jobs.handler INFO 2024-11-24 06:57:44,932 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (233) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:44,934 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 233
galaxy.jobs DEBUG 2024-11-24 06:57:44,989 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [233] prepared (48.474 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:44,989 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:57:44,989 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:45,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:57:45,262 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/233/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/233/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/3/0/b/dataset_30b75404-a156-491e-a600-a070417098ec.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/2/d/9/metadata_2d95e8e1-ff22-42f7-8f2f-8bc32802b99a.dat' '0.bai' &&   samtools depth  -b '/galaxy/server/database/objects/e/1/5/dataset_e15664f6-8375-4453-9766-aa0f1b6a443f.dat' 0 > '/galaxy/server/database/objects/3/1/e/dataset_31e1b11c-52eb-46c0-b4e4-268289424e34.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:57:45,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (233) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/233/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/233/galaxy_233.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:45,292 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:45,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:57:45,300 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:57:45,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:45,345 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:45,589 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:57:53,692 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kr8tw with k8s id: gxy-kr8tw succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:57:53,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 233: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:58:00,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 233 finished
galaxy.model.metadata DEBUG 2024-11-24 06:58:00,734 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 319
galaxy.jobs INFO 2024-11-24 06:58:00,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 233 in /galaxy/server/database/jobs_directory/000/233
galaxy.jobs DEBUG 2024-11-24 06:58:00,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 233 executed (89.149 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:00,812 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 233 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:58:02,191 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 234
tpv.core.entities DEBUG 2024-11-24 06:58:02,216 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:02,216 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:02,220 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:02,229 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:02,243 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Working directory for job is: /galaxy/server/database/jobs_directory/000/234
galaxy.jobs.runners DEBUG 2024-11-24 06:58:02,249 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [234] queued (28.755 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:02,251 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (234) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:02,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 234
galaxy.jobs DEBUG 2024-11-24 06:58:02,324 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [234] prepared (64.030 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:58:02,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/234/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/234/registry.xml' '/galaxy/server/database/jobs_directory/000/234/upload_params.json' '320:/galaxy/server/database/objects/0/6/c/dataset_06cdf519-c71f-4472-b9fc-6493770a418d_files:/galaxy/server/database/objects/0/6/c/dataset_06cdf519-c71f-4472-b9fc-6493770a418d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:02,351 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (234) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/234/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/234/galaxy_234.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:02,362 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:02,374 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:02,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:11,849 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2mnhb with k8s id: gxy-2mnhb succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:58:11,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 234: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:58:19,169 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 234 finished
galaxy.model.metadata DEBUG 2024-11-24 06:58:19,207 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 320
galaxy.jobs INFO 2024-11-24 06:58:19,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 234 in /galaxy/server/database/jobs_directory/000/234
galaxy.jobs DEBUG 2024-11-24 06:58:19,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 234 executed (105.536 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:19,306 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 234 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:58:19,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 235
tpv.core.entities DEBUG 2024-11-24 06:58:19,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:19,545 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:19,548 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:19,557 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:19,570 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Working directory for job is: /galaxy/server/database/jobs_directory/000/235
galaxy.jobs.runners DEBUG 2024-11-24 06:58:19,579 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [235] queued (30.825 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:19,581 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (235) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:19,584 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 235
galaxy.jobs DEBUG 2024-11-24 06:58:19,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [235] prepared (42.438 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:19,635 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:58:19,636 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:19,661 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:58:19,683 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/235/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/235/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/0/6/c/dataset_06cdf519-c71f-4472-b9fc-6493770a418d.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/a/6/c/metadata_a6c1d643-9bd8-42d6-b110-788fd5f30d7e.dat' '0.bai' &&   samtools depth  -r eboVir3:500-1500 0 > '/galaxy/server/database/objects/0/c/a/dataset_0ca1065e-a7e8-4b12-bade-167875a96ac0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:19,698 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (235) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/235/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/235/galaxy_235.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:19,712 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:19,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:58:19,718 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:19,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:19,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:19,889 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:22,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-88mzt failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:22,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:22,969 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-88mzt.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:22,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 06:58:22,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-88mzt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-88mzt": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,004 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (235/gxy-88mzt) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (235/gxy-88mzt) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (235/gxy-88mzt) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (235/gxy-88mzt) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-88mzt.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Attempting to stop job 235 (gxy-88mzt)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Found job with id gxy-88mzt to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 235 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:23,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (235/gxy-88mzt) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 06:58:24,648 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 237, 236
tpv.core.entities DEBUG 2024-11-24 06:58:24,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:24,669 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:24,672 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:24,680 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:24,691 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Working directory for job is: /galaxy/server/database/jobs_directory/000/236
galaxy.jobs.runners DEBUG 2024-11-24 06:58:24,697 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [236] queued (25.148 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:24,699 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (236) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,701 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 236
tpv.core.entities DEBUG 2024-11-24 06:58:24,710 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:24,710 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:24,713 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:24,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:24,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Working directory for job is: /galaxy/server/database/jobs_directory/000/237
galaxy.jobs.runners DEBUG 2024-11-24 06:58:24,756 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [237] queued (42.833 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:24,759 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (237) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,763 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 237
galaxy.jobs DEBUG 2024-11-24 06:58:24,790 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [236] prepared (79.271 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:58:24,815 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/236/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/236/registry.xml' '/galaxy/server/database/jobs_directory/000/236/upload_params.json' '322:/galaxy/server/database/objects/2/f/e/dataset_2fe3fa9d-5591-4f56-9a79-893c7e609be5_files:/galaxy/server/database/objects/2/f/e/dataset_2fe3fa9d-5591-4f56-9a79-893c7e609be5.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:24,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (236) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/236/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/236/galaxy_236.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:58:24,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [237] prepared (68.462 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,849 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 06:58:24,855 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/237/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/237/registry.xml' '/galaxy/server/database/jobs_directory/000/237/upload_params.json' '323:/galaxy/server/database/objects/8/a/e/dataset_8aea611a-333b-4747-9df1-89f804530eb5_files:/galaxy/server/database/objects/8/a/e/dataset_8aea611a-333b-4747-9df1-89f804530eb5.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:24,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (237) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/237/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/237/galaxy_237.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,874 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:24,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:25,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:25,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:35,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-58qhl with k8s id: gxy-58qhl succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:35,408 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rvlkk with k8s id: gxy-rvlkk succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:58:35,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 236: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:58:35,517 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 237: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:58:42,842 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 237 finished
galaxy.model.metadata DEBUG 2024-11-24 06:58:42,877 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 323
galaxy.jobs.runners DEBUG 2024-11-24 06:58:42,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 236 finished
galaxy.jobs INFO 2024-11-24 06:58:42,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 237 in /galaxy/server/database/jobs_directory/000/237
galaxy.model.metadata DEBUG 2024-11-24 06:58:42,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 322
galaxy.jobs INFO 2024-11-24 06:58:42,964 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 236 in /galaxy/server/database/jobs_directory/000/236
galaxy.jobs DEBUG 2024-11-24 06:58:42,973 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 237 executed (114.138 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:42,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 237 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 06:58:43,012 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 236 executed (99.075 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:43,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 236 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:58:44,052 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 238
tpv.core.entities DEBUG 2024-11-24 06:58:44,078 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:44,079 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:44,083 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:44,093 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:44,106 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Working directory for job is: /galaxy/server/database/jobs_directory/000/238
galaxy.jobs.runners DEBUG 2024-11-24 06:58:44,114 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [238] queued (30.849 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:44,115 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (238) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:44,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 238
galaxy.jobs DEBUG 2024-11-24 06:58:44,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [238] prepared (48.765 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:44,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:58:44,172 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:44,196 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:58:44,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/238/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/238/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/2/f/e/dataset_2fe3fa9d-5591-4f56-9a79-893c7e609be5.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/d/2/3/metadata_d23aea3d-a2ee-4ac9-8cc6-e1d06ece5a1f.dat' '0.bai' && ln -s '/galaxy/server/database/objects/8/a/e/dataset_8aea611a-333b-4747-9df1-89f804530eb5.dat' '1' && ln -s '/galaxy/server/database/objects/_metadata_files/7/a/0/metadata_7a0fcf03-8ecc-4529-acbf-c6638c3af68d.dat' '1.bai' &&   samtools depth -a 0 1 > '/galaxy/server/database/objects/5/8/a/dataset_58a11e5e-a68d-4161-a2f1-4f7284a6edc1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:44,224 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (238) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/238/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/238/galaxy_238.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:44,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:44,237 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:58:44,237 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:58:44,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:44,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:44,446 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:48,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8p6b7 with k8s id: gxy-8p6b7 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:58:48,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 238: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:58:55,787 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 238 finished
galaxy.model.metadata DEBUG 2024-11-24 06:58:55,824 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 324
galaxy.jobs INFO 2024-11-24 06:58:55,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 238 in /galaxy/server/database/jobs_directory/000/238
galaxy.jobs DEBUG 2024-11-24 06:58:55,885 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 238 executed (80.258 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:55,896 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 238 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:58:57,412 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 239
tpv.core.entities DEBUG 2024-11-24 06:58:57,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:57,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:57,436 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:57,444 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:57,455 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Working directory for job is: /galaxy/server/database/jobs_directory/000/239
galaxy.jobs.runners DEBUG 2024-11-24 06:58:57,461 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [239] queued (24.927 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:57,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (239) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:57,466 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 239
galaxy.jobs DEBUG 2024-11-24 06:58:57,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [239] prepared (65.915 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:58:57,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/239/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/239/registry.xml' '/galaxy/server/database/jobs_directory/000/239/upload_params.json' '325:/galaxy/server/database/objects/0/a/1/dataset_0a1c6239-6989-4e33-9dcd-8997303d81c5_files:/galaxy/server/database/objects/0/a/1/dataset_0a1c6239-6989-4e33-9dcd-8997303d81c5.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:57,566 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (239) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/239/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/239/galaxy_239.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:57,579 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:57,590 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:58:58,467 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 240
tpv.core.entities DEBUG 2024-11-24 06:58:58,488 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:58:58,488 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:58:58,491 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:58:58,499 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:58:58,512 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Working directory for job is: /galaxy/server/database/jobs_directory/000/240
galaxy.jobs.runners DEBUG 2024-11-24 06:58:58,520 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [240] queued (28.097 ms)
galaxy.jobs.handler INFO 2024-11-24 06:58:58,522 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (240) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:58,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 240
galaxy.jobs DEBUG 2024-11-24 06:58:58,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [240] prepared (61.948 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:58:58,609 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/240/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/240/registry.xml' '/galaxy/server/database/jobs_directory/000/240/upload_params.json' '326:/galaxy/server/database/objects/8/6/7/dataset_8674302a-4d8b-46c9-95b2-2f39ed63b2ab_files:/galaxy/server/database/objects/8/6/7/dataset_8674302a-4d8b-46c9-95b2-2f39ed63b2ab.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:58:58,617 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (240) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/240/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/240/galaxy_240.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:58,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:58,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:58,776 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:58:59,826 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:06,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g6549 with k8s id: gxy-g6549 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:59:07,083 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 239: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:09,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wfgvm with k8s id: gxy-wfgvm succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:59:09,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 240: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:59:14,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 239 finished
galaxy.model.metadata DEBUG 2024-11-24 06:59:14,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 325
galaxy.jobs INFO 2024-11-24 06:59:14,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 239 in /galaxy/server/database/jobs_directory/000/239
galaxy.jobs DEBUG 2024-11-24 06:59:14,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 239 executed (101.527 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:14,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 239 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 06:59:16,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 240 finished
galaxy.model.metadata DEBUG 2024-11-24 06:59:16,382 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 326
galaxy.jobs INFO 2024-11-24 06:59:16,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 240 in /galaxy/server/database/jobs_directory/000/240
galaxy.jobs DEBUG 2024-11-24 06:59:16,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 240 executed (100.866 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:16,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 240 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:59:16,925 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 241
tpv.core.entities DEBUG 2024-11-24 06:59:16,950 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:59:16,950 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:59:16,953 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:59:16,961 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:59:16,972 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Working directory for job is: /galaxy/server/database/jobs_directory/000/241
galaxy.jobs.runners DEBUG 2024-11-24 06:59:16,981 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [241] queued (27.468 ms)
galaxy.jobs.handler INFO 2024-11-24 06:59:16,983 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (241) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:16,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 241
galaxy.jobs DEBUG 2024-11-24 06:59:17,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [241] prepared (47.507 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:17,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:59:17,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:17,062 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:59:17,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/241/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/241/outputs/COMMAND_VERSION 2>&1;
ln -s '/galaxy/server/database/objects/0/a/1/dataset_0a1c6239-6989-4e33-9dcd-8997303d81c5.dat' '0' && ln -s '/galaxy/server/database/objects/_metadata_files/a/f/c/metadata_afc5ae51-bc1b-43b3-9f90-fabacad9c830.dat' '0.bai' && ln -s '/galaxy/server/database/objects/8/6/7/dataset_8674302a-4d8b-46c9-95b2-2f39ed63b2ab.dat' '1' && ln -s '/galaxy/server/database/objects/_metadata_files/7/9/c/metadata_79c8dcd3-4e98-4565-8433-018f29413a5a.dat' '1.bai' &&   samtools depth  -l 10 -m 4 -q 11 -Q 12 0 1 > '/galaxy/server/database/objects/9/0/8/dataset_90836cd2-9c07-4c9f-ac5d-8b2aad9110ef.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:59:17,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (241) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/241/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/241/galaxy_241.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:17,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:17,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:59:17,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.9: samtools:1.9
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:17,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.9--h10a08f8_12,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:17,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:18,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:21,093 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rbh9b with k8s id: gxy-rbh9b succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:59:21,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 241: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:59:28,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 241 finished
galaxy.model.metadata DEBUG 2024-11-24 06:59:28,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 327
galaxy.jobs INFO 2024-11-24 06:59:28,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 241 in /galaxy/server/database/jobs_directory/000/241
galaxy.jobs DEBUG 2024-11-24 06:59:28,443 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 241 executed (84.802 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:28,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 241 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:59:31,208 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 242
tpv.core.entities DEBUG 2024-11-24 06:59:31,228 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:59:31,228 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:59:31,231 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:59:31,241 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:59:31,252 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Working directory for job is: /galaxy/server/database/jobs_directory/000/242
galaxy.jobs.runners DEBUG 2024-11-24 06:59:31,259 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [242] queued (27.359 ms)
galaxy.jobs.handler INFO 2024-11-24 06:59:31,261 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (242) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:31,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 242
galaxy.jobs DEBUG 2024-11-24 06:59:31,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [242] prepared (57.869 ms)
galaxy.jobs.command_factory INFO 2024-11-24 06:59:31,343 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/242/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/242/registry.xml' '/galaxy/server/database/jobs_directory/000/242/upload_params.json' '328:/galaxy/server/database/objects/4/a/2/dataset_4a2169dd-57f4-4037-bef7-d46dc967e94b_files:/galaxy/server/database/objects/4/a/2/dataset_4a2169dd-57f4-4037-bef7-d46dc967e94b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:59:31,352 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (242) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/242/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/242/galaxy_242.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:31,363 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:31,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:32,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:41,242 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gnr46 with k8s id: gxy-gnr46 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:59:41,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 242: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 06:59:48,287 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 242 finished
galaxy.model.metadata DEBUG 2024-11-24 06:59:48,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 328
galaxy.jobs INFO 2024-11-24 06:59:48,356 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 242 in /galaxy/server/database/jobs_directory/000/242
galaxy.jobs DEBUG 2024-11-24 06:59:48,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 242 executed (87.363 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:48,403 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 242 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 06:59:49,552 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 243
tpv.core.entities DEBUG 2024-11-24 06:59:49,578 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/.*, abstract=False, cores=1, mem=7.6, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 06:59:49,578 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 06:59:49,582 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 06:59:49,591 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 06:59:49,602 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Working directory for job is: /galaxy/server/database/jobs_directory/000/243
galaxy.jobs.runners DEBUG 2024-11-24 06:59:49,610 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [243] queued (27.700 ms)
galaxy.jobs.handler INFO 2024-11-24 06:59:49,612 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (243) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:49,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 243
galaxy.jobs DEBUG 2024-11-24 06:59:49,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [243] prepared (33.252 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:49,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:59:49,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/2.0.1: samtools:1.3.1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:49,676 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.3.1--h0cf4675_11,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 06:59:49,695 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/243/tool_script.sh] for tool command [samtools 2>&1 | grep Version > /galaxy/server/database/jobs_directory/000/243/outputs/COMMAND_VERSION 2>&1;
samtools rmdup  '/galaxy/server/database/objects/4/a/2/dataset_4a2169dd-57f4-4037-bef7-d46dc967e94b.dat' '/galaxy/server/database/objects/2/d/f/dataset_2dfb4c74-d5a1-4ef6-90ed-5791a0001302.dat']
galaxy.jobs.runners DEBUG 2024-11-24 06:59:49,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (243) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/243/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/243/galaxy_243.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:49,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:49,727 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 06:59:49,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/samtools_rmdup/samtools_rmdup/2.0.1: samtools:1.3.1
galaxy.tool_util.deps.containers INFO 2024-11-24 06:59:49,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/samtools:1.3.1--h0cf4675_11,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:49,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:50,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 06:59:56,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wxd67 with k8s id: gxy-wxd67 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 06:59:56,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 243: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:00:03,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 243 finished
galaxy.model.metadata DEBUG 2024-11-24 07:00:03,641 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 329
galaxy.jobs INFO 2024-11-24 07:00:03,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 243 in /galaxy/server/database/jobs_directory/000/243
galaxy.jobs DEBUG 2024-11-24 07:00:03,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 243 executed (98.535 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:03,734 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 243 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:00:06,887 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 244, 245
tpv.core.entities DEBUG 2024-11-24 07:00:06,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:00:06,913 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:00:06,916 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:00:06,928 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:00:06,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Working directory for job is: /galaxy/server/database/jobs_directory/000/244
galaxy.jobs.runners DEBUG 2024-11-24 07:00:06,947 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [244] queued (30.970 ms)
galaxy.jobs.handler INFO 2024-11-24 07:00:06,950 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (244) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:06,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 244
tpv.core.entities DEBUG 2024-11-24 07:00:06,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:00:06,960 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:00:06,964 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:00:06,975 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:00:07,000 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Working directory for job is: /galaxy/server/database/jobs_directory/000/245
galaxy.jobs.runners DEBUG 2024-11-24 07:00:07,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [245] queued (43.653 ms)
galaxy.jobs.handler INFO 2024-11-24 07:00:07,010 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (245) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 245
galaxy.jobs DEBUG 2024-11-24 07:00:07,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [244] prepared (94.887 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:00:07,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/244/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/244/registry.xml' '/galaxy/server/database/jobs_directory/000/244/upload_params.json' '330:/galaxy/server/database/objects/b/5/5/dataset_b55b616a-493b-441e-b25a-71375e14f45c_files:/galaxy/server/database/objects/b/5/5/dataset_b55b616a-493b-441e-b25a-71375e14f45c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:00:07,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (244) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/244/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/244/galaxy_244.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:00:07,097 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [245] prepared (73.036 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,104 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,116 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:00:07,117 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/245/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/245/registry.xml' '/galaxy/server/database/jobs_directory/000/245/upload_params.json' '331:/galaxy/server/database/objects/a/5/1/dataset_a51e689a-cef7-4f30-a91a-efd734d76a64_files:/galaxy/server/database/objects/a/5/1/dataset_a51e689a-cef7-4f30-a91a-efd734d76a64.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:00:07,126 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (245) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/245/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/245/galaxy_245.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,154 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:07,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:16,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-z7s4k with k8s id: gxy-z7s4k succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:16,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qtzfh with k8s id: gxy-qtzfh succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:00:16,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 245: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:00:16,869 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 244: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:00:24,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 244 finished
galaxy.model.metadata DEBUG 2024-11-24 07:00:24,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 330
galaxy.jobs.runners DEBUG 2024-11-24 07:00:24,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 245 finished
galaxy.jobs INFO 2024-11-24 07:00:24,277 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 244 in /galaxy/server/database/jobs_directory/000/244
galaxy.model.metadata DEBUG 2024-11-24 07:00:24,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 331
galaxy.jobs INFO 2024-11-24 07:00:24,330 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 245 in /galaxy/server/database/jobs_directory/000/245
galaxy.jobs DEBUG 2024-11-24 07:00:24,341 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 244 executed (110.188 ms)
galaxy.jobs DEBUG 2024-11-24 07:00:24,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 245 executed (92.514 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:24,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 244 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:24,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 245 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:00:25,353 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 246
tpv.core.entities DEBUG 2024-11-24 07:00:25,381 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:00:25,381 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:00:25,384 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:00:25,393 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:00:25,404 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Working directory for job is: /galaxy/server/database/jobs_directory/000/246
galaxy.jobs.runners DEBUG 2024-11-24 07:00:25,411 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [246] queued (26.978 ms)
galaxy.jobs.handler INFO 2024-11-24 07:00:25,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (246) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:25,415 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 246
galaxy.jobs DEBUG 2024-11-24 07:00:25,460 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [246] prepared (38.844 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:00:25,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:00:25,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:00:25,640 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:00:25,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/246/tool_script.sh] for tool command [python -c "import anndata as ad;print('anndata version: %s' % ad.__version__); import loompy;print('\nloompy version: %s' % loompy.__version__)" > /galaxy/server/database/jobs_directory/000/246/outputs/COMMAND_VERSION 2>&1;
cp '/galaxy/server/database/objects/b/5/5/dataset_b55b616a-493b-441e-b25a-71375e14f45c.dat' loom_add_out.loom && python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/05631436cdf1/modify_loom/modify_loom.py' -f 'loom_add_out.loom' -a cols -c '/galaxy/server/database/objects/a/5/1/dataset_a51e689a-cef7-4f30-a91a-efd734d76a64.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:00:25,675 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (246) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/246/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/246/galaxy_246.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/246/working/loom_add_out.loom" -a -f "/galaxy/server/database/objects/4/b/d/dataset_4bde678c-34a5-4416-ac21-5f18a39f89e3.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/246/working/loom_add_out.loom" "/galaxy/server/database/objects/4/b/d/dataset_4bde678c-34a5-4416-ac21-5f18a39f89e3.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:25,689 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:00:25,695 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:00:25,695 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:00:25,712 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:25,733 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:26,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:41,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tqjhh with k8s id: gxy-tqjhh succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:00:42,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 246: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:00:49,121 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 246 finished
galaxy.model.metadata DEBUG 2024-11-24 07:00:49,160 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 332
galaxy.util WARNING 2024-11-24 07:00:49,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/4/b/d/dataset_4bde678c-34a5-4416-ac21-5f18a39f89e3.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/4/b/d/dataset_4bde678c-34a5-4416-ac21-5f18a39f89e3.dat'
galaxy.jobs INFO 2024-11-24 07:00:49,188 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 246 in /galaxy/server/database/jobs_directory/000/246
galaxy.jobs DEBUG 2024-11-24 07:00:49,225 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 246 executed (89.266 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:49,240 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 246 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:00:50,904 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 248, 247
tpv.core.entities DEBUG 2024-11-24 07:00:50,926 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:00:50,927 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:00:50,930 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:00:50,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:00:50,949 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Working directory for job is: /galaxy/server/database/jobs_directory/000/247
galaxy.jobs.runners DEBUG 2024-11-24 07:00:50,954 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [247] queued (24.521 ms)
galaxy.jobs.handler INFO 2024-11-24 07:00:50,956 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (247) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:50,958 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 247
tpv.core.entities DEBUG 2024-11-24 07:00:50,964 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:00:50,964 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:00:50,967 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:00:50,976 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:00:51,000 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Working directory for job is: /galaxy/server/database/jobs_directory/000/248
galaxy.jobs.runners DEBUG 2024-11-24 07:00:51,008 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [248] queued (41.336 ms)
galaxy.jobs.handler INFO 2024-11-24 07:00:51,010 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (248) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 248
galaxy.jobs DEBUG 2024-11-24 07:00:51,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [247] prepared (89.960 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:00:51,077 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/247/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/247/registry.xml' '/galaxy/server/database/jobs_directory/000/247/upload_params.json' '333:/galaxy/server/database/objects/b/f/4/dataset_bf4272de-2325-40bb-94af-37dc99749099_files:/galaxy/server/database/objects/b/f/4/dataset_bf4272de-2325-40bb-94af-37dc99749099.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:00:51,085 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (247) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/247/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/247/galaxy_247.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:00:51,097 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [248] prepared (72.423 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,100 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:00:51,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/248/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/248/registry.xml' '/galaxy/server/database/jobs_directory/000/248/upload_params.json' '334:/galaxy/server/database/objects/7/7/8/dataset_7787fffb-2c21-4463-8679-a7757a2feb5c_files:/galaxy/server/database/objects/7/7/8/dataset_7787fffb-2c21-4463-8679-a7757a2feb5c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:00:51,124 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (248) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/248/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/248/galaxy_248.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,135 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,149 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:51,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:00:52,035 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:00,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-8qfq6 with k8s id: gxy-8qfq6 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:00,228 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-s96hx with k8s id: gxy-s96hx succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:01:00,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 247: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:01:00,349 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 248: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:01:07,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 247 finished
galaxy.jobs.runners DEBUG 2024-11-24 07:01:07,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 248 finished
galaxy.model.metadata DEBUG 2024-11-24 07:01:07,802 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 333
galaxy.jobs INFO 2024-11-24 07:01:07,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 247 in /galaxy/server/database/jobs_directory/000/247
galaxy.model.metadata DEBUG 2024-11-24 07:01:07,846 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 334
galaxy.jobs INFO 2024-11-24 07:01:07,875 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 248 in /galaxy/server/database/jobs_directory/000/248
galaxy.jobs DEBUG 2024-11-24 07:01:07,890 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 247 executed (112.277 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:07,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 247 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 07:01:07,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 248 executed (100.498 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:07,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 248 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:01:08,385 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 249
tpv.core.entities DEBUG 2024-11-24 07:01:08,406 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:01:08,407 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:01:08,410 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:01:08,417 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:01:08,426 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Working directory for job is: /galaxy/server/database/jobs_directory/000/249
galaxy.jobs.runners DEBUG 2024-11-24 07:01:08,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [249] queued (23.273 ms)
galaxy.jobs.handler INFO 2024-11-24 07:01:08,435 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (249) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:08,437 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 249
galaxy.jobs DEBUG 2024-11-24 07:01:08,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [249] prepared (31.778 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:08,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:01:08,475 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:08,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:01:08,677 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/249/tool_script.sh] for tool command [python -c "import anndata as ad;print('anndata version: %s' % ad.__version__); import loompy;print('\nloompy version: %s' % loompy.__version__)" > /galaxy/server/database/jobs_directory/000/249/outputs/COMMAND_VERSION 2>&1;
cp '/galaxy/server/database/objects/b/f/4/dataset_bf4272de-2325-40bb-94af-37dc99749099.dat' loom_add_out.loom && python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/05631436cdf1/modify_loom/modify_loom.py' -f 'loom_add_out.loom']
galaxy.jobs.runners DEBUG 2024-11-24 07:01:08,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (249) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/249/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/249/galaxy_249.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/249/working/loom_add_out.loom" -a -f "/galaxy/server/database/objects/4/f/3/dataset_4f38ea9e-6453-4b4f-b163-26d3c3074c0a.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/249/working/loom_add_out.loom" "/galaxy/server/database/objects/4/f/3/dataset_4f38ea9e-6453-4b4f-b163-26d3c3074c0a.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:08,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:08,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:01:08,708 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:08,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:08,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:09,327 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jpn96 failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-jpn96.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 07:01:13,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-jpn96

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-jpn96": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,480 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249/gxy-jpn96) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249/gxy-jpn96) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249/gxy-jpn96) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249/gxy-jpn96) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-jpn96.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,485 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 249 (gxy-jpn96)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,496 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-jpn96 to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,498 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 249 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:13,566 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (249/gxy-jpn96) Terminated at user's request
galaxy.util WARNING 2024-11-24 07:01:13,591 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/4/f/3/dataset_4f38ea9e-6453-4b4f-b163-26d3c3074c0a.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/4/f/3/dataset_4f38ea9e-6453-4b4f-b163-26d3c3074c0a.dat'
galaxy.jobs.handler DEBUG 2024-11-24 07:01:14,517 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 250
tpv.core.entities DEBUG 2024-11-24 07:01:14,537 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:01:14,537 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:01:14,540 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:01:14,549 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:01:14,561 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Working directory for job is: /galaxy/server/database/jobs_directory/000/250
galaxy.jobs.runners DEBUG 2024-11-24 07:01:14,568 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [250] queued (28.115 ms)
galaxy.jobs.handler INFO 2024-11-24 07:01:14,571 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (250) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:14,572 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 250
galaxy.jobs DEBUG 2024-11-24 07:01:14,638 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [250] prepared (59.375 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:01:14,655 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/250/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/250/registry.xml' '/galaxy/server/database/jobs_directory/000/250/upload_params.json' '336:/galaxy/server/database/objects/7/8/8/dataset_78874513-9357-4f42-a227-8b3226c2078d_files:/galaxy/server/database/objects/7/8/8/dataset_78874513-9357-4f42-a227-8b3226c2078d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:01:14,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (250) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/250/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/250/galaxy_250.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:14,676 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:14,688 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:15,496 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 07:01:15,575 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 251
tpv.core.entities DEBUG 2024-11-24 07:01:15,595 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:01:15,596 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:01:15,599 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:01:15,608 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:01:15,621 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Working directory for job is: /galaxy/server/database/jobs_directory/000/251
galaxy.jobs.runners DEBUG 2024-11-24 07:01:15,627 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [251] queued (28.458 ms)
galaxy.jobs.handler INFO 2024-11-24 07:01:15,630 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (251) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:15,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 251
galaxy.jobs DEBUG 2024-11-24 07:01:15,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [251] prepared (67.092 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:01:15,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/251/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/251/registry.xml' '/galaxy/server/database/jobs_directory/000/251/upload_params.json' '337:/galaxy/server/database/objects/1/5/8/dataset_158be05c-00cd-40a8-8b52-61b426d499a8_files:/galaxy/server/database/objects/1/5/8/dataset_158be05c-00cd-40a8-8b52-61b426d499a8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:01:15,732 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (251) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/251/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/251/galaxy_251.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:15,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:15,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:16,554 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:24,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-pm99h with k8s id: gxy-pm99h succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:01:24,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 250: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:25,770 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-jzkkk with k8s id: gxy-jzkkk succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:01:25,886 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 251: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:01:31,977 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 250 finished
galaxy.model.metadata DEBUG 2024-11-24 07:01:32,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 336
galaxy.jobs INFO 2024-11-24 07:01:32,040 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 250 in /galaxy/server/database/jobs_directory/000/250
galaxy.jobs DEBUG 2024-11-24 07:01:32,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 250 executed (137.768 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:32,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 250 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:01:33,084 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 251 finished
galaxy.model.metadata DEBUG 2024-11-24 07:01:33,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 337
galaxy.jobs INFO 2024-11-24 07:01:33,138 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 251 in /galaxy/server/database/jobs_directory/000/251
galaxy.jobs DEBUG 2024-11-24 07:01:33,179 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 251 executed (80.209 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:33,190 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 251 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:01:33,912 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 252
tpv.core.entities DEBUG 2024-11-24 07:01:33,935 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:01:33,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:01:33,939 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:01:33,948 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:01:33,960 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Working directory for job is: /galaxy/server/database/jobs_directory/000/252
galaxy.jobs.runners DEBUG 2024-11-24 07:01:33,968 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [252] queued (28.417 ms)
galaxy.jobs.handler INFO 2024-11-24 07:01:33,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (252) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:33,971 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 252
galaxy.jobs DEBUG 2024-11-24 07:01:34,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [252] prepared (37.108 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:34,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:01:34,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:34,035 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:01:34,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/252/tool_script.sh] for tool command [python -c "import anndata as ad;print('anndata version: %s' % ad.__version__); import loompy;print('\nloompy version: %s' % loompy.__version__)" > /galaxy/server/database/jobs_directory/000/252/outputs/COMMAND_VERSION 2>&1;
cp '/galaxy/server/database/objects/7/8/8/dataset_78874513-9357-4f42-a227-8b3226c2078d.dat' loom_add_out.loom && python '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/05631436cdf1/modify_loom/modify_loom.py' -f 'loom_add_out.loom' -a layers -l '/galaxy/server/database/objects/1/5/8/dataset_158be05c-00cd-40a8-8b52-61b426d499a8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:01:34,063 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (252) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/252/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/252/galaxy_252.ec; 
if [ -f "/galaxy/server/database/jobs_directory/000/252/working/loom_add_out.loom" -a -f "/galaxy/server/database/objects/3/d/8/dataset_3d8ac502-1ec3-4a75-888c-7186b9ce935c.dat" ] ; then cp "/galaxy/server/database/jobs_directory/000/252/working/loom_add_out.loom" "/galaxy/server/database/objects/3/d/8/dataset_3d8ac502-1ec3-4a75-888c-7186b9ce935c.dat" ; fi; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:34,075 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:34,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:01:34,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/modify_loom/modify_loom/0.7.5+galaxy1: mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d
galaxy.tool_util.deps.containers INFO 2024-11-24 07:01:34,095 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-61fb942689aeef789decdfc6589cc2be67326474:0102e9b7b1e5f4c343a80f24e8371bc683d6111d-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:34,115 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:34,795 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:39,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-c2b6b with k8s id: gxy-c2b6b succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:01:39,991 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 252: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:01:47,166 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 252 finished
galaxy.model.metadata DEBUG 2024-11-24 07:01:47,211 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 338
galaxy.util WARNING 2024-11-24 07:01:47,213 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/3/d/8/dataset_3d8ac502-1ec3-4a75-888c-7186b9ce935c.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/3/d/8/dataset_3d8ac502-1ec3-4a75-888c-7186b9ce935c.dat'
galaxy.jobs INFO 2024-11-24 07:01:47,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 252 in /galaxy/server/database/jobs_directory/000/252
galaxy.jobs DEBUG 2024-11-24 07:01:47,267 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 252 executed (84.209 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:47,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 252 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:01:50,233 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 253
tpv.core.entities DEBUG 2024-11-24 07:01:50,255 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:01:50,255 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:01:50,258 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:01:50,267 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:01:50,278 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Working directory for job is: /galaxy/server/database/jobs_directory/000/253
galaxy.jobs.runners DEBUG 2024-11-24 07:01:50,284 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [253] queued (26.129 ms)
galaxy.jobs.handler INFO 2024-11-24 07:01:50,286 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (253) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:50,288 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 253
galaxy.jobs DEBUG 2024-11-24 07:01:50,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [253] prepared (75.526 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:01:50,391 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/253/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/253/registry.xml' '/galaxy/server/database/jobs_directory/000/253/upload_params.json' '339:/galaxy/server/database/objects/f/c/f/dataset_fcf46c74-16b4-4a9f-be55-8950f1d8120c_files:/galaxy/server/database/objects/f/c/f/dataset_fcf46c74-16b4-4a9f-be55-8950f1d8120c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:01:50,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (253) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/253/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/253/galaxy_253.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:50,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:50,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:01:50,911 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:00,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-kmx6b with k8s id: gxy-kmx6b succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:02:00,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 253: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:02:07,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 253 finished
galaxy.model.metadata DEBUG 2024-11-24 07:02:07,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 339
galaxy.jobs INFO 2024-11-24 07:02:07,348 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 253 in /galaxy/server/database/jobs_directory/000/253
galaxy.jobs DEBUG 2024-11-24 07:02:07,384 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 253 executed (80.194 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:07,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 253 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:02:08,581 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 254
tpv.core.entities DEBUG 2024-11-24 07:02:08,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:02:08,607 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:02:08,610 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:02:08,621 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:02:08,634 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Working directory for job is: /galaxy/server/database/jobs_directory/000/254
galaxy.jobs.runners DEBUG 2024-11-24 07:02:08,643 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [254] queued (32.521 ms)
galaxy.jobs.handler INFO 2024-11-24 07:02:08,645 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (254) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:08,647 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 254
galaxy.jobs DEBUG 2024-11-24 07:02:08,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [254] prepared (38.895 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:02:08,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:02:08,694 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/scater_plot_tsne/1.22.0: mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057
galaxy.tool_util.deps.containers INFO 2024-11-24 07:02:08,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:02:08,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/254/tool_script.sh] for tool command [Rscript '/cvmfs/cloud.galaxyproject.org/tools/toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/99f912d5af9f/scater_plot_tsne/scater-plot-tsne.R' -i '/galaxy/server/database/objects/f/c/f/dataset_fcf46c74-16b4-4a9f-be55-8950f1d8120c.dat' --colour-by 'Treatment' --shape-by 'Mutation_Status' -o '/galaxy/server/database/objects/5/3/1/dataset_531ecf3d-f227-42f5-9d6e-5367b97d7b76.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:02:08,928 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (254) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/254/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/254/galaxy_254.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:08,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:02:08,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:02:08,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/scater_plot_tsne/scater_plot_tsne/1.22.0: mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057
galaxy.tool_util.deps.containers INFO 2024-11-24 07:02:08,966 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-e13023c8593d24824dd3fac34c8bd64338108543:66a209fb455058282232dc7688fd6ceb6b331057-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:08,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:10,092 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:46,726 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cqjfx with k8s id: gxy-cqjfx succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:02:46,840 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 254: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:02:54,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 254 finished
galaxy.model.metadata DEBUG 2024-11-24 07:02:54,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 340
galaxy.jobs INFO 2024-11-24 07:02:54,070 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 254 in /galaxy/server/database/jobs_directory/000/254
galaxy.jobs DEBUG 2024-11-24 07:02:54,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 254 executed (85.285 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:02:54,119 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 254 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:03:01,501 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 256, 255
tpv.core.entities DEBUG 2024-11-24 07:03:01,526 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:03:01,526 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:03:01,529 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:03:01,538 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:03:01,551 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Working directory for job is: /galaxy/server/database/jobs_directory/000/255
galaxy.jobs.runners DEBUG 2024-11-24 07:03:01,558 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [255] queued (29.111 ms)
galaxy.jobs.handler INFO 2024-11-24 07:03:01,562 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (255) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,562 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 255
tpv.core.entities DEBUG 2024-11-24 07:03:01,573 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:03:01,574 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:03:01,578 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:03:01,590 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:03:01,616 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Working directory for job is: /galaxy/server/database/jobs_directory/000/256
galaxy.jobs.runners DEBUG 2024-11-24 07:03:01,624 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [256] queued (45.590 ms)
galaxy.jobs.handler INFO 2024-11-24 07:03:01,629 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (256) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,630 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 256
galaxy.jobs DEBUG 2024-11-24 07:03:01,673 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [255] prepared (98.178 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:03:01,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/255/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/255/registry.xml' '/galaxy/server/database/jobs_directory/000/255/upload_params.json' '341:/galaxy/server/database/objects/0/d/7/dataset_0d7be167-56fa-4c12-9fe0-425fd2e5e168_files:/galaxy/server/database/objects/0/d/7/dataset_0d7be167-56fa-4c12-9fe0-425fd2e5e168.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:03:01,703 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (255) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/255/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/255/galaxy_255.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:03:01,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [256] prepared (73.936 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,737 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:03:01,741 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/256/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/256/registry.xml' '/galaxy/server/database/jobs_directory/000/256/upload_params.json' '342:/galaxy/server/database/objects/2/d/b/dataset_2dbb91e1-cc06-4d32-a4b3-ec8172514c68_files:/galaxy/server/database/objects/2/d/b/dataset_2dbb91e1-cc06-4d32-a4b3-ec8172514c68.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:03:01,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (256) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/256/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/256/galaxy_256.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:01,796 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:02,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:02,795 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:10,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-4swj5 with k8s id: gxy-4swj5 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:03:11,103 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 256: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:12,007 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-cdlql with k8s id: gxy-cdlql succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:03:12,160 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 255: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:03:18,898 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 256 finished
galaxy.model.metadata DEBUG 2024-11-24 07:03:18,946 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 342
galaxy.jobs INFO 2024-11-24 07:03:18,976 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 256 in /galaxy/server/database/jobs_directory/000/256
galaxy.jobs DEBUG 2024-11-24 07:03:19,023 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 256 executed (105.515 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:19,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 256 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:03:19,748 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 255 finished
galaxy.model.metadata DEBUG 2024-11-24 07:03:19,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 341
galaxy.jobs INFO 2024-11-24 07:03:19,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 255 in /galaxy/server/database/jobs_directory/000/255
galaxy.jobs DEBUG 2024-11-24 07:03:19,844 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 255 executed (80.091 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:19,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 255 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:03:20,954 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 257
tpv.core.entities DEBUG 2024-11-24 07:03:20,979 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:03:20,979 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:03:20,982 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:03:20,991 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:03:21,002 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Working directory for job is: /galaxy/server/database/jobs_directory/000/257
galaxy.jobs.runners DEBUG 2024-11-24 07:03:21,009 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [257] queued (26.638 ms)
galaxy.jobs.handler INFO 2024-11-24 07:03:21,011 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (257) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:21,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 257
galaxy.jobs DEBUG 2024-11-24 07:03:21,087 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [257] prepared (67.450 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:03:21,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:03:21,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:03:21,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:03:21,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/257/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/257/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/2/d/b/dataset_2dbb91e1-cc06-4d32-a4b3-ec8172514c68.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/0/d/7/dataset_0d7be167-56fa-4c12-9fe0-425fd2e5e168.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/4/5/0/metadata_450c8b4d-4764-4698-903b-756880c42be7.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/1/4/1/dataset_1415ad09-a609-4715-9e7a-c18b41a5da5e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:03:21,290 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (257) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/257/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/257/galaxy_257.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:21,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:03:21,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:03:21,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:03:21,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:21,339 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:22,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:33,214 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qnjfz with k8s id: gxy-qnjfz succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:03:33,319 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 257: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:03:40,269 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 257 finished
galaxy.model.metadata DEBUG 2024-11-24 07:03:40,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 343
galaxy.jobs INFO 2024-11-24 07:03:40,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 257 in /galaxy/server/database/jobs_directory/000/257
galaxy.jobs DEBUG 2024-11-24 07:03:40,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 257 executed (101.607 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:40,404 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 257 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:03:41,354 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 258
tpv.core.entities DEBUG 2024-11-24 07:03:41,378 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:03:41,379 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:03:41,382 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:03:41,395 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:03:41,406 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Working directory for job is: /galaxy/server/database/jobs_directory/000/258
galaxy.jobs.runners DEBUG 2024-11-24 07:03:41,413 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [258] queued (30.867 ms)
galaxy.jobs.handler INFO 2024-11-24 07:03:41,415 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (258) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:41,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 258
galaxy.jobs DEBUG 2024-11-24 07:03:41,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [258] prepared (62.278 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:03:41,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/258/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/258/registry.xml' '/galaxy/server/database/jobs_directory/000/258/upload_params.json' '344:/galaxy/server/database/objects/7/e/5/dataset_7e5db5ca-badf-4652-9d92-c89a399e3fce_files:/galaxy/server/database/objects/7/e/5/dataset_7e5db5ca-badf-4652-9d92-c89a399e3fce.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:03:41,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (258) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/258/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/258/galaxy_258.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:41,523 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:41,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:42,238 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 07:03:42,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 259
tpv.core.entities DEBUG 2024-11-24 07:03:42,441 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:03:42,442 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:03:42,446 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:03:42,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:03:42,468 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Working directory for job is: /galaxy/server/database/jobs_directory/000/259
galaxy.jobs.runners DEBUG 2024-11-24 07:03:42,474 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [259] queued (28.731 ms)
galaxy.jobs.handler INFO 2024-11-24 07:03:42,477 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (259) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:42,478 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 259
galaxy.jobs DEBUG 2024-11-24 07:03:42,546 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [259] prepared (62.387 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:03:42,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/259/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/259/registry.xml' '/galaxy/server/database/jobs_directory/000/259/upload_params.json' '345:/galaxy/server/database/objects/b/a/d/dataset_bad2b1b0-d3c6-4b80-9659-3fdccf63713e_files:/galaxy/server/database/objects/b/a/d/dataset_bad2b1b0-d3c6-4b80-9659-3fdccf63713e.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:03:42,569 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (259) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/259/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/259/galaxy_259.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:42,580 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:42,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:43,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:51,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-czvzq with k8s id: gxy-czvzq succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:03:51,574 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 258: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:52,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tl8ff with k8s id: gxy-tl8ff succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:03:52,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 259: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:03:58,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 258 finished
galaxy.model.metadata DEBUG 2024-11-24 07:03:58,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 344
galaxy.jobs INFO 2024-11-24 07:03:58,995 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 258 in /galaxy/server/database/jobs_directory/000/258
galaxy.jobs DEBUG 2024-11-24 07:03:59,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 258 executed (101.655 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:59,052 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 258 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:03:59,739 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 259 finished
galaxy.model.metadata DEBUG 2024-11-24 07:03:59,782 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 345
galaxy.jobs INFO 2024-11-24 07:03:59,810 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 259 in /galaxy/server/database/jobs_directory/000/259
galaxy.jobs DEBUG 2024-11-24 07:03:59,848 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 259 executed (88.580 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:03:59,858 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 259 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:04:00,772 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 260
tpv.core.entities DEBUG 2024-11-24 07:04:00,799 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:00,799 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:00,803 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:00,812 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:00,823 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Working directory for job is: /galaxy/server/database/jobs_directory/000/260
galaxy.jobs.runners DEBUG 2024-11-24 07:04:00,830 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [260] queued (27.650 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:00,832 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (260) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:00,834 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 260
galaxy.jobs DEBUG 2024-11-24 07:04:00,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [260] prepared (38.213 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:00,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:04:00,879 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:00,899 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:04:00,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/260/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/260/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/b/a/d/dataset_bad2b1b0-d3c6-4b80-9659-3fdccf63713e.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/7/e/5/dataset_7e5db5ca-badf-4652-9d92-c89a399e3fce.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/e/8/6/metadata_e861c1ac-0ddf-40b0-912e-3d2c43ce6abc.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 14 --skip-coverage 0 --limit-coverage 0   --haplotype-length 0 --min-alternate-count 1 --min-alternate-fraction 0.05 --pooled-continuous --report-monomorphic --standard-filters  "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/9/a/b/dataset_9ab0122c-9edc-45fb-b9c8-673da721f3fb.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:04:00,927 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (260) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/260/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/260/galaxy_260.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:00,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:00,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:04:00,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:00,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:00,970 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:01,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:05,595 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gt2cg with k8s id: gxy-gt2cg succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:05,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 260: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:04:12,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 260 finished
galaxy.model.metadata DEBUG 2024-11-24 07:04:12,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 346
galaxy.jobs INFO 2024-11-24 07:04:12,822 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 260 in /galaxy/server/database/jobs_directory/000/260
galaxy.jobs DEBUG 2024-11-24 07:04:12,870 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 260 executed (100.248 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:12,884 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 260 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:04:14,035 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 261
tpv.core.entities DEBUG 2024-11-24 07:04:14,057 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:14,058 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:14,061 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:14,071 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:14,085 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Working directory for job is: /galaxy/server/database/jobs_directory/000/261
galaxy.jobs.runners DEBUG 2024-11-24 07:04:14,091 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [261] queued (30.180 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:14,093 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (261) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:14,096 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 261
galaxy.jobs DEBUG 2024-11-24 07:04:14,171 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [261] prepared (69.351 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:04:14,191 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/261/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/261/registry.xml' '/galaxy/server/database/jobs_directory/000/261/upload_params.json' '347:/galaxy/server/database/objects/a/8/e/dataset_a8ef701d-296f-4143-9fca-18874d8a56fd_files:/galaxy/server/database/objects/a/8/e/dataset_a8ef701d-296f-4143-9fca-18874d8a56fd.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:04:14,200 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (261) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/261/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/261/galaxy_261.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:14,213 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:14,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:14,625 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 07:04:15,096 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 262
tpv.core.entities DEBUG 2024-11-24 07:04:15,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:15,116 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:15,119 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:15,128 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:15,139 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Working directory for job is: /galaxy/server/database/jobs_directory/000/262
galaxy.jobs.runners DEBUG 2024-11-24 07:04:15,146 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [262] queued (26.866 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:15,148 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (262) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:15,150 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 262
galaxy.jobs DEBUG 2024-11-24 07:04:15,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [262] prepared (69.921 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:04:15,244 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/262/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/262/registry.xml' '/galaxy/server/database/jobs_directory/000/262/upload_params.json' '348:/galaxy/server/database/objects/a/c/d/dataset_acd67216-3630-458d-8014-2725a5ae6c29_files:/galaxy/server/database/objects/a/c/d/dataset_acd67216-3630-458d-8014-2725a5ae6c29.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:04:15,252 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (262) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/262/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/262/galaxy_262.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:15,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:15,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:15,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:23,871 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-tbxm5 with k8s id: gxy-tbxm5 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:23,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 261: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:24,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-66ts8 with k8s id: gxy-66ts8 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:25,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 262: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:04:31,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 261 finished
galaxy.model.metadata DEBUG 2024-11-24 07:04:31,165 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 347
galaxy.jobs INFO 2024-11-24 07:04:31,203 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 261 in /galaxy/server/database/jobs_directory/000/261
galaxy.jobs DEBUG 2024-11-24 07:04:31,245 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 261 executed (98.926 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:31,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 261 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:04:32,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 262 finished
galaxy.model.metadata DEBUG 2024-11-24 07:04:32,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 348
galaxy.jobs INFO 2024-11-24 07:04:32,367 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 262 in /galaxy/server/database/jobs_directory/000/262
galaxy.jobs DEBUG 2024-11-24 07:04:32,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 262 executed (94.696 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:32,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 262 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:04:33,437 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 263
tpv.core.entities DEBUG 2024-11-24 07:04:33,465 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:33,465 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:33,469 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:33,478 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:33,491 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Working directory for job is: /galaxy/server/database/jobs_directory/000/263
galaxy.jobs.runners DEBUG 2024-11-24 07:04:33,498 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [263] queued (28.965 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:33,501 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (263) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:33,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 263
galaxy.jobs DEBUG 2024-11-24 07:04:33,550 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [263] prepared (42.128 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:33,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:04:33,551 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:33,572 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:04:33,590 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/263/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/263/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/a/c/d/dataset_acd67216-3630-458d-8014-2725a5ae6c29.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/a/8/e/dataset_a8ef701d-296f-4143-9fca-18874d8a56fd.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/0/c/5/metadata_0c58ab28-d8bb-4f4a-94b6-48f0ce97d133.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 14 --skip-coverage 0 --limit-coverage 0   --haplotype-length 0 --min-alternate-count 1 --min-alternate-fraction 0.05 --pooled-continuous --report-monomorphic --standard-filters  "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/7/8/b/dataset_78ba7f55-f2d9-4734-8c94-92b3eca1c5ef.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:04:33,598 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (263) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/263/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/263/galaxy_263.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:33,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:33,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:04:33,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:04:33,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:33,645 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:33,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:37,994 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-wznpw with k8s id: gxy-wznpw succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:38,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 263: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:04:45,146 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 263 finished
galaxy.model.metadata DEBUG 2024-11-24 07:04:45,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 349
galaxy.jobs INFO 2024-11-24 07:04:45,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 263 in /galaxy/server/database/jobs_directory/000/263
galaxy.jobs DEBUG 2024-11-24 07:04:45,282 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 263 executed (98.256 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:45,296 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 263 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:04:46,710 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 264, 265
tpv.core.entities DEBUG 2024-11-24 07:04:46,733 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:46,734 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:46,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:46,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:46,761 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Working directory for job is: /galaxy/server/database/jobs_directory/000/264
galaxy.jobs.runners DEBUG 2024-11-24 07:04:46,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [264] queued (30.830 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:46,770 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (264) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,773 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 264
tpv.core.entities DEBUG 2024-11-24 07:04:46,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:04:46,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:04:46,786 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:04:46,797 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:04:46,824 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Working directory for job is: /galaxy/server/database/jobs_directory/000/265
galaxy.jobs.runners DEBUG 2024-11-24 07:04:46,833 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [265] queued (47.057 ms)
galaxy.jobs.handler INFO 2024-11-24 07:04:46,835 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (265) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,837 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 265
galaxy.jobs DEBUG 2024-11-24 07:04:46,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [264] prepared (95.296 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:04:46,901 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/264/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/264/registry.xml' '/galaxy/server/database/jobs_directory/000/264/upload_params.json' '350:/galaxy/server/database/objects/a/5/d/dataset_a5d6ff04-07d3-4ccf-9a11-6f303f9acb9b_files:/galaxy/server/database/objects/a/5/d/dataset_a5d6ff04-07d3-4ccf-9a11-6f303f9acb9b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:04:46,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (264) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/264/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/264/galaxy_264.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:04:46,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [265] prepared (73.992 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,926 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:04:46,943 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/265/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/265/registry.xml' '/galaxy/server/database/jobs_directory/000/265/upload_params.json' '351:/galaxy/server/database/objects/9/d/7/dataset_9d799684-03da-4c80-ad45-e630f12000fa_files:/galaxy/server/database/objects/9/d/7/dataset_9d799684-03da-4c80-ad45-e630f12000fa.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,945 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:04:46,953 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (265) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/265/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/265/galaxy_265.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,965 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:46,980 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:48,036 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:48,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:56,287 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2jpff with k8s id: gxy-2jpff succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:56,389 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 265: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:04:57,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-fwr86 with k8s id: gxy-fwr86 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:04:57,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 264: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:05:03,875 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 265 finished
galaxy.model.metadata DEBUG 2024-11-24 07:05:03,913 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 351
galaxy.jobs INFO 2024-11-24 07:05:03,941 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 265 in /galaxy/server/database/jobs_directory/000/265
galaxy.jobs DEBUG 2024-11-24 07:05:03,985 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 265 executed (94.489 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:03,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 265 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:05:04,786 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 264 finished
galaxy.model.metadata DEBUG 2024-11-24 07:05:04,821 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 350
galaxy.jobs INFO 2024-11-24 07:05:04,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 264 in /galaxy/server/database/jobs_directory/000/264
galaxy.jobs DEBUG 2024-11-24 07:05:04,893 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 264 executed (90.925 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:04,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 264 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:05:05,449 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 266
tpv.core.entities DEBUG 2024-11-24 07:05:05,474 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:05,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:05,478 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:05,489 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:05,503 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Working directory for job is: /galaxy/server/database/jobs_directory/000/266
galaxy.jobs.runners DEBUG 2024-11-24 07:05:05,510 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [266] queued (31.770 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:05,512 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (266) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:05,514 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 266
galaxy.jobs DEBUG 2024-11-24 07:05:05,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [266] prepared (45.101 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:05,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:05:05,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:05,586 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:05:05,606 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/266/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/266/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/9/d/7/dataset_9d799684-03da-4c80-ad45-e630f12000fa.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/a/5/d/dataset_a5d6ff04-07d3-4ccf-9a11-6f303f9acb9b.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/7/a/2/metadata_7a261eeb-e6f3-4315-9101-b213942a5d84.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    --theta 0.001 --ploidy 1            "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/7/9/6/dataset_7962f6d2-3458-4bed-9c51-6295593e4dd1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:05,615 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (266) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/266/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/266/galaxy_266.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:05,628 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:05,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:05:05,629 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:05,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:05,662 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:06,323 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:10,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-g9jzh with k8s id: gxy-g9jzh succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:05:10,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 266: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:05:17,608 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 266 finished
galaxy.model.metadata DEBUG 2024-11-24 07:05:17,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 352
galaxy.jobs INFO 2024-11-24 07:05:17,678 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 266 in /galaxy/server/database/jobs_directory/000/266
galaxy.jobs DEBUG 2024-11-24 07:05:17,723 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 266 executed (97.608 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:17,735 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 266 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:05:19,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 268, 267
tpv.core.entities DEBUG 2024-11-24 07:05:19,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:19,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:19,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:19,758 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:19,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Working directory for job is: /galaxy/server/database/jobs_directory/000/267
galaxy.jobs.runners DEBUG 2024-11-24 07:05:19,776 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [267] queued (26.453 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:19,778 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (267) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 267
tpv.core.entities DEBUG 2024-11-24 07:05:19,789 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:19,790 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:19,794 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:19,803 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:19,826 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Working directory for job is: /galaxy/server/database/jobs_directory/000/268
galaxy.jobs.runners DEBUG 2024-11-24 07:05:19,831 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [268] queued (37.686 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:19,834 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (268) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 268
galaxy.jobs DEBUG 2024-11-24 07:05:19,875 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [267] prepared (84.193 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:05:19,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/267/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/267/registry.xml' '/galaxy/server/database/jobs_directory/000/267/upload_params.json' '353:/galaxy/server/database/objects/9/8/3/dataset_9833a3d3-5af8-416d-8c7c-08b90a3b7d86_files:/galaxy/server/database/objects/9/8/3/dataset_9833a3d3-5af8-416d-8c7c-08b90a3b7d86.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:19,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (267) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/267/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/267/galaxy_267.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:05:19,918 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [268] prepared (72.745 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,936 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:05:19,939 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/268/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/268/registry.xml' '/galaxy/server/database/jobs_directory/000/268/upload_params.json' '354:/galaxy/server/database/objects/8/b/3/dataset_8b34db41-2383-4997-a027-f489bf593294_files:/galaxy/server/database/objects/8/b/3/dataset_8b34db41-2383-4997-a027-f489bf593294.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:19,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (268) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/268/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/268/galaxy_268.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:19,971 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:20,423 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:20,458 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:29,752 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ggmdd with k8s id: gxy-ggmdd succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:29,764 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ztpmq with k8s id: gxy-ztpmq succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:05:29,867 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 267: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:05:29,887 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 268: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:05:37,273 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 267 finished
galaxy.jobs.runners DEBUG 2024-11-24 07:05:37,283 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 268 finished
galaxy.model.metadata DEBUG 2024-11-24 07:05:37,321 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 353
galaxy.model.metadata DEBUG 2024-11-24 07:05:37,325 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 354
galaxy.jobs INFO 2024-11-24 07:05:37,362 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 268 in /galaxy/server/database/jobs_directory/000/268
galaxy.jobs INFO 2024-11-24 07:05:37,371 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 267 in /galaxy/server/database/jobs_directory/000/267
galaxy.jobs DEBUG 2024-11-24 07:05:37,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 268 executed (106.915 ms)
galaxy.jobs DEBUG 2024-11-24 07:05:37,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 267 executed (127.349 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:37,422 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 268 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:37,433 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 267 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:05:38,120 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 269
tpv.core.entities DEBUG 2024-11-24 07:05:38,142 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:38,143 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:38,145 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:38,154 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:38,164 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Working directory for job is: /galaxy/server/database/jobs_directory/000/269
galaxy.jobs.runners DEBUG 2024-11-24 07:05:38,171 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [269] queued (25.728 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:38,173 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (269) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:38,176 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 269
galaxy.jobs DEBUG 2024-11-24 07:05:38,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [269] prepared (42.434 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:38,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:05:38,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:38,246 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:05:38,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/269/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/269/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/8/b/3/dataset_8b34db41-2383-4997-a027-f489bf593294.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/9/8/3/dataset_9833a3d3-5af8-416d-8c7c-08b90a3b7d86.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/2/d/d/metadata_2ddc0215-2aac-4799-becc-6ed906ee33d2.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 250 --skip-coverage 0 --limit-coverage 0    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/0/4/9/dataset_0494d927-2663-41ff-9bd3-df7ca0b58ac2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:38,274 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (269) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/269/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/269/galaxy_269.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:38,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:38,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:05:38,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:05:38,303 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:38,320 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:38,796 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:42,868 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-fz9vv with k8s id: gxy-fz9vv succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:05:42,992 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 269: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:05:49,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 269 finished
galaxy.model.metadata DEBUG 2024-11-24 07:05:50,025 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 355
galaxy.jobs INFO 2024-11-24 07:05:50,056 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 269 in /galaxy/server/database/jobs_directory/000/269
galaxy.jobs DEBUG 2024-11-24 07:05:50,099 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 269 executed (96.734 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:50,112 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 269 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:05:51,381 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 270
tpv.core.entities DEBUG 2024-11-24 07:05:51,407 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:51,407 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:51,411 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:51,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:51,437 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Working directory for job is: /galaxy/server/database/jobs_directory/000/270
galaxy.jobs.runners DEBUG 2024-11-24 07:05:51,443 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [270] queued (32.348 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:51,446 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (270) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:51,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 270
galaxy.jobs DEBUG 2024-11-24 07:05:51,530 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [270] prepared (74.169 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:05:51,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/270/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/270/registry.xml' '/galaxy/server/database/jobs_directory/000/270/upload_params.json' '356:/galaxy/server/database/objects/4/4/0/dataset_44023c4c-ec43-4773-8de9-3c20faff3942_files:/galaxy/server/database/objects/4/4/0/dataset_44023c4c-ec43-4773-8de9-3c20faff3942.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:51,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/270/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/270/galaxy_270.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:51,574 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:51,588 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:51,900 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 07:05:52,450 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 271
tpv.core.entities DEBUG 2024-11-24 07:05:52,475 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:05:52,476 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:05:52,479 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:05:52,491 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:05:52,505 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Working directory for job is: /galaxy/server/database/jobs_directory/000/271
galaxy.jobs.runners DEBUG 2024-11-24 07:05:52,513 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [271] queued (33.034 ms)
galaxy.jobs.handler INFO 2024-11-24 07:05:52,515 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (271) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:52,518 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 271
galaxy.jobs DEBUG 2024-11-24 07:05:52,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [271] prepared (66.777 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:05:52,610 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/271/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/271/registry.xml' '/galaxy/server/database/jobs_directory/000/271/upload_params.json' '357:/galaxy/server/database/objects/0/7/3/dataset_0732e11e-0f44-4668-abeb-130ce4cd9651_files:/galaxy/server/database/objects/0/7/3/dataset_0732e11e-0f44-4668-abeb-130ce4cd9651.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:05:52,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (271) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/271/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/271/galaxy_271.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:52,634 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:52,649 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:05:52,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t6t5p failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,171 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-t6t5p.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,181 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 07:06:01,206 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-t6t5p

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-t6t5p": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,218 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270/gxy-t6t5p) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270/gxy-t6t5p) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270/gxy-t6t5p) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270/gxy-t6t5p) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-t6t5p.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,226 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 270 (gxy-t6t5p)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-t6t5p to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 270 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:01,281 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (270/gxy-t6t5p) Terminated at user's request
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,233 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vg97x with k8s id: gxy-vg97x succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:06:02,347 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 271: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-24 07:06:02,660 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 272, 273
tpv.core.entities DEBUG 2024-11-24 07:06:02,686 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:02,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:02,691 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:02,702 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:02,716 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Working directory for job is: /galaxy/server/database/jobs_directory/000/272
galaxy.jobs.runners DEBUG 2024-11-24 07:06:02,723 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [272] queued (32.166 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:02,725 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (272) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 272
tpv.core.entities DEBUG 2024-11-24 07:06:02,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:02,737 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:02,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:02,752 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:02,777 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Working directory for job is: /galaxy/server/database/jobs_directory/000/273
galaxy.jobs.runners DEBUG 2024-11-24 07:06:02,787 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [273] queued (45.970 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:02,791 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (273) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,797 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 273
galaxy.jobs DEBUG 2024-11-24 07:06:02,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [272] prepared (96.167 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:06:02,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/272/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/272/registry.xml' '/galaxy/server/database/jobs_directory/000/272/upload_params.json' '358:/galaxy/server/database/objects/3/6/6/dataset_36609257-5fa4-46a0-8e6f-f7c2509c5b18_files:/galaxy/server/database/objects/3/6/6/dataset_36609257-5fa4-46a0-8e6f-f7c2509c5b18.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:02,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (272) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/272/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/272/galaxy_272.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:06:02,880 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [273] prepared (74.285 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,884 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:06:02,909 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/273/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/273/registry.xml' '/galaxy/server/database/jobs_directory/000/273/upload_params.json' '359:/galaxy/server/database/objects/c/e/9/dataset_ce9e5d09-6e32-4daf-b767-55358bb764f0_files:/galaxy/server/database/objects/c/e/9/dataset_ce9e5d09-6e32-4daf-b767-55358bb764f0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:02,923 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (273) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/273/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/273/galaxy_273.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:02,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:03,256 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:03,293 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 07:06:09,549 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 271 finished
galaxy.model.metadata DEBUG 2024-11-24 07:06:09,587 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 357
galaxy.jobs INFO 2024-11-24 07:06:09,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 271 in /galaxy/server/database/jobs_directory/000/271
galaxy.jobs DEBUG 2024-11-24 07:06:09,658 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 271 executed (90.729 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:09,681 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 271 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:12,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rw9px with k8s id: gxy-rw9px succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:12,531 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vjrwr with k8s id: gxy-vjrwr succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:06:12,642 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 272: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:06:12,657 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 273: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:06:19,818 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 273 finished
galaxy.jobs.runners DEBUG 2024-11-24 07:06:19,838 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 272 finished
galaxy.model.metadata DEBUG 2024-11-24 07:06:19,861 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 359
galaxy.model.metadata DEBUG 2024-11-24 07:06:19,881 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 358
galaxy.jobs INFO 2024-11-24 07:06:19,895 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 273 in /galaxy/server/database/jobs_directory/000/273
galaxy.jobs INFO 2024-11-24 07:06:19,922 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 272 in /galaxy/server/database/jobs_directory/000/272
galaxy.jobs DEBUG 2024-11-24 07:06:19,949 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 273 executed (113.886 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:19,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 273 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 07:06:19,974 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 272 executed (115.979 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:19,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 272 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:06:21,076 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 274
tpv.core.entities DEBUG 2024-11-24 07:06:21,103 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:21,103 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:21,107 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:21,117 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:21,129 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Working directory for job is: /galaxy/server/database/jobs_directory/000/274
galaxy.jobs.runners DEBUG 2024-11-24 07:06:21,137 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [274] queued (29.303 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:21,139 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (274) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:21,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 274
galaxy.jobs DEBUG 2024-11-24 07:06:21,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [274] prepared (46.455 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:21,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:06:21,197 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:21,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:06:21,376 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/274/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/274/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/c/e/9/dataset_ce9e5d09-6e32-4daf-b767-55358bb764f0.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/3/6/6/dataset_36609257-5fa4-46a0-8e6f-f7c2509c5b18.dat' 'b_0.bam' && ln -s -f '/galaxy/server/database/objects/_metadata_files/d/d/f/metadata_ddf922b4-a6ed-4415-b10d-1eeda5de1b86.dat' 'b_0.bam.bai' &&   samtools view -H b_0.bam| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.bam' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'   --min-coverage 0 --skip-coverage 100 --limit-coverage 0    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/2/0/9/dataset_20914d27-0a5e-4e7a-ae94-7a42d84d9e08.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:21,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (274) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/274/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/274/galaxy_274.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:21,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:21,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:06:21,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:21,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:21,435 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:21,583 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:25,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sfpjs with k8s id: gxy-sfpjs succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:06:25,782 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 274: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:06:32,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 274 finished
galaxy.model.metadata DEBUG 2024-11-24 07:06:32,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 360
galaxy.jobs INFO 2024-11-24 07:06:32,971 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 274 in /galaxy/server/database/jobs_directory/000/274
galaxy.jobs DEBUG 2024-11-24 07:06:33,016 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 274 executed (92.991 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:33,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 274 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:06:34,342 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 275, 276
tpv.core.entities DEBUG 2024-11-24 07:06:34,368 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:34,368 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:34,372 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:34,381 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:34,395 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Working directory for job is: /galaxy/server/database/jobs_directory/000/275
galaxy.jobs.runners DEBUG 2024-11-24 07:06:34,401 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [275] queued (29.407 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:34,403 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (275) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,406 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 275
tpv.core.entities DEBUG 2024-11-24 07:06:34,417 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:34,418 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:34,421 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:34,433 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:34,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Working directory for job is: /galaxy/server/database/jobs_directory/000/276
galaxy.jobs.runners DEBUG 2024-11-24 07:06:34,464 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [276] queued (42.824 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:34,467 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (276) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,471 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 276
galaxy.jobs DEBUG 2024-11-24 07:06:34,513 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [275] prepared (96.178 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:06:34,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/275/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/275/registry.xml' '/galaxy/server/database/jobs_directory/000/275/upload_params.json' '361:/galaxy/server/database/objects/5/f/4/dataset_5f4127df-0f81-4fc2-8bdf-45c7cb8b507d_files:/galaxy/server/database/objects/5/f/4/dataset_5f4127df-0f81-4fc2-8bdf-45c7cb8b507d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:34,542 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (275) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/275/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/275/galaxy_275.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:06:34,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [276] prepared (71.991 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,556 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:06:34,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/276/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/276/registry.xml' '/galaxy/server/database/jobs_directory/000/276/upload_params.json' '362:/galaxy/server/database/objects/c/1/b/dataset_c1b2321f-1ac7-4ff9-93d0-0ddc6116f6a6_files:/galaxy/server/database/objects/c/1/b/dataset_c1b2321f-1ac7-4ff9-93d0-0ddc6116f6a6.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:34,587 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (276) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/276/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/276/galaxy_276.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,616 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:34,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:35,764 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:43,948 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2c4tc with k8s id: gxy-2c4tc succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:43,961 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-7clcz with k8s id: gxy-7clcz succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:06:44,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 275: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:06:44,098 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 276: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:06:51,337 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 276 finished
galaxy.model.metadata DEBUG 2024-11-24 07:06:51,380 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 362
galaxy.jobs.runners DEBUG 2024-11-24 07:06:51,409 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 275 finished
galaxy.jobs INFO 2024-11-24 07:06:51,414 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 276 in /galaxy/server/database/jobs_directory/000/276
galaxy.model.metadata DEBUG 2024-11-24 07:06:51,448 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 361
galaxy.jobs DEBUG 2024-11-24 07:06:51,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 276 executed (117.713 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:51,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 276 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs INFO 2024-11-24 07:06:51,488 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 275 in /galaxy/server/database/jobs_directory/000/275
galaxy.jobs DEBUG 2024-11-24 07:06:51,535 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 275 executed (105.193 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:51,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 275 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:06:51,888 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 277
tpv.core.entities DEBUG 2024-11-24 07:06:51,916 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/.*, abstract=False, cores=10, mem=90, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:06:51,916 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:06:51,920 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:06:51,931 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:06:51,944 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Working directory for job is: /galaxy/server/database/jobs_directory/000/277
galaxy.jobs.runners DEBUG 2024-11-24 07:06:51,953 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [277] queued (33.161 ms)
galaxy.jobs.handler INFO 2024-11-24 07:06:51,955 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (277) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:51,957 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 277
galaxy.jobs DEBUG 2024-11-24 07:06:52,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [277] prepared (47.081 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:52,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:06:52,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:52,034 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:06:52,053 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/277/tool_script.sh] for tool command [freebayes --version | cut -d v -f 3 > /galaxy/server/database/jobs_directory/000/277/outputs/COMMAND_VERSION 2>&1;
ln -s -f '/galaxy/server/database/objects/c/1/b/dataset_c1b2321f-1ac7-4ff9-93d0-0ddc6116f6a6.dat' 'localref.fa' && samtools faidx 'localref.fa' 2>&1 || echo "Error running samtools faidx for FreeBayes" >&2 &&   ln -s -f '/galaxy/server/database/objects/5/f/4/dataset_5f4127df-0f81-4fc2-8bdf-45c7cb8b507d.dat' 'b_0.cram' && ln -s -f '/galaxy/server/database/objects/_metadata_files/9/5/f/metadata_95f06da0-385c-4300-b3d3-e33283c2a06f.dat' 'b_0.cram.crai' &&   samtools view -H b_0.cram| grep '^@SQ' | cut -f 2- | awk '{ gsub("^SN:","",$1); gsub("^LN:","",$2); print $1"\t0\t"$2; }' >> regions_all.bed &&  sort -u regions_all.bed > regions_uniq.bed &&  mkdir vcf_output failed_alleles trace &&   for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do echo "   freebayes  --region '$i'  --bam 'b_0.cram' --fasta-reference 'localref.fa'  --vcf './vcf_output/part_$i.vcf'    "; done > freebayes_commands.sh &&  cat freebayes_commands.sh | parallel --will-cite -j ${GALAXY_SLOTS:-1} &&  grep "^#" "./vcf_output/part_$i.vcf" > header.txt &&  for i in `cat regions_uniq.bed | awk '{print $1":"$2".."$3}'`; do cat "./vcf_output/part_$i.vcf" | grep -v "^#" || true ; done | sort -k1,1 -k2,2n -k5,5 -u | cat header.txt - > '/galaxy/server/database/objects/b/6/4/dataset_b647274d-a29b-44a0-93b2-157ed4db02d9.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:06:52,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (277) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/277/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/277/galaxy_277.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:52,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:52,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:06:52,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/freebayes/freebayes/1.3.8+galaxy0: mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad
galaxy.tool_util.deps.containers INFO 2024-11-24 07:06:52,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-7bde9f0045905cc44cb726ad016ff10c70a194d7:b4de2951c942c93b5ed20929f2c533ceb2c2c1ad-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:52,114 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:53,028 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:06:57,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mtlcb with k8s id: gxy-mtlcb succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:06:57,194 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 277: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:07:04,126 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 277 finished
galaxy.model.metadata DEBUG 2024-11-24 07:07:04,176 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 363
galaxy.jobs INFO 2024-11-24 07:07:04,208 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 277 in /galaxy/server/database/jobs_directory/000/277
galaxy.jobs DEBUG 2024-11-24 07:07:04,259 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 277 executed (110.229 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:04,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 277 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:07:07,190 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 278
tpv.core.entities DEBUG 2024-11-24 07:07:07,215 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:07:07,215 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:07:07,218 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:07:07,227 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:07:07,240 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Working directory for job is: /galaxy/server/database/jobs_directory/000/278
galaxy.jobs.runners DEBUG 2024-11-24 07:07:07,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [278] queued (27.976 ms)
galaxy.jobs.handler INFO 2024-11-24 07:07:07,249 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (278) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:07,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 278
galaxy.jobs DEBUG 2024-11-24 07:07:07,317 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [278] prepared (59.239 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:07:07,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/278/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/278/registry.xml' '/galaxy/server/database/jobs_directory/000/278/upload_params.json' '364:/galaxy/server/database/objects/f/1/b/dataset_f1b30397-1f29-4814-9974-4d7d822d63da_files:/galaxy/server/database/objects/f/1/b/dataset_f1b30397-1f29-4814-9974-4d7d822d63da.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:07:07,344 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (278) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/278/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/278/galaxy_278.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:07,357 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:07,369 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:08,120 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:17,260 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2zm22 with k8s id: gxy-2zm22 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:07:17,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 278: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:07:24,378 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 278 finished
galaxy.model.metadata DEBUG 2024-11-24 07:07:24,417 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 364
galaxy.jobs INFO 2024-11-24 07:07:24,445 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 278 in /galaxy/server/database/jobs_directory/000/278
galaxy.jobs DEBUG 2024-11-24 07:07:24,484 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 278 executed (88.661 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:24,524 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 278 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:07:25,531 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 279
tpv.core.entities DEBUG 2024-11-24 07:07:25,554 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:07:25,555 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:07:25,558 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:07:25,566 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:07:25,581 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Working directory for job is: /galaxy/server/database/jobs_directory/000/279
galaxy.jobs.runners DEBUG 2024-11-24 07:07:25,589 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [279] queued (31.290 ms)
galaxy.jobs.handler INFO 2024-11-24 07:07:25,592 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (279) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:25,594 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 279
galaxy.jobs DEBUG 2024-11-24 07:07:25,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [279] prepared (65.842 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:07:25,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:07:25,667 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:07:25,856 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:07:25,875 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/279/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/279/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/f/1/b/dataset_f1b30397-1f29-4814-9974-4d7d822d63da.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp    -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/7/7/6/dataset_7767897e-cb44-4ef9-bc7f-2483f87c303c.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/e/d/9/dataset_ed933504-1662-4055-a17e-cca2326ae9c5.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/c/5/6/dataset_c56f5b27-a3d9-4352-8d76-282f8b41d5d1.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/c/5/6/dataset_c56f5b27-a3d9-4352-8d76-282f8b41d5d1.dat; python -m base64 $plot >> /galaxy/server/database/objects/c/5/6/dataset_c56f5b27-a3d9-4352-8d76-282f8b41d5d1.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/c/5/6/dataset_c56f5b27-a3d9-4352-8d76-282f8b41d5d1.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/c/5/6/dataset_c56f5b27-a3d9-4352-8d76-282f8b41d5d1.dat;)]
galaxy.jobs.runners DEBUG 2024-11-24 07:07:25,894 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (279) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/279/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/279/galaxy_279.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:25,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:07:25,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:07:25,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:07:25,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:25,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:26,285 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:07:55,755 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gm9tj with k8s id: gxy-gm9tj succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:07:55,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 279: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:08:02,959 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 279 finished
galaxy.model.metadata DEBUG 2024-11-24 07:08:02,993 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 365
galaxy.model.metadata DEBUG 2024-11-24 07:08:03,001 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 366
galaxy.model.metadata DEBUG 2024-11-24 07:08:03,011 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 367
galaxy.util WARNING 2024-11-24 07:08:03,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/7/7/6/dataset_7767897e-cb44-4ef9-bc7f-2483f87c303c.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/7/7/6/dataset_7767897e-cb44-4ef9-bc7f-2483f87c303c.dat'
galaxy.util WARNING 2024-11-24 07:08:03,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/e/d/9/dataset_ed933504-1662-4055-a17e-cca2326ae9c5.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/e/d/9/dataset_ed933504-1662-4055-a17e-cca2326ae9c5.dat'
galaxy.jobs INFO 2024-11-24 07:08:03,042 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 279 in /galaxy/server/database/jobs_directory/000/279
galaxy.jobs DEBUG 2024-11-24 07:08:03,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 279 executed (103.442 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:03,098 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 279 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:08:04,231 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 280
tpv.core.entities DEBUG 2024-11-24 07:08:04,253 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:08:04,254 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:08:04,257 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:08:04,266 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:08:04,276 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Working directory for job is: /galaxy/server/database/jobs_directory/000/280
galaxy.jobs.runners DEBUG 2024-11-24 07:08:04,282 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [280] queued (24.780 ms)
galaxy.jobs.handler INFO 2024-11-24 07:08:04,284 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (280) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:04,286 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 280
galaxy.jobs DEBUG 2024-11-24 07:08:04,360 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [280] prepared (66.741 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:08:04,379 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/280/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/280/registry.xml' '/galaxy/server/database/jobs_directory/000/280/upload_params.json' '368:/galaxy/server/database/objects/b/9/9/dataset_b999ebab-0299-43ad-a23f-5913931b8730_files:/galaxy/server/database/objects/b/9/9/dataset_b999ebab-0299-43ad-a23f-5913931b8730.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:08:04,387 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (280) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/280/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/280/galaxy_280.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:04,399 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:04,411 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:04,781 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:13,902 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9ds7s with k8s id: gxy-9ds7s succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:08:14,003 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 280: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:08:21,019 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 280 finished
galaxy.model.metadata DEBUG 2024-11-24 07:08:21,057 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 368
galaxy.jobs INFO 2024-11-24 07:08:21,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 280 in /galaxy/server/database/jobs_directory/000/280
galaxy.jobs DEBUG 2024-11-24 07:08:21,132 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 280 executed (95.052 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:21,142 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 280 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:08:21,546 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 281
tpv.core.entities DEBUG 2024-11-24 07:08:21,568 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:08:21,569 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:08:21,572 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:08:21,582 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:08:21,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Working directory for job is: /galaxy/server/database/jobs_directory/000/281
galaxy.jobs.runners DEBUG 2024-11-24 07:08:21,606 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [281] queued (34.270 ms)
galaxy.jobs.handler INFO 2024-11-24 07:08:21,609 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (281) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:21,611 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 281
galaxy.jobs DEBUG 2024-11-24 07:08:21,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [281] prepared (45.535 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:21,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:08:21,664 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:21,686 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:08:21,705 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/281/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/281/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/b/9/9/dataset_b999ebab-0299-43ad-a23f-5913931b8730.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp     --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/7/0/6/dataset_7063aa8f-299e-4fad-95b5-9bd4147e6cc4.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/d/6/d/dataset_d6d067f3-f21a-4bfb-89f6-d6133ecb5776.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:08:21,716 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (281) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/281/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/281/galaxy_281.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:21,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:21,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:08:21,728 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:21,746 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:21,760 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:21,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:26,002 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-sprgj with k8s id: gxy-sprgj succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:08:26,134 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 281: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:08:33,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 281 finished
galaxy.model.metadata DEBUG 2024-11-24 07:08:33,215 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 369
galaxy.model.metadata DEBUG 2024-11-24 07:08:33,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 370
galaxy.util WARNING 2024-11-24 07:08:33,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/7/0/6/dataset_7063aa8f-299e-4fad-95b5-9bd4147e6cc4.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/7/0/6/dataset_7063aa8f-299e-4fad-95b5-9bd4147e6cc4.dat'
galaxy.util WARNING 2024-11-24 07:08:33,229 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/d/6/d/dataset_d6d067f3-f21a-4bfb-89f6-d6133ecb5776.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/d/6/d/dataset_d6d067f3-f21a-4bfb-89f6-d6133ecb5776.dat'
galaxy.jobs INFO 2024-11-24 07:08:33,253 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 281 in /galaxy/server/database/jobs_directory/000/281
galaxy.jobs DEBUG 2024-11-24 07:08:33,287 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 281 executed (91.447 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:33,299 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 281 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:08:39,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 282
tpv.core.entities DEBUG 2024-11-24 07:08:40,017 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:08:40,018 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:08:40,021 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:08:40,029 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:08:40,041 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Working directory for job is: /galaxy/server/database/jobs_directory/000/282
galaxy.jobs.runners DEBUG 2024-11-24 07:08:40,046 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [282] queued (25.484 ms)
galaxy.jobs.handler INFO 2024-11-24 07:08:40,048 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (282) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:40,050 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 282
galaxy.jobs DEBUG 2024-11-24 07:08:40,127 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [282] prepared (71.664 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:08:40,144 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/282/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/282/registry.xml' '/galaxy/server/database/jobs_directory/000/282/upload_params.json' '371:/galaxy/server/database/objects/e/5/d/dataset_e5d1c700-3491-43cc-a3e1-f01f82b172f0_files:/galaxy/server/database/objects/e/5/d/dataset_e5d1c700-3491-43cc-a3e1-f01f82b172f0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:08:40,152 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (282) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/282/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/282/galaxy_282.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:40,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:40,177 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:41,030 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:49,161 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-bsqlv with k8s id: gxy-bsqlv succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:08:49,271 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 282: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:08:56,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 282 finished
galaxy.model.metadata DEBUG 2024-11-24 07:08:56,199 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 371
galaxy.jobs INFO 2024-11-24 07:08:56,227 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 282 in /galaxy/server/database/jobs_directory/000/282
galaxy.jobs DEBUG 2024-11-24 07:08:56,263 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 282 executed (86.843 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:56,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 282 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:08:57,310 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 283
tpv.core.entities DEBUG 2024-11-24 07:08:57,335 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:08:57,336 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:08:57,339 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:08:57,348 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:08:57,362 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Working directory for job is: /galaxy/server/database/jobs_directory/000/283
galaxy.jobs.runners DEBUG 2024-11-24 07:08:57,371 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [283] queued (31.868 ms)
galaxy.jobs.handler INFO 2024-11-24 07:08:57,373 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (283) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:57,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 283
galaxy.jobs DEBUG 2024-11-24 07:08:57,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [283] prepared (36.657 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:57,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:08:57,418 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:57,437 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:08:57,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/283/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/283/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/e/5/d/dataset_e5d1c700-3491-43cc-a3e1-f01f82b172f0.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp  -c 'test' -s 'test'   -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/d/0/a/dataset_d0aa606a-abf4-4e39-9ea6-75b4041c2a3e.dat' && mv cnv_tmp/summary.tab '/galaxy/server/database/objects/5/6/c/dataset_56c592ec-92e0-490e-8cf7-646df11faa98.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/9/0/e/dataset_90eaf73d-b15d-4512-816c-8cd112b2c8ac.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/9/0/e/dataset_90eaf73d-b15d-4512-816c-8cd112b2c8ac.dat; python -m base64 $plot >> /galaxy/server/database/objects/9/0/e/dataset_90eaf73d-b15d-4512-816c-8cd112b2c8ac.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/9/0/e/dataset_90eaf73d-b15d-4512-816c-8cd112b2c8ac.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/9/0/e/dataset_90eaf73d-b15d-4512-816c-8cd112b2c8ac.dat;)]
galaxy.jobs.runners DEBUG 2024-11-24 07:08:57,474 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (283) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/283/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/283/galaxy_283.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:57,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:57,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:08:57,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:08:57,503 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:57,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:08:58,189 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:04,273 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9c69q with k8s id: gxy-9c69q succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:09:04,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 283: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:09:11,521 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 283 finished
galaxy.model.metadata DEBUG 2024-11-24 07:09:11,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 372
galaxy.model.metadata DEBUG 2024-11-24 07:09:11,570 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 373
galaxy.model.metadata DEBUG 2024-11-24 07:09:11,579 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 374
galaxy.util WARNING 2024-11-24 07:09:11,584 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/d/0/a/dataset_d0aa606a-abf4-4e39-9ea6-75b4041c2a3e.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/d/0/a/dataset_d0aa606a-abf4-4e39-9ea6-75b4041c2a3e.dat'
galaxy.util WARNING 2024-11-24 07:09:11,584 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/5/6/c/dataset_56c592ec-92e0-490e-8cf7-646df11faa98.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/5/6/c/dataset_56c592ec-92e0-490e-8cf7-646df11faa98.dat'
galaxy.jobs INFO 2024-11-24 07:09:11,612 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 283 in /galaxy/server/database/jobs_directory/000/283
galaxy.jobs DEBUG 2024-11-24 07:09:11,652 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 283 executed (110.872 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:11,663 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 283 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:09:12,608 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 284
tpv.core.entities DEBUG 2024-11-24 07:09:12,630 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:09:12,631 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:09:12,635 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:09:12,645 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:09:12,655 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Working directory for job is: /galaxy/server/database/jobs_directory/000/284
galaxy.jobs.runners DEBUG 2024-11-24 07:09:12,661 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [284] queued (26.818 ms)
galaxy.jobs.handler INFO 2024-11-24 07:09:12,664 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (284) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:12,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 284
galaxy.jobs DEBUG 2024-11-24 07:09:12,749 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [284] prepared (75.464 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:09:12,765 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/284/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/284/registry.xml' '/galaxy/server/database/jobs_directory/000/284/upload_params.json' '375:/galaxy/server/database/objects/5/d/6/dataset_5d62d8c7-398d-4076-a80c-aa36ea6e3780_files:/galaxy/server/database/objects/5/d/6/dataset_5d62d8c7-398d-4076-a80c-aa36ea6e3780.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:09:12,774 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (284) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/284/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/284/galaxy_284.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:12,787 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:12,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:13,298 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:22,426 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-gtfwd with k8s id: gxy-gtfwd succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:09:22,534 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 284: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:09:29,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 284 finished
galaxy.model.metadata DEBUG 2024-11-24 07:09:29,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 375
galaxy.jobs INFO 2024-11-24 07:09:29,483 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 284 in /galaxy/server/database/jobs_directory/000/284
galaxy.jobs DEBUG 2024-11-24 07:09:29,520 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 284 executed (84.280 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:29,533 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 284 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:09:29,936 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 285
tpv.core.entities DEBUG 2024-11-24 07:09:29,958 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:09:29,959 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:09:29,961 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:09:29,970 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:09:29,982 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Working directory for job is: /galaxy/server/database/jobs_directory/000/285
galaxy.jobs.runners DEBUG 2024-11-24 07:09:29,989 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [285] queued (27.640 ms)
galaxy.jobs.handler INFO 2024-11-24 07:09:29,992 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (285) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:29,994 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 285
galaxy.jobs DEBUG 2024-11-24 07:09:30,043 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [285] prepared (42.569 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:09:30,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:09:30,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:09:30,064 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:09:30,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/285/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/285/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/5/d/6/dataset_5d62d8c7-398d-4076-a80c-aa36ea6e3780.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp     --aberrant "1.0,1.0" --BAF-weight 1 --BAF-dev "0.04,0.04" --LRR-weight 0 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09             input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/a/0/d/dataset_a0d07803-6c83-46c5-bf09-f53f2333a196.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/9/8/e/dataset_98e30f8a-0809-46d1-a355-938453127762.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:09:30,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (285) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/285/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/285/galaxy_285.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:30,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:09:30,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:09:30,107 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:09:30,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:30,137 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:30,450 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:34,509 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-86kkb with k8s id: gxy-86kkb succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:09:34,614 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 285: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:09:41,555 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 285 finished
galaxy.model.metadata DEBUG 2024-11-24 07:09:41,589 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 376
galaxy.model.metadata DEBUG 2024-11-24 07:09:41,597 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 377
galaxy.util WARNING 2024-11-24 07:09:41,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/a/0/d/dataset_a0d07803-6c83-46c5-bf09-f53f2333a196.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/a/0/d/dataset_a0d07803-6c83-46c5-bf09-f53f2333a196.dat'
galaxy.util WARNING 2024-11-24 07:09:41,603 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/9/8/e/dataset_98e30f8a-0809-46d1-a355-938453127762.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/9/8/e/dataset_98e30f8a-0809-46d1-a355-938453127762.dat'
galaxy.jobs INFO 2024-11-24 07:09:41,627 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 285 in /galaxy/server/database/jobs_directory/000/285
galaxy.jobs DEBUG 2024-11-24 07:09:41,666 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 285 executed (95.398 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:41,679 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 285 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:09:43,190 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 286
tpv.core.entities DEBUG 2024-11-24 07:09:43,213 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:09:43,213 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:09:43,217 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:09:43,227 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:09:43,238 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Working directory for job is: /galaxy/server/database/jobs_directory/000/286
galaxy.jobs.runners DEBUG 2024-11-24 07:09:43,244 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [286] queued (26.905 ms)
galaxy.jobs.handler INFO 2024-11-24 07:09:43,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (286) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:43,248 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 286
galaxy.jobs DEBUG 2024-11-24 07:09:43,322 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [286] prepared (67.057 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:09:43,340 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/286/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/286/registry.xml' '/galaxy/server/database/jobs_directory/000/286/upload_params.json' '378:/galaxy/server/database/objects/1/6/5/dataset_16543996-f87b-48a6-950e-ff1b7833cc45_files:/galaxy/server/database/objects/1/6/5/dataset_16543996-f87b-48a6-950e-ff1b7833cc45.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:09:43,350 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (286) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/286/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/286/galaxy_286.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:43,363 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:43,375 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:43,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:09:53,747 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-snlgg with k8s id: gxy-snlgg succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:09:53,847 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 286: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:10:00,665 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 286 finished
galaxy.model.metadata DEBUG 2024-11-24 07:10:00,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 378
galaxy.jobs INFO 2024-11-24 07:10:00,736 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 286 in /galaxy/server/database/jobs_directory/000/286
galaxy.jobs DEBUG 2024-11-24 07:10:00,780 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 286 executed (97.169 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:00,808 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 286 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:10:01,598 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 287
tpv.core.entities DEBUG 2024-11-24 07:10:01,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:10:01,625 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:10:01,629 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:10:01,642 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:10:01,659 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Working directory for job is: /galaxy/server/database/jobs_directory/000/287
galaxy.jobs.runners DEBUG 2024-11-24 07:10:01,668 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [287] queued (38.497 ms)
galaxy.jobs.handler INFO 2024-11-24 07:10:01,670 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (287) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:01,672 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 287
galaxy.jobs DEBUG 2024-11-24 07:10:01,721 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [287] prepared (42.718 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:10:01,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:10:01,722 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:10:01,740 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:10:01,757 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/287/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/287/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/1/6/5/dataset_16543996-f87b-48a6-950e-ff1b7833cc45.dat' > input.vcf.gz && bcftools index input.vcf.gz &&            bcftools cnv  --output-dir cnv_tmp    -p 0  --aberrant "1.0,1.0" --BAF-weight 1.0 --BAF-dev "0.04,0.04" --LRR-weight 0.2 --LRR-dev "0.2,0.2" --LRR-smooth-win 10 --same-prob 0.5 --err-prob 0.0001 --xy-prob 1e-09    --regions-overlap 1          input.vcf.gz   && mv cnv_tmp/cn.*.tab '/galaxy/server/database/objects/0/e/d/dataset_0ed947e9-b20f-49f2-a5a4-63b2c51f8216.dat' && mv cnv_tmp/summary.*.tab '/galaxy/server/database/objects/1/9/4/dataset_194186a5-04e4-44d9-a88f-e765e0d27243.dat'  && (echo '<html><body><head><title>Copy-number variation plots (bcftools cnv)</title><style type="text/css"> @media print { img { max-width:100% !important; page-break-inside: avoid; } </style>' > /galaxy/server/database/objects/4/3/1/dataset_4313af67-76e7-4546-8d1a-21bfd7f6a9bf.dat; for plot in cnv_tmp/*.png; do [ -f "$plot" ] || break; echo '<div><img src="data:image/png;base64,' >> /galaxy/server/database/objects/4/3/1/dataset_4313af67-76e7-4546-8d1a-21bfd7f6a9bf.dat; python -m base64 $plot >> /galaxy/server/database/objects/4/3/1/dataset_4313af67-76e7-4546-8d1a-21bfd7f6a9bf.dat; echo '" /></div><hr>' >> /galaxy/server/database/objects/4/3/1/dataset_4313af67-76e7-4546-8d1a-21bfd7f6a9bf.dat; done; echo '</body></html>' >> /galaxy/server/database/objects/4/3/1/dataset_4313af67-76e7-4546-8d1a-21bfd7f6a9bf.dat;)]
galaxy.jobs.runners DEBUG 2024-11-24 07:10:01,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (287) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/287/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/287/galaxy_287.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:01,783 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:10:01,783 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:10:01,783 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4: mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e
galaxy.tool_util.deps.containers INFO 2024-11-24 07:10:01,799 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-3f0b2099bce3ecb75064dfe6cdabcd4018727aa8:765890586dbdb5583fc21a09dae4bc93bb0eed0e-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:01,811 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:02,777 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:08,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-5qndn with k8s id: gxy-5qndn succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:10:08,996 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 287: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:10:16,123 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 287 finished
galaxy.model.metadata DEBUG 2024-11-24 07:10:16,164 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 379
galaxy.model.metadata DEBUG 2024-11-24 07:10:16,174 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 380
galaxy.model.metadata DEBUG 2024-11-24 07:10:16,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 381
galaxy.util WARNING 2024-11-24 07:10:16,185 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/0/e/d/dataset_0ed947e9-b20f-49f2-a5a4-63b2c51f8216.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/0/e/d/dataset_0ed947e9-b20f-49f2-a5a4-63b2c51f8216.dat'
galaxy.util WARNING 2024-11-24 07:10:16,186 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Unable to honor primary group (grp.struct_group(gr_name='galaxy', gr_passwd='x', gr_gid=101, gr_mem=[])) for /galaxy/server/database/objects/1/9/4/dataset_194186a5-04e4-44d9-a88f-e765e0d27243.dat, group remains grp.struct_group(gr_name='nogroup', gr_passwd='x', gr_gid=65534, gr_mem=[]), error was: [Errno 1] Operation not permitted: '/galaxy/server/database/objects/1/9/4/dataset_194186a5-04e4-44d9-a88f-e765e0d27243.dat'
galaxy.jobs INFO 2024-11-24 07:10:16,222 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 287 in /galaxy/server/database/jobs_directory/000/287
galaxy.jobs DEBUG 2024-11-24 07:10:16,264 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 287 executed (119.335 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:16,276 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 287 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:10:24,017 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 288
tpv.core.entities DEBUG 2024-11-24 07:10:24,038 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:10:24,038 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:10:24,041 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:10:24,049 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:10:24,059 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Working directory for job is: /galaxy/server/database/jobs_directory/000/288
galaxy.jobs.runners DEBUG 2024-11-24 07:10:24,064 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [288] queued (23.122 ms)
galaxy.jobs.handler INFO 2024-11-24 07:10:24,066 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (288) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:24,069 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 288
galaxy.jobs DEBUG 2024-11-24 07:10:24,141 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [288] prepared (64.722 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:10:24,159 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/288/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/288/registry.xml' '/galaxy/server/database/jobs_directory/000/288/upload_params.json' '382:/galaxy/server/database/objects/1/5/b/dataset_15be5d9d-0381-446e-9c2b-b53258d5d4e0_files:/galaxy/server/database/objects/1/5/b/dataset_15be5d9d-0381-446e-9c2b-b53258d5d4e0.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:10:24,168 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (288) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/288/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/288/galaxy_288.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:24,180 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:24,192 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:24,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,013 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zmvdf failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,014 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-zmvdf.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,046 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 07:10:33,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-zmvdf

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-zmvdf": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,075 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (288/gxy-zmvdf) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (288/gxy-zmvdf) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (288/gxy-zmvdf) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (288/gxy-zmvdf) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-zmvdf.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,081 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Attempting to stop job 288 (gxy-zmvdf)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Found job with id gxy-zmvdf to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,089 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 288 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:33,133 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (288/gxy-zmvdf) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 07:10:34,209 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 289
tpv.core.entities DEBUG 2024-11-24 07:10:34,234 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:10:34,234 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:10:34,237 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:10:34,246 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:10:34,256 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Working directory for job is: /galaxy/server/database/jobs_directory/000/289
galaxy.jobs.runners DEBUG 2024-11-24 07:10:34,261 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [289] queued (23.619 ms)
galaxy.jobs.handler INFO 2024-11-24 07:10:34,263 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (289) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:34,265 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 289
galaxy.jobs DEBUG 2024-11-24 07:10:34,331 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [289] prepared (59.637 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:10:34,346 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/289/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/289/registry.xml' '/galaxy/server/database/jobs_directory/000/289/upload_params.json' '383:/galaxy/server/database/objects/2/d/6/dataset_2d6231dc-d8b0-48f9-bd04-70db042d0216_files:/galaxy/server/database/objects/2/d/6/dataset_2d6231dc-d8b0-48f9-bd04-70db042d0216.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:10:34,354 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (289) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/289/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/289/galaxy_289.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:34,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:34,376 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:35,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,234 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-9pftb failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,235 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,377 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-9pftb.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,384 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 07:10:44,439 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-9pftb

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-9pftb": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,447 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289/gxy-9pftb) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289/gxy-9pftb) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289/gxy-9pftb) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289/gxy-9pftb) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-9pftb.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,453 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 289 (gxy-9pftb)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,463 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Found job with id gxy-9pftb to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,464 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 289 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:44,561 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (289/gxy-9pftb) Terminated at user's request
galaxy.jobs.handler DEBUG 2024-11-24 07:10:45,417 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 290
tpv.core.entities DEBUG 2024-11-24 07:10:45,440 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:10:45,440 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:10:45,443 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:10:45,452 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:10:45,463 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Working directory for job is: /galaxy/server/database/jobs_directory/000/290
galaxy.jobs.runners DEBUG 2024-11-24 07:10:45,469 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [290] queued (26.084 ms)
galaxy.jobs.handler INFO 2024-11-24 07:10:45,471 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (290) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:45,473 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 290
galaxy.jobs DEBUG 2024-11-24 07:10:45,539 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [290] prepared (59.996 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:10:45,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/290/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/290/registry.xml' '/galaxy/server/database/jobs_directory/000/290/upload_params.json' '384:/galaxy/server/database/objects/b/1/4/dataset_b14c8746-666a-4cd5-a688-014e2ec66886_files:/galaxy/server/database/objects/b/1/4/dataset_b14c8746-666a-4cd5-a688-014e2ec66886.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:10:45,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (290) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/290/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/290/galaxy_290.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:45,577 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:45,590 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:46,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:10:54,576 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-w26nr with k8s id: gxy-w26nr succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:10:54,680 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 290: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:11:01,793 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 290 finished
galaxy.model.metadata DEBUG 2024-11-24 07:11:01,836 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 384
galaxy.jobs INFO 2024-11-24 07:11:01,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 290 in /galaxy/server/database/jobs_directory/000/290
galaxy.jobs DEBUG 2024-11-24 07:11:01,907 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 290 executed (93.532 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:01,920 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 290 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:11:02,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 291
tpv.core.entities DEBUG 2024-11-24 07:11:02,753 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:11:02,753 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:11:02,757 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:11:02,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:11:02,780 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Working directory for job is: /galaxy/server/database/jobs_directory/000/291
galaxy.jobs.runners DEBUG 2024-11-24 07:11:02,788 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [291] queued (30.554 ms)
galaxy.jobs.handler INFO 2024-11-24 07:11:02,790 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (291) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:02,791 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 291
galaxy.jobs DEBUG 2024-11-24 07:11:02,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [291] prepared (58.017 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:02,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:11:02,857 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:03,038 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:11:03,058 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/291/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/291/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/b/1/4/dataset_b14c8746-666a-4cd5-a688-014e2ec66886.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"  --ignore-homref --include-noalt  --hw-to-az "6.7e-08" --az-to-hw "5e-09"               --output-type r   input.vcf.gz  > '/galaxy/server/database/objects/9/6/1/dataset_9611cec0-3c07-4907-af4e-1daa8408af0c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:11:03,067 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (291) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/291/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/291/galaxy_291.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:03,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:03,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:11:03,079 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:03,094 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:03,106 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:03,600 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:13,762 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-qxm6d with k8s id: gxy-qxm6d succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:11:13,874 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 291: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:11:20,817 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 291 finished
galaxy.model.metadata DEBUG 2024-11-24 07:11:20,854 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 385
galaxy.jobs INFO 2024-11-24 07:11:20,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 291 in /galaxy/server/database/jobs_directory/000/291
galaxy.jobs DEBUG 2024-11-24 07:11:20,924 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 291 executed (90.252 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:20,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 291 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:11:22,075 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 292
tpv.core.entities DEBUG 2024-11-24 07:11:22,102 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:11:22,102 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:11:22,107 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:11:22,117 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:11:22,129 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Working directory for job is: /galaxy/server/database/jobs_directory/000/292
galaxy.jobs.runners DEBUG 2024-11-24 07:11:22,136 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [292] queued (28.934 ms)
galaxy.jobs.handler INFO 2024-11-24 07:11:22,138 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (292) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:22,140 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 292
galaxy.jobs DEBUG 2024-11-24 07:11:22,236 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [292] prepared (88.506 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:11:22,255 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/292/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/292/registry.xml' '/galaxy/server/database/jobs_directory/000/292/upload_params.json' '386:/galaxy/server/database/objects/9/5/6/dataset_956ae345-99b4-4c91-a01b-8db0f8cd0cc8_files:/galaxy/server/database/objects/9/5/6/dataset_956ae345-99b4-4c91-a01b-8db0f8cd0cc8.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:11:22,266 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (292) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/292/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/292/galaxy_292.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:22,278 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:22,292 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:22,785 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:31,983 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-t4wf6 with k8s id: gxy-t4wf6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:11:32,087 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 292: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:11:39,182 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 292 finished
galaxy.model.metadata DEBUG 2024-11-24 07:11:39,220 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 386
galaxy.jobs INFO 2024-11-24 07:11:39,250 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 292 in /galaxy/server/database/jobs_directory/000/292
galaxy.jobs DEBUG 2024-11-24 07:11:39,289 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 292 executed (89.791 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:39,302 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 292 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:11:40,430 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 293
tpv.core.entities DEBUG 2024-11-24 07:11:40,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:11:40,454 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:11:40,457 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:11:40,466 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:11:40,477 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Working directory for job is: /galaxy/server/database/jobs_directory/000/293
galaxy.jobs.runners DEBUG 2024-11-24 07:11:40,484 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [293] queued (26.294 ms)
galaxy.jobs.handler INFO 2024-11-24 07:11:40,486 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (293) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:40,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 293
galaxy.jobs DEBUG 2024-11-24 07:11:40,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [293] prepared (37.666 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:40,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:11:40,532 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:40,707 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:11:40,724 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/293/tool_script.sh] for tool command [bcftools 2>&1 | grep 'Version:' > /galaxy/server/database/jobs_directory/000/293/outputs/COMMAND_VERSION 2>&1;
export BCFTOOLS_PLUGINS=`which bcftools | sed 's,bin/bcftools,libexec/bcftools,'`;     bgzip -c '/galaxy/server/database/objects/9/5/6/dataset_956ae345-99b4-4c91-a01b-8db0f8cd0cc8.dat' > input.vcf.gz && bcftools index input.vcf.gz &&                bcftools roh      --AF-dflt "0.4"   --GTs-only "30.0"     --hw-to-az "6.7e-08" --az-to-hw "5e-09"     --regions-overlap 1             input.vcf.gz  > '/galaxy/server/database/objects/0/3/b/dataset_03bab658-8c06-45f8-b774-c9449c80f9dd.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:11:40,733 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (293) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/293/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/293/galaxy_293.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:40,744 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:40,744 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:11:40,745 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Image name for tool toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4: mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a
galaxy.tool_util.deps.containers INFO 2024-11-24 07:11:40,761 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/mulled-v2-b99184dc2d32592dd62a87fa4a796c61585788e6:07602ea99d759e160674ea07c369efffcc80577a-0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:40,775 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:41,008 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:46,088 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-l4cf6 with k8s id: gxy-l4cf6 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:11:46,198 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 293: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:11:53,390 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 293 finished
galaxy.model.metadata DEBUG 2024-11-24 07:11:53,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 387
galaxy.jobs INFO 2024-11-24 07:11:53,452 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 293 in /galaxy/server/database/jobs_directory/000/293
galaxy.jobs DEBUG 2024-11-24 07:11:53,489 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 293 executed (81.533 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:53,501 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 293 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:11:55,708 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 295, 294
tpv.core.entities DEBUG 2024-11-24 07:11:55,730 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:11:55,731 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:11:55,734 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:11:55,742 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:11:55,754 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Working directory for job is: /galaxy/server/database/jobs_directory/000/294
galaxy.jobs.runners DEBUG 2024-11-24 07:11:55,760 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [294] queued (26.419 ms)
galaxy.jobs.handler INFO 2024-11-24 07:11:55,763 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (294) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,766 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 294
tpv.core.entities DEBUG 2024-11-24 07:11:55,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:11:55,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:11:55,778 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:11:55,790 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:11:55,814 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Working directory for job is: /galaxy/server/database/jobs_directory/000/295
galaxy.jobs.runners DEBUG 2024-11-24 07:11:55,823 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [295] queued (44.115 ms)
galaxy.jobs.handler INFO 2024-11-24 07:11:55,828 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (295) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,828 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 295
galaxy.jobs DEBUG 2024-11-24 07:11:55,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [294] prepared (85.522 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:11:55,882 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/294/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/294/registry.xml' '/galaxy/server/database/jobs_directory/000/294/upload_params.json' '388:/galaxy/server/database/objects/8/2/9/dataset_829128fd-55ee-452a-b905-2ea5f1b0eeb1_files:/galaxy/server/database/objects/8/2/9/dataset_829128fd-55ee-452a-b905-2ea5f1b0eeb1.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:11:55,892 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (294) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/294/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/294/galaxy_294.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:11:55,905 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [295] prepared (67.927 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,925 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:11:55,930 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/295/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/295/registry.xml' '/galaxy/server/database/jobs_directory/000/295/upload_params.json' '389:/galaxy/server/database/objects/c/e/1/dataset_ce1cbdbb-2459-451a-b084-b5c45303993f_files:/galaxy/server/database/objects/c/e/1/dataset_ce1cbdbb-2459-451a-b084-b5c45303993f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:11:55,938 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (295) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/295/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/295/galaxy_295.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,951 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:55,963 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:56,136 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:11:56,190 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,419 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-ngr9c failed and it is not a deletion case. Current state: running
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Trying with error file in _handle_job_failure
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,496 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-ngr9c.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes ERROR 2024-11-24 07:12:05,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Could not clean up k8s batch job. Ignoring...
Traceback (most recent call last):
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 437, in raise_for_status
    resp.raise_for_status()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://34.118.224.1:443/apis/batch/v1/namespaces/edge-24-11-24-06-11-1/jobs/gxy-ngr9c

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 872, in _handle_job_failure
    self.__cleanup_k8s_job(job)
  File "/galaxy/server/lib/galaxy/jobs/runners/kubernetes.py", line 879, in __cleanup_k8s_job
    delete_job(job, k8s_cleanup_job)
  File "/galaxy/server/lib/galaxy/jobs/runners/util/pykube_util.py", line 108, in delete_job
    job.scale(replicas=0)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/mixins.py", line 30, in scale
    self.update()
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 165, in update
    self.patch(self.obj, subresource=subresource)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/objects.py", line 157, in patch
    self.api.raise_for_status(r)
  File "/galaxy/server/.venv/lib/python3.12/site-packages/pykube/http.py", line 444, in raise_for_status
    raise HTTPError(resp.status_code, payload["message"])
pykube.exceptions.HTTPError: Operation cannot be fulfilled on jobs.batch "gxy-ngr9c": the object has been modified; please apply your changes to the latest version and try again
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,537 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] PP Getting into fail_job in k8s runner
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,544 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-rjl65 with k8s id: gxy-rjl65 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,547 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (294/gxy-ngr9c) tool_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (294/gxy-ngr9c) tool_stderr: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (294/gxy-ngr9c) job_stdout: 
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (294/gxy-ngr9c) job_stderr: An unknown error occurred in this job and the maximum number of retries have been exceeded for job: gxy-ngr9c.
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,548 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Attempting to stop job 294 (gxy-ngr9c)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,559 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Found job with id gxy-ngr9c to delete
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,560 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 294 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:05,613 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (294/gxy-ngr9c) Terminated at user's request
galaxy.jobs.runners DEBUG 2024-11-24 07:12:05,660 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 295: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.handler DEBUG 2024-11-24 07:12:06,994 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 296
tpv.core.entities DEBUG 2024-11-24 07:12:07,020 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:12:07,021 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:12:07,025 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:12:07,034 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:12:07,045 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Working directory for job is: /galaxy/server/database/jobs_directory/000/296
galaxy.jobs.runners DEBUG 2024-11-24 07:12:07,052 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [296] queued (27.211 ms)
galaxy.jobs.handler INFO 2024-11-24 07:12:07,054 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (296) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:07,055 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 296
galaxy.jobs DEBUG 2024-11-24 07:12:07,131 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [296] prepared (69.941 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:12:07,149 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/296/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/296/registry.xml' '/galaxy/server/database/jobs_directory/000/296/upload_params.json' '390:/galaxy/server/database/objects/a/1/5/dataset_a1501ec5-5072-47c5-85b6-4f6602b85d66_files:/galaxy/server/database/objects/a/1/5/dataset_a1501ec5-5072-47c5-85b6-4f6602b85d66.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:12:07,158 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (296) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/296/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/296/galaxy_296.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:07,173 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:07,187 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:07,565 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners DEBUG 2024-11-24 07:12:12,978 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 295 finished
galaxy.model.metadata DEBUG 2024-11-24 07:12:13,015 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 389
galaxy.jobs INFO 2024-11-24 07:12:13,044 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 295 in /galaxy/server/database/jobs_directory/000/295
galaxy.jobs DEBUG 2024-11-24 07:12:13,078 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 295 executed (84.032 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:13,091 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 295 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:16,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-767kq with k8s id: gxy-767kq succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:12:16,800 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 296: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:12:23,771 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 296 finished
galaxy.model.metadata DEBUG 2024-11-24 07:12:23,806 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 390
galaxy.jobs INFO 2024-11-24 07:12:23,829 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 296 in /galaxy/server/database/jobs_directory/000/296
galaxy.jobs DEBUG 2024-11-24 07:12:23,862 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 296 executed (73.102 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:23,873 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 296 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:12:24,330 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 297
tpv.core.entities DEBUG 2024-11-24 07:12:24,352 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:12:24,352 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:12:24,355 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:12:24,365 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:12:24,375 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Working directory for job is: /galaxy/server/database/jobs_directory/000/297
galaxy.jobs.runners DEBUG 2024-11-24 07:12:24,382 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [297] queued (26.587 ms)
galaxy.jobs.handler INFO 2024-11-24 07:12:24,384 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (297) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:24,386 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Starting queue_job for job 297
galaxy.jobs DEBUG 2024-11-24 07:12:24,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Job wrapper for Job [297] prepared (33.471 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:12:24,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:12:24,425 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:12:24,602 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:12:24,620 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Built script [/galaxy/server/database/jobs_directory/000/297/tool_script.sh] for tool command [vcfintersect -R '20:1-30000'  '/galaxy/server/database/objects/a/1/5/dataset_a1501ec5-5072-47c5-85b6-4f6602b85d66.dat' > '/galaxy/server/database/objects/b/1/d/dataset_b1d97c98-5ac3-4328-ba68-c4a90f99311d.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:12:24,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] (297) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/297/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/297/galaxy_297.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:24,646 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:12:24,652 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:12:24,652 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:12:24,669 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:24,686 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:25,719 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:34,853 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-zt947 with k8s id: gxy-zt947 succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:12:34,954 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 297: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:12:41,798 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 297 finished
galaxy.model.metadata DEBUG 2024-11-24 07:12:41,832 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 391
galaxy.jobs INFO 2024-11-24 07:12:41,864 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 297 in /galaxy/server/database/jobs_directory/000/297
galaxy.jobs DEBUG 2024-11-24 07:12:41,903 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 297 executed (88.763 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:41,914 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 297 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:12:44,724 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 300, 299, 298
tpv.core.entities DEBUG 2024-11-24 07:12:44,745 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:12:44,746 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:12:44,749 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:12:44,758 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:12:44,769 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Working directory for job is: /galaxy/server/database/jobs_directory/000/298
galaxy.jobs.runners DEBUG 2024-11-24 07:12:44,774 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [298] queued (24.959 ms)
galaxy.jobs.handler INFO 2024-11-24 07:12:44,776 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (298) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:44,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 298
tpv.core.entities DEBUG 2024-11-24 07:12:44,785 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:12:44,785 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:12:44,789 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:12:44,802 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:12:44,823 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Working directory for job is: /galaxy/server/database/jobs_directory/000/299
galaxy.jobs.runners DEBUG 2024-11-24 07:12:44,830 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [299] queued (40.815 ms)
galaxy.jobs.handler INFO 2024-11-24 07:12:44,833 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (299) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:44,839 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 299
tpv.core.entities DEBUG 2024-11-24 07:12:44,846 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:12:44,846 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:12:44,850 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:12:44,863 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:12:44,873 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [298] prepared (84.349 ms)
galaxy.jobs DEBUG 2024-11-24 07:12:44,893 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Working directory for job is: /galaxy/server/database/jobs_directory/000/300
galaxy.jobs.runners DEBUG 2024-11-24 07:12:44,901 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [300] queued (50.708 ms)
galaxy.jobs.handler INFO 2024-11-24 07:12:44,904 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (300) Job dispatched
galaxy.jobs.command_factory INFO 2024-11-24 07:12:44,906 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/298/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/298/registry.xml' '/galaxy/server/database/jobs_directory/000/298/upload_params.json' '392:/galaxy/server/database/objects/3/d/7/dataset_3d78ca66-a44d-40e1-9c52-a495c60c7565_files:/galaxy/server/database/objects/3/d/7/dataset_3d78ca66-a44d-40e1-9c52-a495c60c7565.dat']
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:44,908 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 300
galaxy.jobs.runners DEBUG 2024-11-24 07:12:44,919 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (298) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/298/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/298/galaxy_298.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:44,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs DEBUG 2024-11-24 07:12:44,962 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [299] prepared (113.203 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:44,969 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:12:44,987 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/299/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/299/registry.xml' '/galaxy/server/database/jobs_directory/000/299/upload_params.json' '393:/galaxy/server/database/objects/e/3/a/dataset_e3aa2710-d939-4652-93b7-b45bc619584b_files:/galaxy/server/database/objects/e/3/a/dataset_e3aa2710-d939-4652-93b7-b45bc619584b.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:12:44,999 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (299) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/299/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/299/galaxy_299.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:12:45,009 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [300] prepared (86.139 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,018 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,029 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:12:45,031 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/300/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/300/registry.xml' '/galaxy/server/database/jobs_directory/000/300/upload_params.json' '394:/galaxy/server/database/objects/f/0/d/dataset_f0de0aa5-19f5-4be9-821a-1abfb190ddb4_files:/galaxy/server/database/objects/f/0/d/dataset_f0de0aa5-19f5-4be9-821a-1abfb190ddb4.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:12:45,039 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (300) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/300/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/300/galaxy_300.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,049 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,061 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,888 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,937 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:45,980 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:55,247 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-x4t4r with k8s id: gxy-x4t4r succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:55,257 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-x6gt2 with k8s id: gxy-x6gt2 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:12:55,270 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-vvz2c with k8s id: gxy-vvz2c succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:12:55,372 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 298: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:12:55,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 299: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:12:55,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 300: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:13:06,258 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 299 finished
galaxy.jobs.runners DEBUG 2024-11-24 07:13:06,301 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 300 finished
galaxy.jobs.runners DEBUG 2024-11-24 07:13:06,309 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 298 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:06,342 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 393
galaxy.model.metadata DEBUG 2024-11-24 07:13:06,350 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 394
galaxy.model.metadata DEBUG 2024-11-24 07:13:06,359 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 392
galaxy.jobs INFO 2024-11-24 07:13:06,394 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 299 in /galaxy/server/database/jobs_directory/000/299
galaxy.jobs INFO 2024-11-24 07:13:06,405 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 300 in /galaxy/server/database/jobs_directory/000/300
galaxy.jobs INFO 2024-11-24 07:13:06,410 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 298 in /galaxy/server/database/jobs_directory/000/298
galaxy.jobs DEBUG 2024-11-24 07:13:06,444 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 299 executed (130.801 ms)
galaxy.jobs DEBUG 2024-11-24 07:13:06,449 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 300 executed (124.592 ms)
galaxy.jobs DEBUG 2024-11-24 07:13:06,457 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 298 executed (125.069 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:06,459 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 299 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:06,461 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 300 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:06,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 298 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:13:07,387 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 301
tpv.core.entities DEBUG 2024-11-24 07:13:07,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:13:07,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:13:07,419 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:13:07,427 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:13:07,440 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Working directory for job is: /galaxy/server/database/jobs_directory/000/301
galaxy.jobs.runners DEBUG 2024-11-24 07:13:07,447 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [301] queued (27.738 ms)
galaxy.jobs.handler INFO 2024-11-24 07:13:07,449 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (301) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:07,451 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Starting queue_job for job 301
galaxy.jobs DEBUG 2024-11-24 07:13:07,499 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Job wrapper for Job [301] prepared (43.184 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:07,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:13:07,500 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:07,519 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:13:07,536 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Built script [/galaxy/server/database/jobs_directory/000/301/tool_script.sh] for tool command [ln -s '/galaxy/server/database/objects/f/0/d/dataset_f0de0aa5-19f5-4be9-821a-1abfb190ddb4.dat' 'localref.fa' &&  vcfintersect   -r 'localref.fa' -w "30" -i '/galaxy/server/database/objects/3/d/7/dataset_3d78ca66-a44d-40e1-9c52-a495c60c7565.dat' '/galaxy/server/database/objects/e/3/a/dataset_e3aa2710-d939-4652-93b7-b45bc619584b.dat' > '/galaxy/server/database/objects/1/9/d/dataset_19db966b-fed6-49fa-8609-c37692a127b2.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:13:07,545 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] (301) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/301/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/301/galaxy_301.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:07,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:07,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:13:07,557 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:07,573 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:07,588 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:08,335 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:12,397 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-fbp4v with k8s id: gxy-fbp4v succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:13:12,512 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] executing external set_meta script for job 301: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:13:19,529 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] execution of external set_meta for job 301 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:19,563 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 395
galaxy.jobs INFO 2024-11-24 07:13:19,592 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Collecting metrics for Job 301 in /galaxy/server/database/jobs_directory/000/301
galaxy.jobs DEBUG 2024-11-24 07:13:19,632 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] job_wrapper.finish for job 301 executed (87.044 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:19,644 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-3] Checking if job 301 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:13:20,666 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 302, 303
tpv.core.entities DEBUG 2024-11-24 07:13:20,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:13:20,687 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:13:20,691 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:13:20,699 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:13:20,709 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Working directory for job is: /galaxy/server/database/jobs_directory/000/302
galaxy.jobs.runners DEBUG 2024-11-24 07:13:20,716 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [302] queued (24.973 ms)
galaxy.jobs.handler INFO 2024-11-24 07:13:20,717 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (302) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,720 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 302
tpv.core.entities DEBUG 2024-11-24 07:13:20,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:13:20,726 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:13:20,730 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:13:20,741 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:13:20,768 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Working directory for job is: /galaxy/server/database/jobs_directory/000/303
galaxy.jobs.runners DEBUG 2024-11-24 07:13:20,775 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [303] queued (44.813 ms)
galaxy.jobs.handler INFO 2024-11-24 07:13:20,777 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (303) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,779 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Starting queue_job for job 303
galaxy.jobs DEBUG 2024-11-24 07:13:20,823 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [302] prepared (90.697 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:13:20,843 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/302/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/302/registry.xml' '/galaxy/server/database/jobs_directory/000/302/upload_params.json' '396:/galaxy/server/database/objects/9/6/b/dataset_96b68d6e-aaad-42e8-8249-ebec6bd43740_files:/galaxy/server/database/objects/9/6/b/dataset_96b68d6e-aaad-42e8-8249-ebec6bd43740.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:13:20,852 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (302) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/302/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/302/galaxy_302.ec; sh -c "exit $return_code"
galaxy.jobs DEBUG 2024-11-24 07:13:20,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Job wrapper for Job [303] prepared (72.843 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,866 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,878 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.command_factory INFO 2024-11-24 07:13:20,883 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Built script [/galaxy/server/database/jobs_directory/000/303/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/303/registry.xml' '/galaxy/server/database/jobs_directory/000/303/upload_params.json' '397:/galaxy/server/database/objects/3/7/2/dataset_37269dcd-dd07-413c-81de-122e2897a89f_files:/galaxy/server/database/objects/3/7/2/dataset_37269dcd-dd07-413c-81de-122e2897a89f.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:13:20,891 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] (303) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/303/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/303/galaxy_303.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,904 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:20,915 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:21,428 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:21,477 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.handler DEBUG 2024-11-24 07:13:21,781 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 304
tpv.core.entities DEBUG 2024-11-24 07:13:21,806 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=force_default_container_for_built_in_tools, Rule: force_default_container_for_built_in_tools, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true', 'docker_container_id_override': 'quay.io/galaxyproject/galaxy-anvil:24.1.1'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:13:21,807 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:13:21,811 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:13:21,821 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:13:21,831 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Working directory for job is: /galaxy/server/database/jobs_directory/000/304
galaxy.jobs.runners DEBUG 2024-11-24 07:13:21,837 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [304] queued (26.223 ms)
galaxy.jobs.handler INFO 2024-11-24 07:13:21,839 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (304) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:21,842 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 304
galaxy.jobs DEBUG 2024-11-24 07:13:21,912 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [304] prepared (63.026 ms)
galaxy.jobs.command_factory INFO 2024-11-24 07:13:21,932 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/304/tool_script.sh] for tool command [python '/galaxy/server/database/tools/data_source/upload.py' '/galaxy/server' '/galaxy/server/database/jobs_directory/000/304/registry.xml' '/galaxy/server/database/jobs_directory/000/304/upload_params.json' '398:/galaxy/server/database/objects/b/7/8/dataset_b78ba12a-0bc4-4ed8-9d87-b12509d9060c_files:/galaxy/server/database/objects/b/7/8/dataset_b78ba12a-0bc4-4ed8-9d87-b12509d9060c.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:13:21,942 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (304) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/304/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/304/galaxy_304.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:21,955 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:21,968 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:22,552 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:29,863 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-2gfhj with k8s id: gxy-2gfhj succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:13:29,966 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] executing external set_meta script for job 302: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:30,935 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-6xc27 with k8s id: gxy-6xc27 succeeded
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:30,947 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-w22cx with k8s id: gxy-w22cx succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:13:31,051 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 303: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:13:31,080 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] executing external set_meta script for job 304: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:13:40,326 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] execution of external set_meta for job 302 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:40,366 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] loading metadata from file for: HistoryDatasetAssociation 396
galaxy.jobs INFO 2024-11-24 07:13:40,413 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Collecting metrics for Job 302 in /galaxy/server/database/jobs_directory/000/302
galaxy.jobs DEBUG 2024-11-24 07:13:40,455 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] job_wrapper.finish for job 302 executed (109.115 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:40,470 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 302 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:13:41,365 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 303 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:41,398 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 397
galaxy.jobs INFO 2024-11-24 07:13:41,424 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 303 in /galaxy/server/database/jobs_directory/000/303
galaxy.jobs DEBUG 2024-11-24 07:13:41,467 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 303 executed (84.952 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:41,479 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 303 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners DEBUG 2024-11-24 07:13:41,590 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] execution of external set_meta for job 304 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:41,623 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] loading metadata from file for: HistoryDatasetAssociation 398
galaxy.jobs INFO 2024-11-24 07:13:41,645 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Collecting metrics for Job 304 in /galaxy/server/database/jobs_directory/000/304
galaxy.jobs DEBUG 2024-11-24 07:13:41,682 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] job_wrapper.finish for job 304 executed (77.349 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:41,693 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-1] Checking if job 304 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.handler DEBUG 2024-11-24 07:13:42,357 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 305
tpv.core.entities DEBUG 2024-11-24 07:13:42,382 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=k8s, dest_name=k8s, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=100, max_accepted_mem=800, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=docker, type=TagType.ACCEPT>], handler_tags=None<class 'tpv.core.entities.Destination'> id=k8s, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 8, max_mem = 48, max_gpus = None, env=[], params={'tpv_cores': '{cores}', 'tpv_gpus': '{gpus}', 'tpv_mem': '{mem}', 'docker_enabled': 'true', 'limits_cpu': '{cores}', 'limits_memory': '{mem}Gi', 'requests_cpu': '{cores}', 'requests_memory': '{mem}Gi'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=cores * 3.8, gpus=0, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'container_monitor': False, 'docker_default_container_id': 'quay.io/galaxyproject/galaxy-anvil:24.1.1', 'tmp_dir': 'true'}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=local, type=TagType.REJECT>, <Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function
galaxy.jobs.mapper DEBUG 2024-11-24 07:13:42,382 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Mapped job to destination id: k8s
galaxy.jobs.handler DEBUG 2024-11-24 07:13:42,386 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Dispatching to k8s runner
galaxy.jobs DEBUG 2024-11-24 07:13:42,394 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Persisting job destination (destination id: k8s)
galaxy.jobs DEBUG 2024-11-24 07:13:42,407 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Working directory for job is: /galaxy/server/database/jobs_directory/000/305
galaxy.jobs.runners DEBUG 2024-11-24 07:13:42,416 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] Job [305] queued (29.810 ms)
galaxy.jobs.handler INFO 2024-11-24 07:13:42,418 [pN:job_handler_0,p:8,tN:JobHandlerQueue.monitor_thread] (305) Job dispatched
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:42,420 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Starting queue_job for job 305
galaxy.jobs DEBUG 2024-11-24 07:13:42,468 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Job wrapper for Job [305] prepared (40.210 ms)
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:42,469 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:13:42,469 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:42,487 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.command_factory INFO 2024-11-24 07:13:42,504 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Built script [/galaxy/server/database/jobs_directory/000/305/tool_script.sh] for tool command [ln -s '/galaxy/server/database/objects/b/7/8/dataset_b78ba12a-0bc4-4ed8-9d87-b12509d9060c.dat' 'localref.fa' &&  vcfintersect   -r 'localref.fa' -w "30" -u '/galaxy/server/database/objects/9/6/b/dataset_96b68d6e-aaad-42e8-8249-ebec6bd43740.dat' '/galaxy/server/database/objects/3/7/2/dataset_37269dcd-dd07-413c-81de-122e2897a89f.dat' > '/galaxy/server/database/objects/6/4/9/dataset_6491392a-0a9b-4881-8f5d-4a324852af20.dat']
galaxy.jobs.runners DEBUG 2024-11-24 07:13:42,511 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] (305) command is: mkdir -p working outputs configs
if [ -d _working ]; then
    rm -rf working/ outputs/ configs/; cp -R _working working; cp -R _outputs outputs; cp -R _configs configs
else
    cp -R working _working; cp -R outputs _outputs; cp -R configs _configs
fi
cd working; __out="${TMPDIR:-.}/out.$$" __err="${TMPDIR:-.}/err.$$"
mkfifo "$__out" "$__err"
trap 'rm -f "$__out" "$__err"' EXIT
tee -a '../outputs/tool_stdout' < "$__out" &
tee -a '../outputs/tool_stderr' < "$__err" >&2 & /bin/bash /galaxy/server/database/jobs_directory/000/305/tool_script.sh > "$__out" 2> "$__err"; return_code=$?; echo $return_code > /galaxy/server/database/jobs_directory/000/305/galaxy_305.ec; sh -c "exit $return_code"
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:42,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:42,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [ExplicitContainerResolver[]] found description [None]
galaxy.tool_util.deps.container_resolvers.mulled DEBUG 2024-11-24 07:13:42,522 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Image name for tool toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/1.0.0_rc3+galaxy0: vcflib:1.0.0_rc3
galaxy.tool_util.deps.containers INFO 2024-11-24 07:13:42,538 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking with container resolver [MulledDockerContainerResolver[namespace=biocontainers]] found description [ContainerDescription[identifier=quay.io/biocontainers/vcflib:1.0.0_rc3--py37hc088bd4_0,type=docker]]
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:42,553 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-2] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:43,026 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job set to running...
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:46,074 [pN:job_handler_0,p:8,tN:KubernetesRunner.monitor_thread] Job id: gxy-mvbgg with k8s id: gxy-mvbgg succeeded
galaxy.jobs.runners DEBUG 2024-11-24 07:13:46,205 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] executing external set_meta script for job 305: GALAXY_LIB="/galaxy/server/lib"; if [ "$GALAXY_LIB" != "None" ]; then if [ -n "$PYTHONPATH" ]; then PYTHONPATH="$GALAXY_LIB:$PYTHONPATH"; else PYTHONPATH="$GALAXY_LIB"; fi; export PYTHONPATH; fi; GALAXY_VIRTUAL_ENV="None"; if [ "$GALAXY_VIRTUAL_ENV" != "None" -a -z "$VIRTUAL_ENV" -a -f "$GALAXY_VIRTUAL_ENV/bin/activate" ]; then . "$GALAXY_VIRTUAL_ENV/bin/activate"; fi; python metadata/set.py
galaxy.jobs.runners DEBUG 2024-11-24 07:13:53,314 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] execution of external set_meta for job 305 finished
galaxy.model.metadata DEBUG 2024-11-24 07:13:53,350 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] loading metadata from file for: HistoryDatasetAssociation 399
galaxy.jobs INFO 2024-11-24 07:13:53,381 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Collecting metrics for Job 305 in /galaxy/server/database/jobs_directory/000/305
galaxy.jobs DEBUG 2024-11-24 07:13:53,416 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] job_wrapper.finish for job 305 executed (84.167 ms)
galaxy.jobs.runners.kubernetes DEBUG 2024-11-24 07:13:53,429 [pN:job_handler_0,p:8,tN:KubernetesRunner.work_thread-0] Checking if job 305 is an interactive tool. guest ports: []. interactive entry points: []
